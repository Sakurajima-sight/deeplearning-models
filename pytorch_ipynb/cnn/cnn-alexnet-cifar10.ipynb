{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "*Accompanying code examples of the book \"Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python\" by [Sebastian Raschka](https://sebastianraschka.com). All code examples are released under the [MIT license](https://github.com/rasbt/deep-learning-book/blob/master/LICENSE). If you find this content useful, please consider supporting the work by buying a [copy of the book](https://leanpub.com/ann-and-deeplearning).*\n",
    "  \n",
    "Other code examples and content are available on [GitHub](https://github.com/rasbt/deep-learning-book). The PDF and ebook versions of the book are available through [Leanpub](https://leanpub.com/ann-and-deeplearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 9.0.2\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# Model Zoo -- AlexNet CIFAR-10 Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "    \n",
    "- [1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"[Imagenet classification with deep convolutional neural networks.](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\" In Advances in Neural Information Processing Systems, pp. 1097-1105. 2012.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### 参数设置\n",
    "##########################\n",
    "\n",
    "# 超参数\n",
    "RANDOM_SEED = 1          # 随机种子\n",
    "LEARNING_RATE = 0.0001   # 学习率\n",
    "BATCH_SIZE = 256         # 批量大小\n",
    "NUM_EPOCHS = 20          # 训练轮数\n",
    "\n",
    "# 网络结构相关\n",
    "NUM_CLASSES = 10         # 分类类别数量\n",
    "\n",
    "# 其他设置\n",
    "DEVICE = \"cuda:0\"        # 使用的设备（GPU）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_loader(data_dir,\n",
    "                           batch_size,\n",
    "                           train_transform,\n",
    "                           valid_transform,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           num_workers=4):\n",
    "    \"\"\"\n",
    "    加载 CIFAR-10 的训练集，并划分为训练集和验证集，返回对应的 DataLoader。\n",
    "    \"\"\"\n",
    "\n",
    "    # 加载训练数据集（用于训练）\n",
    "    train_dataset = datasets.CIFAR10(root=data_dir,\n",
    "                                     train=True,\n",
    "                                     download=True,\n",
    "                                     transform=train_transform)\n",
    "\n",
    "    # 再次加载训练数据集（用于验证），但使用不同的 transform\n",
    "    valid_dataset = datasets.CIFAR10(root=data_dir,\n",
    "                                     train=True,\n",
    "                                     download=False,\n",
    "                                     transform=valid_transform)\n",
    "\n",
    "    # 计算总训练样本数\n",
    "    num_train = len(train_dataset)\n",
    "    indices = np.arange(num_train)  # 生成索引列表\n",
    "    split = np.int64(np.floor(valid_size * num_train))  # 计算验证集大小\n",
    "\n",
    "    if shuffle:\n",
    "        # 打乱索引，确保划分是随机的\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    # 根据划分的索引生成训练和验证集索引\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # 创建采样器\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # 创建训练数据加载器\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=train_sampler,\n",
    "                                               num_workers=num_workers)\n",
    "\n",
    "    # 创建验证数据加载器\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=valid_sampler,\n",
    "                                               num_workers=num_workers)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir,\n",
    "                    batch_size,\n",
    "                    test_transform,\n",
    "                    num_workers=4):\n",
    "    \"\"\"\n",
    "    加载 CIFAR-10 的测试集并返回 DataLoader。\n",
    "    \"\"\"\n",
    "\n",
    "    # 加载测试数据集\n",
    "    dataset = datasets.CIFAR10(root=data_dir,\n",
    "                               train=False,\n",
    "                               download=False,\n",
    "                               transform=test_transform)\n",
    "\n",
    "    # 创建测试数据加载器\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=num_workers)\n",
    "\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本:\n",
      "\n",
      "图像批次尺寸: torch.Size([256, 3, 64, 64])\n",
      "标签批次尺寸: torch.Size([256])\n",
      "\n",
      "验证集样本:\n",
      "图像批次尺寸: torch.Size([256, 3, 64, 64])\n",
      "标签批次尺寸: torch.Size([256])\n",
      "\n",
      "测试集样本:\n",
      "图像批次尺寸: torch.Size([256, 3, 64, 64])\n",
      "标签批次尺寸: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### CIFAR-10 数据集加载与检查\n",
    "##########################\n",
    "\n",
    "# 定义图像的预处理操作：\n",
    "# - Resize：将图像统一调整为 64x64 像素\n",
    "# - ToTensor：将图像转换为 PyTorch 的张量格式，并自动归一化到 [0, 1]\n",
    "custom_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 加载训练集和验证集\n",
    "train_loader, valid_loader = get_train_valid_loader(\n",
    "    data_dir='data',                 # 数据存储路径\n",
    "    batch_size=BATCH_SIZE,          # 批次大小\n",
    "    train_transform=custom_transform,  # 训练集图像预处理\n",
    "    valid_transform=custom_transform,  # 验证集图像预处理\n",
    "    random_seed=RANDOM_SEED,        # 控制划分验证集的随机性\n",
    "    valid_size=0.1,                 # 验证集占训练集的比例（10%）\n",
    "    shuffle=True,                   # 是否在划分前打乱数据\n",
    "    num_workers=4                   # 加载数据使用的线程数\n",
    ")\n",
    "\n",
    "# 加载测试集\n",
    "test_loader = get_test_loader(\n",
    "    data_dir='data',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    test_transform=custom_transform,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# 检查训练集中的一个批次\n",
    "print('训练集样本:\\n')\n",
    "for images, labels in train_loader:\n",
    "    print('图像批次尺寸:', images.size())  # 输出形状：(batch_size, 3, 64, 64)\n",
    "    print('标签批次尺寸:', labels.size())  # 输出形状：(batch_size)\n",
    "    break  # 只查看一个批次\n",
    "\n",
    "# 检查验证集中的一个批次\n",
    "print('\\n验证集样本:')\n",
    "for images, labels in valid_loader:\n",
    "    print('图像批次尺寸:', images.size())\n",
    "    print('标签批次尺寸:', labels.size())\n",
    "    break\n",
    "\n",
    "# 检查测试集中的一个批次\n",
    "print('\\n测试集样本:')\n",
    "for images, labels in test_loader:\n",
    "    print('图像批次尺寸:', images.size())\n",
    "    print('标签批次尺寸:', labels.size())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型定义：AlexNet\n",
    "##########################\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        # 特征提取部分：多个卷积层 + 激活函数 + 池化层\n",
    "        self.features = nn.Sequential(\n",
    "            # 第一层：输入通道3（RGB图像），输出通道64，卷积核11x11，步幅4，padding=2\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            # 第二层：卷积核5x5，输出通道192\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            # 第三层：卷积核3x3，输出通道384\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 第四层：卷积核3x3，输出通道256\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 第五层：卷积核3x3，输出通道256\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 最大池化层\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        # 自适应平均池化层：输出尺寸为 (6, 6)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "        # 分类器部分：全连接层 + Dropout + ReLU\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)  # 输出为类别数\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # 提取特征\n",
    "        x = self.avgpool(x)   # 池化\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)  # 展平成一维向量\n",
    "        logits = self.classifier(x)        # 全连接层进行分类\n",
    "        probas = F.softmax(logits, dim=1)  # 转为概率分布\n",
    "        return logits, probas              # 返回原始输出 + 概率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "# 设置随机种子，确保实验结果可复现\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# 实例化模型，指定输出类别数\n",
    "model = AlexNet(NUM_CLASSES)\n",
    "\n",
    "# 将模型移动到指定设备（GPU 或 CPU）\n",
    "model.to(DEVICE)\n",
    "\n",
    "# 使用 Adam 优化器，并设置学习率\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Batch 0000/0176 | Cost: 2.3027\n",
      "Epoch: 001/020 | Batch 0150/0176 | Cost: 1.5864\n",
      "Epoch: 001/020 | Train: 36.842%  | Valid: 36.740%\n",
      "本轮耗时: 0.15 分钟\n",
      "Epoch: 002/020 | Batch 0000/0176 | Cost: 1.6263\n",
      "Epoch: 002/020 | Batch 0150/0176 | Cost: 1.4651\n",
      "Epoch: 002/020 | Train: 46.724%  | Valid: 46.260%\n",
      "本轮耗时: 0.29 分钟\n",
      "Epoch: 003/020 | Batch 0000/0176 | Cost: 1.3999\n",
      "Epoch: 003/020 | Batch 0150/0176 | Cost: 1.2032\n",
      "Epoch: 003/020 | Train: 51.836%  | Valid: 50.840%\n",
      "本轮耗时: 0.43 分钟\n",
      "Epoch: 004/020 | Batch 0000/0176 | Cost: 1.2515\n",
      "Epoch: 004/020 | Batch 0150/0176 | Cost: 1.1873\n",
      "Epoch: 004/020 | Train: 57.331%  | Valid: 55.120%\n",
      "本轮耗时: 0.58 分钟\n",
      "Epoch: 005/020 | Batch 0000/0176 | Cost: 1.0831\n",
      "Epoch: 005/020 | Batch 0150/0176 | Cost: 1.0954\n",
      "Epoch: 005/020 | Train: 61.304%  | Valid: 58.980%\n",
      "本轮耗时: 0.71 分钟\n",
      "Epoch: 006/020 | Batch 0000/0176 | Cost: 1.0111\n",
      "Epoch: 006/020 | Batch 0150/0176 | Cost: 1.1086\n",
      "Epoch: 006/020 | Train: 62.633%  | Valid: 58.500%\n",
      "本轮耗时: 0.85 分钟\n",
      "Epoch: 007/020 | Batch 0000/0176 | Cost: 1.0290\n",
      "Epoch: 007/020 | Batch 0150/0176 | Cost: 0.9839\n",
      "Epoch: 007/020 | Train: 68.809%  | Valid: 62.320%\n",
      "本轮耗时: 0.99 分钟\n",
      "Epoch: 008/020 | Batch 0000/0176 | Cost: 0.9228\n",
      "Epoch: 008/020 | Batch 0150/0176 | Cost: 0.8691\n",
      "Epoch: 008/020 | Train: 66.811%  | Valid: 60.800%\n",
      "本轮耗时: 1.14 分钟\n",
      "Epoch: 009/020 | Batch 0000/0176 | Cost: 1.0046\n",
      "Epoch: 009/020 | Batch 0150/0176 | Cost: 0.8422\n",
      "Epoch: 009/020 | Train: 71.844%  | Valid: 63.380%\n",
      "本轮耗时: 1.28 分钟\n",
      "Epoch: 010/020 | Batch 0000/0176 | Cost: 0.7936\n",
      "Epoch: 010/020 | Batch 0150/0176 | Cost: 0.7727\n",
      "Epoch: 010/020 | Train: 77.542%  | Valid: 66.120%\n",
      "本轮耗时: 1.41 分钟\n",
      "Epoch: 011/020 | Batch 0000/0176 | Cost: 0.6214\n",
      "Epoch: 011/020 | Batch 0150/0176 | Cost: 0.6812\n",
      "Epoch: 011/020 | Train: 80.687%  | Valid: 66.720%\n",
      "本轮耗时: 1.56 分钟\n",
      "Epoch: 012/020 | Batch 0000/0176 | Cost: 0.6033\n",
      "Epoch: 012/020 | Batch 0150/0176 | Cost: 0.6666\n",
      "Epoch: 012/020 | Train: 83.207%  | Valid: 66.660%\n",
      "本轮耗时: 1.70 分钟\n",
      "Epoch: 013/020 | Batch 0000/0176 | Cost: 0.4216\n",
      "Epoch: 013/020 | Batch 0150/0176 | Cost: 0.6149\n",
      "Epoch: 013/020 | Train: 84.867%  | Valid: 67.360%\n",
      "本轮耗时: 1.84 分钟\n",
      "Epoch: 014/020 | Batch 0000/0176 | Cost: 0.5006\n",
      "Epoch: 014/020 | Batch 0150/0176 | Cost: 0.5433\n",
      "Epoch: 014/020 | Train: 87.256%  | Valid: 67.600%\n",
      "本轮耗时: 1.98 分钟\n",
      "Epoch: 015/020 | Batch 0000/0176 | Cost: 0.3980\n",
      "Epoch: 015/020 | Batch 0150/0176 | Cost: 0.5383\n",
      "Epoch: 015/020 | Train: 86.271%  | Valid: 66.420%\n",
      "本轮耗时: 2.12 分钟\n",
      "Epoch: 016/020 | Batch 0000/0176 | Cost: 0.4022\n",
      "Epoch: 016/020 | Batch 0150/0176 | Cost: 0.3104\n",
      "Epoch: 016/020 | Train: 92.236%  | Valid: 67.200%\n",
      "本轮耗时: 2.26 分钟\n",
      "Epoch: 017/020 | Batch 0000/0176 | Cost: 0.2167\n",
      "Epoch: 017/020 | Batch 0150/0176 | Cost: 0.3584\n",
      "Epoch: 017/020 | Train: 91.904%  | Valid: 67.960%\n",
      "本轮耗时: 2.40 分钟\n",
      "Epoch: 018/020 | Batch 0000/0176 | Cost: 0.2607\n",
      "Epoch: 018/020 | Batch 0150/0176 | Cost: 0.2670\n",
      "Epoch: 018/020 | Train: 91.829%  | Valid: 66.380%\n",
      "本轮耗时: 2.54 分钟\n",
      "Epoch: 019/020 | Batch 0000/0176 | Cost: 0.2116\n",
      "Epoch: 019/020 | Batch 0150/0176 | Cost: 0.1602\n",
      "Epoch: 019/020 | Train: 94.756%  | Valid: 67.740%\n",
      "本轮耗时: 2.68 分钟\n",
      "Epoch: 020/020 | Batch 0000/0176 | Cost: 0.2086\n",
      "Epoch: 020/020 | Batch 0150/0176 | Cost: 0.1349\n",
      "Epoch: 020/020 | Train: 95.720%  | Valid: 67.720%\n",
      "本轮耗时: 2.82 分钟\n",
      "总训练时间: 2.82 分钟\n",
      "测试集准确率: 67.21%\n",
      "总运行时间: 2.83 分钟\n"
     ]
    }
   ],
   "source": [
    "# 计算模型在给定数据集上的准确率\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    model.eval()  # 设置为评估模式（关闭 dropout、BN 等）\n",
    "    \n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)  # 前向传播，获取分类结果\n",
    "        _, predicted_labels = torch.max(probas, 1)  # 获取每个样本预测的类别标签\n",
    "\n",
    "        num_examples += targets.size(0)  # 累加样本总数\n",
    "        assert predicted_labels.size() == targets.size()\n",
    "        correct_pred += (predicted_labels == targets).sum()  # 累加预测正确的数量\n",
    "        \n",
    "    return correct_pred.float() / num_examples * 100  # 返回百分比准确率\n",
    "    \n",
    "\n",
    "\n",
    "# ========== 模型训练部分 ==========\n",
    "start_time = time.time()  # 记录开始时间\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()  # 设置为训练模式（启用 dropout、BN 等）\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### 前向传播 + 反向传播\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        cost.backward()        # 反向传播计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()       # 用优化器更新参数\n",
    "        \n",
    "        ### 打印训练日志\n",
    "        if not batch_idx % 150:  # 每隔150个批次打印一次\n",
    "            print('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                  % (epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    # 每个 epoch 结束后评估训练集和验证集上的准确率\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):  # 推理模式下不计算梯度，节省内存\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%  | Valid: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE),\n",
    "              compute_accuracy(model, valid_loader, device=DEVICE)))\n",
    "        \n",
    "    print('本轮耗时: %.2f 分钟' % ((time.time() - start_time)/60))\n",
    "    \n",
    "\n",
    "# ========== 训练结束后评估测试集 ==========\n",
    "print('总训练时间: %.2f 分钟' % ((time.time() - start_time)/60))\n",
    "\n",
    "with torch.set_grad_enabled(False):  # 推理时关闭梯度计算\n",
    "    print('测试集准确率: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))\n",
    "    \n",
    "print('总运行时间: %.2f 分钟' % ((time.time() - start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas     : 2.2.3\n",
      "PIL        : 11.1.0\n",
      "numpy      : 1.26.4\n",
      "torch      : 2.6.0+cu126\n",
      "matplotlib : 3.10.1\n",
      "torchvision: 0.21.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
