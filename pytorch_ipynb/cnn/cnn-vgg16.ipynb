{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Model-Zoo----Convolutional-Neural-Network-(VGG16)\" data-toc-modified-id=\"Model-Zoo----Convolutional-Neural-Network-(VGG16)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Model Zoo -- Convolutional Neural Network (VGG16)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Settings-and-Dataset\" data-toc-modified-id=\"Settings-and-Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Settings and Dataset</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
    "- Author: Sebastian Raschka\n",
    "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 9.0.2\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEu9MiOxj5wk"
   },
   "source": [
    "- Runs on CPU (not recommended here) or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# Model Zoo -- Convolutional Neural Network (VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.set_per_process_memory_fraction(0.5, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvgJ_0i7j5wt"
   },
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备: cuda:0\n",
      "图像批次的维度: torch.Size([512, 3, 32, 32])\n",
      "标签的维度: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### 配置设置\n",
    "##########################\n",
    "\n",
    "# 设备选择：如果有可用的 GPU，则使用 GPU，否则使用 CPU\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('使用的设备:', DEVICE)\n",
    "\n",
    "# 超参数设置\n",
    "random_seed = 1            # 随机种子\n",
    "learning_rate = 0.001      # 学习率\n",
    "num_epochs = 10            # 训练的轮数\n",
    "batch_size = 512           # 每批次的样本数量\n",
    "\n",
    "# 网络架构设置\n",
    "num_features = 784         # 特征数量（例如：MNIST 图像的像素数，28x28=784）\n",
    "num_classes = 10           # 类别数量（对于 CIFAR10 数据集，类别数为 10）\n",
    "\n",
    "##########################\n",
    "### CIFAR10 数据集\n",
    "##########################\n",
    "\n",
    "# 注意：transforms.ToTensor() 会将输入图像的像素值缩放到 0-1 范围内\n",
    "train_dataset = datasets.CIFAR10(root='data',  # 数据存储路径\n",
    "                                 train=True,   # 加载训练集\n",
    "                                 transform=transforms.ToTensor(),  # 进行 ToTensor 变换\n",
    "                                 download=True)  # 下载数据集（如果没有下载的话）\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data',   # 数据存储路径\n",
    "                                train=False,  # 加载测试集\n",
    "                                transform=transforms.ToTensor())  # 进行 ToTensor 变换\n",
    "\n",
    "# 创建训练数据加载器（DataLoader），批量读取训练集数据\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size,  # 每批次的数据量\n",
    "                          shuffle=True)           # 是否打乱数据顺序\n",
    "\n",
    "# 创建测试数据加载器（DataLoader），批量读取测试集数据\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,  # 每批次的数据量\n",
    "                         shuffle=False)          # 不打乱数据顺序\n",
    "\n",
    "# 检查数据集的维度（查看一个批次的数据形状）\n",
    "for images, labels in train_loader:  \n",
    "    print('图像批次的维度:', images.shape)  # 输出图像的维度，通常是 (batch_size, channels, height, width)\n",
    "    print('标签的维度:', labels.shape)       # 输出标签的维度，通常是 (batch_size,)\n",
    "    break  # 只检查第一个批次的数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class VGG16(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        # calculate same padding:\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "        \n",
    "        self.block_1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          # (1(32-1)- 32 + 3)/2 = 1\n",
    "                          padding=1), \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_3 = nn.Sequential(        \n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "          \n",
    "        self.block_4 = nn.Sequential(   \n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_5 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),    \n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))             \n",
    "        )\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "            \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "                    \n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        #x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "torch.manual_seed(random_seed)\n",
    "model = VGG16(num_features=num_features,\n",
    "              num_classes=num_classes)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0098 | Cost: 2.3856\n",
      "Epoch: 001/010 | Batch 0050/0098 | Cost: 2.2934\n",
      "Epoch: 001/010 | Train: 16.854% |  Loss: 2.162\n",
      "Time elapsed: 0.34 min\n",
      "Epoch: 002/010 | Batch 0000/0098 | Cost: 2.1523\n",
      "Epoch: 002/010 | Batch 0050/0098 | Cost: 1.8502\n",
      "Epoch: 002/010 | Train: 35.606% |  Loss: 1.631\n",
      "Time elapsed: 0.67 min\n",
      "Epoch: 003/010 | Batch 0000/0098 | Cost: 1.5630\n",
      "Epoch: 003/010 | Batch 0050/0098 | Cost: 1.5667\n",
      "Epoch: 003/010 | Train: 40.448% |  Loss: 1.565\n",
      "Time elapsed: 1.00 min\n",
      "Epoch: 004/010 | Batch 0000/0098 | Cost: 1.6272\n",
      "Epoch: 004/010 | Batch 0050/0098 | Cost: 1.4153\n",
      "Epoch: 004/010 | Train: 54.202% |  Loss: 1.234\n",
      "Time elapsed: 1.34 min\n",
      "Epoch: 005/010 | Batch 0000/0098 | Cost: 1.2143\n",
      "Epoch: 005/010 | Batch 0050/0098 | Cost: 1.2371\n",
      "Epoch: 005/010 | Train: 62.090% |  Loss: 1.037\n",
      "Time elapsed: 1.67 min\n",
      "Epoch: 006/010 | Batch 0000/0098 | Cost: 1.0721\n",
      "Epoch: 006/010 | Batch 0050/0098 | Cost: 1.0059\n",
      "Epoch: 006/010 | Train: 70.060% |  Loss: 0.844\n",
      "Time elapsed: 2.00 min\n",
      "Epoch: 007/010 | Batch 0000/0098 | Cost: 0.8832\n",
      "Epoch: 007/010 | Batch 0050/0098 | Cost: 0.9734\n",
      "Epoch: 007/010 | Train: 71.734% |  Loss: 0.788\n",
      "Time elapsed: 2.33 min\n",
      "Epoch: 008/010 | Batch 0000/0098 | Cost: 0.8126\n",
      "Epoch: 008/010 | Batch 0050/0098 | Cost: 0.7249\n",
      "Epoch: 008/010 | Train: 80.310% |  Loss: 0.568\n",
      "Time elapsed: 2.66 min\n",
      "Epoch: 009/010 | Batch 0000/0098 | Cost: 0.5044\n",
      "Epoch: 009/010 | Batch 0050/0098 | Cost: 0.5431\n",
      "Epoch: 009/010 | Train: 81.560% |  Loss: 0.535\n",
      "Time elapsed: 3.00 min\n",
      "Epoch: 010/010 | Batch 0000/0098 | Cost: 0.6132\n",
      "Epoch: 010/010 | Batch 0050/0098 | Cost: 0.5163\n",
      "Epoch: 010/010 | Train: 86.100% |  Loss: 0.402\n",
      "Time elapsed: 3.72 min\n",
      "Total Training Time: 3.72 min\n"
     ]
    }
   ],
   "source": [
    "# 计算模型在给定数据加载器上的准确率\n",
    "def compute_accuracy(model, data_loader):\n",
    "    model.eval()  # 设置模型为评估模式，关闭dropout等\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    # 遍历数据加载器中的每一个批次\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(DEVICE)  # 将特征数据移到设备（GPU 或 CPU）\n",
    "        targets = targets.to(DEVICE)    # 将目标标签移到设备（GPU 或 CPU）\n",
    "\n",
    "        logits, probas = model(features)  # 获取模型的输出 logits 和概率值\n",
    "        _, predicted_labels = torch.max(probas, 1)  # 获取预测的标签，`1` 表示按行选择最大值\n",
    "        \n",
    "        num_examples += targets.size(0)  # 更新总样本数\n",
    "        correct_pred += (predicted_labels == targets).sum()  # 计算预测正确的样本数\n",
    "    \n",
    "    # 返回准确率\n",
    "    return correct_pred.float() / num_examples * 100  # 返回百分比形式的准确率\n",
    "\n",
    "\n",
    "# 计算模型在给定数据加载器上的平均损失\n",
    "def compute_epoch_loss(model, data_loader):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    curr_loss, num_examples = 0., 0\n",
    "    with torch.no_grad():  # 在此上下文中，禁用梯度计算，节省内存\n",
    "        # 遍历数据加载器中的每一个批次\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(DEVICE)  # 将特征数据移到设备\n",
    "            targets = targets.to(DEVICE)    # 将目标标签移到设备\n",
    "            logits, probas = model(features)  # 获取模型的输出\n",
    "            loss = F.cross_entropy(logits, targets, reduction='sum')  # 计算交叉熵损失，`sum`表示对所有样本的损失求和\n",
    "            num_examples += targets.size(0)  # 更新样本数\n",
    "            curr_loss += loss  # 累加损失\n",
    "\n",
    "        curr_loss = curr_loss / num_examples  # 计算平均损失\n",
    "        return curr_loss  # 返回平均损失\n",
    "    \n",
    "\n",
    "# 训练过程开始\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()  # 设置模型为训练模式\n",
    "    # 遍历训练集的每一个批次\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)  # 将特征数据移到设备\n",
    "        targets = targets.to(DEVICE)    # 将目标标签移到设备\n",
    "            \n",
    "        ### 正向传播和反向传播 ###\n",
    "        logits, probas = model(features)  # 获取模型的输出\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清除之前计算的梯度\n",
    "        \n",
    "        cost.backward()  # 反向传播计算梯度\n",
    "        \n",
    "        ### 更新模型参数 ###\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        \n",
    "        ### 记录日志 ###\n",
    "        if not batch_idx % 50:  # 每50个批次打印一次日志\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   % (epoch+1, num_epochs, batch_idx, \n",
    "                      len(train_loader), cost))  # 输出当前轮次、批次和损失值\n",
    "\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.set_grad_enabled(False):  # 禁用梯度计算，节省内存\n",
    "        # 输出训练集的准确率和损失\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%% |  Loss: %.3f' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader),  # 计算并输出训练集的准确率\n",
    "              compute_epoch_loss(model, train_loader)))  # 计算并输出训练集的平均损失\n",
    "\n",
    "\n",
    "    # 输出每个epoch的时间\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time) / 60))\n",
    "    \n",
    "# 输出总的训练时间\n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 72.92%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy      : 1.26.4\n",
      "torchvision: 0.21.0+cu126\n",
      "torch      : 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
