{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
    "- Author: Sebastian Raschka\n",
    "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 9.0.2\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# LeNet-5 CIFAR10 Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the classic LeNet-5 convolutional network [1] and applies it to MNIST digit classification.  \n",
    "本笔记本实现了经典的LeNet-5卷积神经网络[1]并将其应用于MNIST数字分类。\n",
    "\n",
    "The basic architecture is shown in the figure below:  \n",
    "基本架构如下图所示：\n",
    "\n",
    "![](../images/lenet/lenet-5_1.jpg)  \n",
    "\n",
    "LeNet-5 is commonly regarded as the pioneer of convolutional neural networks, consisting of a very simple architecture (by modern standards).  \n",
    "LeNet-5通常被认为是卷积神经网络的开创者，它由一个非常简单的架构组成（按现代标准来看）。\n",
    "\n",
    "In total, LeNet-5 consists of only 7 layers. 3 out of these 7 layers are convolutional layers (C1, C3, C5), which are connected by two average pooling layers (S2 & S4).  \n",
    "总的来说，LeNet-5只有7层，其中3层是卷积层（C1、C3、C5），它们通过两个平均池化层（S2和S4）连接。\n",
    "\n",
    "The penultimate layer is a fully connected layer (F6), which is followed by the final output layer.  \n",
    "倒数第二层是全连接层（F6），之后是最终的输出层。\n",
    "\n",
    "The additional details are summarized below:  \n",
    "额外的细节总结如下：\n",
    "\n",
    "- All convolutional layers use 5x5 kernels with stride 1.  \n",
    "  所有卷积层都使用5x5的卷积核，步幅为1。\n",
    "\n",
    "- The two average pooling (subsampling) layers are 2x2 pixels wide with stride 1.  \n",
    "  两个平均池化（子采样）层宽度为2x2像素，步幅为1。\n",
    "\n",
    "- Throughout the network, tanh sigmoid activation functions are used. (**In this notebook, we replace these with ReLU activations**)  \n",
    "  网络中使用的是tanh sigmoid激活函数。（**在本笔记本中，我们将其替换为ReLU激活函数**）\n",
    "\n",
    "- The output layer uses 10 custom Euclidean Radial Basis Function neurons for the output layer. (**In this notebook, we replace these with softmax activations**)  \n",
    "  输出层使用10个自定义的欧几里得径向基函数神经元作为输出层。（**在本笔记本中，我们将其替换为softmax激活函数**）\n",
    "\n",
    "- The input size is 32x32; here, we rescale the MNIST images from 28x28 to 32x32 to match this input dimension. Alternatively, we would have to change the  \n",
    "  输入大小是32x32；在这里，我们将MNIST图像从28x28重新缩放到32x32以匹配此输入维度。否则，我们将不得不更改\n",
    "\n",
    "achieve error rate below 1% on the MNIST data set, which was very close to the state of the art at the time (produced by a boosted ensemble of three LeNet-4 networks).  \n",
    "在MNIST数据集上实现低于1%的错误率，这在当时接近最先进的技术水平（由三个LeNet-4网络的增强集成生成）。\n",
    "\n",
    "### References  \n",
    "### 参考文献\n",
    "\n",
    "- [1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, november 1998.  \n",
    "- [1] Y. LeCun, L. Bottou, Y. Bengio和P. Haffner. 基于梯度的学习应用于文档识别. IEEE会议录，1998年11月。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### 配置\n",
    "##########################\n",
    "\n",
    "# 超参数\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# 网络结构\n",
    "NUM_FEATURES = 32*32\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# 其他\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([128])\n",
      "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### CIFAR-10 数据集\n",
    "##########################\n",
    "\n",
    "\n",
    "# 注意 transforms.ToTensor() 会将输入图像缩放到 0-1 范围\n",
    "train_dataset = datasets.CIFAR10(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=transforms.ToTensor(),\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)\n",
    "\n",
    "# 检查数据集\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "# 再次检查数据集\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, grayscale=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if self.grayscale:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = 3\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels, 6*in_channels, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6*in_channels, 16*in_channels, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5*in_channels, 120*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120*in_channels, 84*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84*in_channels, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = LeNet5(NUM_CLASSES, GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0391 | Cost: 2.3115\n",
      "Epoch: 001/010 | Batch 0050/0391 | Cost: 1.7790\n",
      "Epoch: 001/010 | Batch 0100/0391 | Cost: 1.5894\n",
      "Epoch: 001/010 | Batch 0150/0391 | Cost: 1.5928\n",
      "Epoch: 001/010 | Batch 0200/0391 | Cost: 1.3675\n",
      "Epoch: 001/010 | Batch 0250/0391 | Cost: 1.4105\n",
      "Epoch: 001/010 | Batch 0300/0391 | Cost: 1.2797\n",
      "Epoch: 001/010 | Batch 0350/0391 | Cost: 1.6213\n",
      "Epoch: 001/010 | Train: 53.020%\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 002/010 | Batch 0000/0391 | Cost: 1.4377\n",
      "Epoch: 002/010 | Batch 0050/0391 | Cost: 1.1872\n",
      "Epoch: 002/010 | Batch 0100/0391 | Cost: 1.3558\n",
      "Epoch: 002/010 | Batch 0150/0391 | Cost: 1.1609\n",
      "Epoch: 002/010 | Batch 0200/0391 | Cost: 1.2661\n",
      "Epoch: 002/010 | Batch 0250/0391 | Cost: 1.0852\n",
      "Epoch: 002/010 | Batch 0300/0391 | Cost: 1.1308\n",
      "Epoch: 002/010 | Batch 0350/0391 | Cost: 1.2074\n",
      "Epoch: 002/010 | Train: 61.494%\n",
      "Time elapsed: 0.07 min\n",
      "Epoch: 003/010 | Batch 0000/0391 | Cost: 1.1985\n",
      "Epoch: 003/010 | Batch 0050/0391 | Cost: 1.1419\n",
      "Epoch: 003/010 | Batch 0100/0391 | Cost: 1.0835\n",
      "Epoch: 003/010 | Batch 0150/0391 | Cost: 1.0313\n",
      "Epoch: 003/010 | Batch 0200/0391 | Cost: 1.1616\n",
      "Epoch: 003/010 | Batch 0250/0391 | Cost: 1.2349\n",
      "Epoch: 003/010 | Batch 0300/0391 | Cost: 1.2135\n",
      "Epoch: 003/010 | Batch 0350/0391 | Cost: 1.0680\n",
      "Epoch: 003/010 | Train: 65.562%\n",
      "Time elapsed: 0.10 min\n",
      "Epoch: 004/010 | Batch 0000/0391 | Cost: 1.0098\n",
      "Epoch: 004/010 | Batch 0050/0391 | Cost: 1.0880\n",
      "Epoch: 004/010 | Batch 0100/0391 | Cost: 1.0108\n",
      "Epoch: 004/010 | Batch 0150/0391 | Cost: 0.9872\n",
      "Epoch: 004/010 | Batch 0200/0391 | Cost: 1.1697\n",
      "Epoch: 004/010 | Batch 0250/0391 | Cost: 1.0225\n",
      "Epoch: 004/010 | Batch 0300/0391 | Cost: 1.1987\n",
      "Epoch: 004/010 | Batch 0350/0391 | Cost: 0.9905\n",
      "Epoch: 004/010 | Train: 68.978%\n",
      "Time elapsed: 0.14 min\n",
      "Epoch: 005/010 | Batch 0000/0391 | Cost: 0.9057\n",
      "Epoch: 005/010 | Batch 0050/0391 | Cost: 1.0413\n",
      "Epoch: 005/010 | Batch 0100/0391 | Cost: 0.7706\n",
      "Epoch: 005/010 | Batch 0150/0391 | Cost: 0.8734\n",
      "Epoch: 005/010 | Batch 0200/0391 | Cost: 0.9264\n",
      "Epoch: 005/010 | Batch 0250/0391 | Cost: 0.8630\n",
      "Epoch: 005/010 | Batch 0300/0391 | Cost: 1.0110\n",
      "Epoch: 005/010 | Batch 0350/0391 | Cost: 0.7672\n",
      "Epoch: 005/010 | Train: 70.974%\n",
      "Time elapsed: 0.17 min\n",
      "Epoch: 006/010 | Batch 0000/0391 | Cost: 0.7854\n",
      "Epoch: 006/010 | Batch 0050/0391 | Cost: 0.8530\n",
      "Epoch: 006/010 | Batch 0100/0391 | Cost: 0.8142\n",
      "Epoch: 006/010 | Batch 0150/0391 | Cost: 0.8263\n",
      "Epoch: 006/010 | Batch 0200/0391 | Cost: 0.8903\n",
      "Epoch: 006/010 | Batch 0250/0391 | Cost: 0.7358\n",
      "Epoch: 006/010 | Batch 0300/0391 | Cost: 0.9713\n",
      "Epoch: 006/010 | Batch 0350/0391 | Cost: 0.9175\n",
      "Epoch: 006/010 | Train: 75.810%\n",
      "Time elapsed: 0.21 min\n",
      "Epoch: 007/010 | Batch 0000/0391 | Cost: 0.7327\n",
      "Epoch: 007/010 | Batch 0050/0391 | Cost: 0.8791\n",
      "Epoch: 007/010 | Batch 0100/0391 | Cost: 0.7074\n",
      "Epoch: 007/010 | Batch 0150/0391 | Cost: 0.6351\n",
      "Epoch: 007/010 | Batch 0200/0391 | Cost: 0.7750\n",
      "Epoch: 007/010 | Batch 0250/0391 | Cost: 0.8532\n",
      "Epoch: 007/010 | Batch 0300/0391 | Cost: 0.9084\n",
      "Epoch: 007/010 | Batch 0350/0391 | Cost: 0.8767\n",
      "Epoch: 007/010 | Train: 78.098%\n",
      "Time elapsed: 0.24 min\n",
      "Epoch: 008/010 | Batch 0000/0391 | Cost: 0.5904\n",
      "Epoch: 008/010 | Batch 0050/0391 | Cost: 0.6977\n",
      "Epoch: 008/010 | Batch 0100/0391 | Cost: 0.6162\n",
      "Epoch: 008/010 | Batch 0150/0391 | Cost: 0.5127\n",
      "Epoch: 008/010 | Batch 0200/0391 | Cost: 0.5330\n",
      "Epoch: 008/010 | Batch 0250/0391 | Cost: 0.8061\n",
      "Epoch: 008/010 | Batch 0300/0391 | Cost: 0.5337\n",
      "Epoch: 008/010 | Batch 0350/0391 | Cost: 0.6153\n",
      "Epoch: 008/010 | Train: 81.566%\n",
      "Time elapsed: 0.27 min\n",
      "Epoch: 009/010 | Batch 0000/0391 | Cost: 0.5887\n",
      "Epoch: 009/010 | Batch 0050/0391 | Cost: 0.4422\n",
      "Epoch: 009/010 | Batch 0100/0391 | Cost: 0.5942\n",
      "Epoch: 009/010 | Batch 0150/0391 | Cost: 0.6710\n",
      "Epoch: 009/010 | Batch 0200/0391 | Cost: 0.5255\n",
      "Epoch: 009/010 | Batch 0250/0391 | Cost: 0.5277\n",
      "Epoch: 009/010 | Batch 0300/0391 | Cost: 0.5393\n",
      "Epoch: 009/010 | Batch 0350/0391 | Cost: 0.6356\n",
      "Epoch: 009/010 | Train: 86.420%\n",
      "Time elapsed: 0.30 min\n",
      "Epoch: 010/010 | Batch 0000/0391 | Cost: 0.4451\n",
      "Epoch: 010/010 | Batch 0050/0391 | Cost: 0.4136\n",
      "Epoch: 010/010 | Batch 0100/0391 | Cost: 0.5279\n",
      "Epoch: 010/010 | Batch 0150/0391 | Cost: 0.4849\n",
      "Epoch: 010/010 | Batch 0200/0391 | Cost: 0.4163\n",
      "Epoch: 010/010 | Batch 0250/0391 | Cost: 0.6025\n",
      "Epoch: 010/010 | Batch 0300/0391 | Cost: 0.3649\n",
      "Epoch: 010/010 | Batch 0350/0391 | Cost: 0.5461\n",
      "Epoch: 010/010 | Train: 89.084%\n",
      "Time elapsed: 0.33 min\n",
      "Total Training Time: 0.33 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### 前向传播和反向传播\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### 日志记录\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # 在推理过程中禁用梯度计算，节省内存\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 66.81%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # 在推理过程中禁用梯度计算，节省内存\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL        : 11.1.0\n",
      "torchvision: 0.21.0+cu126\n",
      "matplotlib : 3.10.1\n",
      "numpy      : 1.26.4\n",
      "torch      : 2.6.0+cu126\n",
      "pandas     : 2.2.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
