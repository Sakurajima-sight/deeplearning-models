{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
    "- Author: Sebastian Raschka\n",
    "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 8.30.0\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# BatchNorm before and after Activation for Network-in-Network CIFAR-10 Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN architecture is based on  \n",
    "CNN架构是基于  \n",
    "\n",
    "- Lin, Min, Qiang Chen, and Shuicheng Yan. \"[Network in network](https://arxiv.org/abs/1312.4400).\" arXiv preprint arXiv:1312.4400 (2013).  \n",
    "- 林敏，陈强，颜水成。\"[网络中的网络](https://arxiv.org/abs/1312.4400)\"。arXiv预印本 arXiv:1312.4400（2013年）。\n",
    "\n",
    "This paper compares using BatchNorm before the activation function as suggested in  \n",
    "本文比较了在激活函数之前使用BatchNorm的做法，正如  \n",
    "\n",
    "- Ioffe, Sergey, and Christian Szegedy. \"[Batch normalization: Accelerating deep network training by reducing internal covariate shift.](https://arxiv.org/abs/1502.03167)\" arXiv preprint arXiv:1502.03167 (2015)  \n",
    "- Ioffe, Sergey 和 Christian Szegedy。\"[批量归一化：通过减少内部协变量偏移加速深度网络训练。](https://arxiv.org/abs/1502.03167)\" arXiv预印本 arXiv:1502.03167（2015年）\n",
    "\n",
    "and after the activation function as it is nowadays common practice.  \n",
    "以及现在通常做法中在激活函数之后使用的做法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.set_per_process_memory_fraction(0.3, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### 设置\n",
    "##########################\n",
    "\n",
    "# 超参数\n",
    "RANDOM_SEED = 1  # 随机种子\n",
    "LEARNING_RATE = 0.0005  # 学习率\n",
    "BATCH_SIZE = 256  # 批次大小\n",
    "NUM_EPOCHS = 100  # 训练轮数\n",
    "\n",
    "# 网络架构\n",
    "NUM_CLASSES = 10  # 分类类别数\n",
    "\n",
    "# 其他设置\n",
    "DEVICE = \"cuda:0\"  # 使用的设备\n",
    "GRAYSCALE = False  # 是否使用灰度图像（True 表示使用灰度图像，False 表示使用彩色图像）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像批次的维度: torch.Size([256, 3, 32, 32])\n",
      "训练集标签批次的维度: torch.Size([256])\n",
      "测试集图像批次的维度: torch.Size([256, 3, 32, 32])\n",
      "测试集标签批次的维度: torch.Size([256])\n",
      "验证集图像批次的维度: torch.Size([256, 3, 32, 32])\n",
      "验证集标签批次的维度: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### CIFAR-10 数据集\n",
    "##########################\n",
    "\n",
    "# 注意 transforms.ToTensor() 会将输入图像缩放到 0-1 范围内\n",
    "\n",
    "train_indices = torch.arange(0, 49000)  # 训练集的索引\n",
    "valid_indices = torch.arange(49000, 50000)  # 验证集的索引\n",
    "\n",
    "# 加载 CIFAR-10 数据集，train=True 表示训练集，transform=transforms.ToTensor() 将图像转为 Tensor 格式，下载数据集\n",
    "train_and_valid = datasets.CIFAR10(root='data', \n",
    "                                   train=True, \n",
    "                                   transform=transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "\n",
    "# 从 CIFAR-10 数据集中提取训练集和验证集\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "\n",
    "# 加载测试集，train=False 表示测试集，transform=transforms.ToTensor() 将图像转为 Tensor 格式\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "#####################################################\n",
    "### 数据加载器\n",
    "#####################################################\n",
    "\n",
    "# 创建训练数据加载器，batch_size 为批次大小，num_workers 设置为 8 表示使用 8 个子进程加载数据，shuffle=True 表示打乱数据\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "# 创建验证数据加载器，shuffle=False 表示不打乱验证集数据\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          shuffle=False)\n",
    "\n",
    "# 创建测试数据加载器，shuffle=False 表示不打乱测试集数据\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "# 检查数据集的形状\n",
    "for images, labels in train_loader:  \n",
    "    print('训练集图像批次的维度:', images.shape)  # 输出训练集图像的维度\n",
    "    print('训练集标签批次的维度:', labels.shape)  # 输出训练集标签的维度\n",
    "    break\n",
    "\n",
    "for images, labels in test_loader:  \n",
    "    print('测试集图像批次的维度:', images.shape)  # 输出测试集图像的维度\n",
    "    print('测试集标签批次的维度:', labels.shape)  # 输出测试集标签的维度\n",
    "    break\n",
    "    \n",
    "for images, labels in valid_loader:  \n",
    "    print('验证集图像批次的维度:', images.shape)  # 输出验证集图像的维度\n",
    "    print('验证集标签批次的维度:', labels.shape)  # 输出验证集标签的维度\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "class NiN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NiN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # 定义网络的分类器部分\n",
    "        self.classifier = nn.Sequential(\n",
    "                # 第一层卷积层：输入通道为 3，输出通道为 192，卷积核大小为 5，步幅为 1，padding 为 2\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第二层卷积层：输入通道为 192，输出通道为 160，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第三层卷积层：输入通道为 160，输出通道为 96，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 最大池化层：卷积后的输出通过最大池化层进行下采样，卷积核大小为 3，步幅为 2，padding 为 1\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                \n",
    "                # Dropout 层：在训练时随机丢弃部分神经元，防止过拟合\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                # 第四层卷积层：输入通道为 96，输出通道为 192，卷积核大小为 5，步幅为 1，padding 为 2\n",
    "                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第五层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第六层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 平均池化层：卷积后的输出通过平均池化层进行下采样，卷积核大小为 3，步幅为 2，padding 为 1\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                \n",
    "                # Dropout 层：在训练时随机丢弃部分神经元，防止过拟合\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                # 第七层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 3，步幅为 1，padding 为 1\n",
    "                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第八层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第九层卷积层：输入通道为 192，输出通道为 10，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 平均池化层：卷积后的输出通过平均池化层进行下采样，卷积核大小为 8，步幅为 1，padding 为 0\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播过程\n",
    "        x = self.classifier(x)  # 通过分类器进行计算\n",
    "        logits = x.view(x.size(0), self.num_classes)  # 将输出展平，形状为 [batch_size, num_classes]\n",
    "        probas = torch.softmax(logits, dim=1)  # 使用 softmax 激活函数获得每个类的概率分布\n",
    "        return logits, probas  # 返回 logits 和概率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = NiN(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100 | Batch 000/192 | Cost: 2.3041\n",
      "Epoch: 001/100 | Batch 120/192 | Cost: 2.1455\n",
      "Epoch: 001/100 Train Acc.: 23.27% | Validation Acc.: 23.80%\n",
      "Time elapsed: 0.69 min\n",
      "Epoch: 002/100 | Batch 000/192 | Cost: 2.1072\n",
      "Epoch: 002/100 | Batch 120/192 | Cost: 2.0444\n",
      "Epoch: 002/100 Train Acc.: 28.35% | Validation Acc.: 30.60%\n",
      "Time elapsed: 1.39 min\n",
      "Epoch: 003/100 | Batch 000/192 | Cost: 2.0100\n",
      "Epoch: 003/100 | Batch 120/192 | Cost: 1.9320\n",
      "Epoch: 003/100 Train Acc.: 33.56% | Validation Acc.: 34.40%\n",
      "Time elapsed: 2.08 min\n",
      "Epoch: 004/100 | Batch 000/192 | Cost: 1.9790\n",
      "Epoch: 004/100 | Batch 120/192 | Cost: 1.9554\n",
      "Epoch: 004/100 Train Acc.: 36.74% | Validation Acc.: 39.00%\n",
      "Time elapsed: 2.76 min\n",
      "Epoch: 005/100 | Batch 000/192 | Cost: 1.9385\n",
      "Epoch: 005/100 | Batch 120/192 | Cost: 1.8509\n",
      "Epoch: 005/100 Train Acc.: 37.33% | Validation Acc.: 39.40%\n",
      "Time elapsed: 3.45 min\n",
      "Epoch: 006/100 | Batch 000/192 | Cost: 1.8317\n",
      "Epoch: 006/100 | Batch 120/192 | Cost: 1.8104\n",
      "Epoch: 006/100 Train Acc.: 39.69% | Validation Acc.: 42.90%\n",
      "Time elapsed: 4.14 min\n",
      "Epoch: 007/100 | Batch 000/192 | Cost: 1.9095\n",
      "Epoch: 007/100 | Batch 120/192 | Cost: 1.7852\n",
      "Epoch: 007/100 Train Acc.: 39.75% | Validation Acc.: 42.20%\n",
      "Time elapsed: 4.82 min\n",
      "Epoch: 008/100 | Batch 000/192 | Cost: 1.8945\n",
      "Epoch: 008/100 | Batch 120/192 | Cost: 1.7055\n",
      "Epoch: 008/100 Train Acc.: 41.52% | Validation Acc.: 41.70%\n",
      "Time elapsed: 5.51 min\n",
      "Epoch: 009/100 | Batch 000/192 | Cost: 1.7510\n",
      "Epoch: 009/100 | Batch 120/192 | Cost: 1.6175\n",
      "Epoch: 009/100 Train Acc.: 43.06% | Validation Acc.: 45.40%\n",
      "Time elapsed: 6.19 min\n",
      "Epoch: 010/100 | Batch 000/192 | Cost: 1.7227\n",
      "Epoch: 010/100 | Batch 120/192 | Cost: 1.6277\n",
      "Epoch: 010/100 Train Acc.: 43.60% | Validation Acc.: 44.50%\n",
      "Time elapsed: 6.88 min\n",
      "Epoch: 011/100 | Batch 000/192 | Cost: 1.6823\n",
      "Epoch: 011/100 | Batch 120/192 | Cost: 1.5329\n",
      "Epoch: 011/100 Train Acc.: 44.84% | Validation Acc.: 45.80%\n",
      "Time elapsed: 7.57 min\n",
      "Epoch: 012/100 | Batch 000/192 | Cost: 1.6123\n",
      "Epoch: 012/100 | Batch 120/192 | Cost: 1.6634\n",
      "Epoch: 012/100 Train Acc.: 44.46% | Validation Acc.: 44.90%\n",
      "Time elapsed: 8.26 min\n",
      "Epoch: 013/100 | Batch 000/192 | Cost: 1.6178\n",
      "Epoch: 013/100 | Batch 120/192 | Cost: 1.5359\n",
      "Epoch: 013/100 Train Acc.: 45.35% | Validation Acc.: 46.50%\n",
      "Time elapsed: 8.95 min\n",
      "Epoch: 014/100 | Batch 000/192 | Cost: 1.5182\n",
      "Epoch: 014/100 | Batch 120/192 | Cost: 1.6210\n",
      "Epoch: 014/100 Train Acc.: 45.86% | Validation Acc.: 46.00%\n",
      "Time elapsed: 9.63 min\n",
      "Epoch: 015/100 | Batch 000/192 | Cost: 1.7737\n",
      "Epoch: 015/100 | Batch 120/192 | Cost: 1.5129\n",
      "Epoch: 015/100 Train Acc.: 47.55% | Validation Acc.: 46.60%\n",
      "Time elapsed: 10.32 min\n",
      "Epoch: 016/100 | Batch 000/192 | Cost: 1.7322\n",
      "Epoch: 016/100 | Batch 120/192 | Cost: 1.7108\n",
      "Epoch: 016/100 Train Acc.: 47.32% | Validation Acc.: 47.70%\n",
      "Time elapsed: 11.01 min\n",
      "Epoch: 017/100 | Batch 000/192 | Cost: 1.5538\n",
      "Epoch: 017/100 | Batch 120/192 | Cost: 1.5483\n",
      "Epoch: 017/100 Train Acc.: 47.23% | Validation Acc.: 47.60%\n",
      "Time elapsed: 11.69 min\n",
      "Epoch: 018/100 | Batch 000/192 | Cost: 1.5569\n",
      "Epoch: 018/100 | Batch 120/192 | Cost: 1.5423\n",
      "Epoch: 018/100 Train Acc.: 48.26% | Validation Acc.: 48.40%\n",
      "Time elapsed: 12.38 min\n",
      "Epoch: 019/100 | Batch 000/192 | Cost: 1.4579\n",
      "Epoch: 019/100 | Batch 120/192 | Cost: 1.5396\n",
      "Epoch: 019/100 Train Acc.: 48.25% | Validation Acc.: 48.90%\n",
      "Time elapsed: 13.07 min\n",
      "Epoch: 020/100 | Batch 000/192 | Cost: 1.5178\n",
      "Epoch: 020/100 | Batch 120/192 | Cost: 1.5450\n",
      "Epoch: 020/100 Train Acc.: 48.40% | Validation Acc.: 47.80%\n",
      "Time elapsed: 13.75 min\n",
      "Epoch: 021/100 | Batch 000/192 | Cost: 1.4782\n",
      "Epoch: 021/100 | Batch 120/192 | Cost: 1.5676\n",
      "Epoch: 021/100 Train Acc.: 49.05% | Validation Acc.: 49.00%\n",
      "Time elapsed: 14.44 min\n",
      "Epoch: 022/100 | Batch 000/192 | Cost: 1.5090\n",
      "Epoch: 022/100 | Batch 120/192 | Cost: 1.5572\n",
      "Epoch: 022/100 Train Acc.: 49.73% | Validation Acc.: 49.20%\n",
      "Time elapsed: 15.13 min\n",
      "Epoch: 023/100 | Batch 000/192 | Cost: 1.4394\n",
      "Epoch: 023/100 | Batch 120/192 | Cost: 1.4403\n",
      "Epoch: 023/100 Train Acc.: 49.37% | Validation Acc.: 49.10%\n",
      "Time elapsed: 15.82 min\n",
      "Epoch: 024/100 | Batch 000/192 | Cost: 1.5426\n",
      "Epoch: 024/100 | Batch 120/192 | Cost: 1.6438\n",
      "Epoch: 024/100 Train Acc.: 50.13% | Validation Acc.: 48.20%\n",
      "Time elapsed: 16.51 min\n",
      "Epoch: 025/100 | Batch 000/192 | Cost: 1.3654\n",
      "Epoch: 025/100 | Batch 120/192 | Cost: 1.4735\n",
      "Epoch: 025/100 Train Acc.: 49.50% | Validation Acc.: 48.90%\n",
      "Time elapsed: 17.19 min\n",
      "Epoch: 026/100 | Batch 000/192 | Cost: 1.4877\n",
      "Epoch: 026/100 | Batch 120/192 | Cost: 1.3903\n",
      "Epoch: 026/100 Train Acc.: 50.67% | Validation Acc.: 48.70%\n",
      "Time elapsed: 17.88 min\n",
      "Epoch: 027/100 | Batch 000/192 | Cost: 1.4905\n",
      "Epoch: 027/100 | Batch 120/192 | Cost: 1.3236\n",
      "Epoch: 027/100 Train Acc.: 50.46% | Validation Acc.: 50.30%\n",
      "Time elapsed: 18.57 min\n",
      "Epoch: 028/100 | Batch 000/192 | Cost: 1.3345\n",
      "Epoch: 028/100 | Batch 120/192 | Cost: 1.5557\n",
      "Epoch: 028/100 Train Acc.: 50.44% | Validation Acc.: 48.00%\n",
      "Time elapsed: 19.25 min\n",
      "Epoch: 029/100 | Batch 000/192 | Cost: 1.3919\n",
      "Epoch: 029/100 | Batch 120/192 | Cost: 1.4221\n",
      "Epoch: 029/100 Train Acc.: 50.36% | Validation Acc.: 48.70%\n",
      "Time elapsed: 19.94 min\n",
      "Epoch: 030/100 | Batch 000/192 | Cost: 1.4781\n",
      "Epoch: 030/100 | Batch 120/192 | Cost: 1.4233\n",
      "Epoch: 030/100 Train Acc.: 50.76% | Validation Acc.: 49.40%\n",
      "Time elapsed: 20.63 min\n",
      "Epoch: 031/100 | Batch 000/192 | Cost: 1.4378\n",
      "Epoch: 031/100 | Batch 120/192 | Cost: 1.3639\n",
      "Epoch: 031/100 Train Acc.: 51.56% | Validation Acc.: 50.00%\n",
      "Time elapsed: 21.32 min\n",
      "Epoch: 032/100 | Batch 000/192 | Cost: 1.3472\n",
      "Epoch: 032/100 | Batch 120/192 | Cost: 1.4499\n",
      "Epoch: 032/100 Train Acc.: 51.80% | Validation Acc.: 50.20%\n",
      "Time elapsed: 22.01 min\n",
      "Epoch: 033/100 | Batch 000/192 | Cost: 1.3640\n",
      "Epoch: 033/100 | Batch 120/192 | Cost: 1.2838\n",
      "Epoch: 033/100 Train Acc.: 52.16% | Validation Acc.: 51.30%\n",
      "Time elapsed: 22.69 min\n",
      "Epoch: 034/100 | Batch 000/192 | Cost: 1.4522\n",
      "Epoch: 034/100 | Batch 120/192 | Cost: 1.4068\n",
      "Epoch: 034/100 Train Acc.: 52.55% | Validation Acc.: 50.80%\n",
      "Time elapsed: 23.38 min\n",
      "Epoch: 035/100 | Batch 000/192 | Cost: 1.3660\n",
      "Epoch: 035/100 | Batch 120/192 | Cost: 1.3310\n",
      "Epoch: 035/100 Train Acc.: 51.43% | Validation Acc.: 50.50%\n",
      "Time elapsed: 24.07 min\n",
      "Epoch: 036/100 | Batch 000/192 | Cost: 1.4489\n",
      "Epoch: 036/100 | Batch 120/192 | Cost: 1.3789\n",
      "Epoch: 036/100 Train Acc.: 51.50% | Validation Acc.: 50.00%\n",
      "Time elapsed: 24.75 min\n",
      "Epoch: 037/100 | Batch 000/192 | Cost: 1.2886\n",
      "Epoch: 037/100 | Batch 120/192 | Cost: 1.2137\n",
      "Epoch: 037/100 Train Acc.: 52.65% | Validation Acc.: 51.40%\n",
      "Time elapsed: 25.44 min\n",
      "Epoch: 038/100 | Batch 000/192 | Cost: 1.2273\n",
      "Epoch: 038/100 | Batch 120/192 | Cost: 1.3515\n",
      "Epoch: 038/100 Train Acc.: 52.38% | Validation Acc.: 50.70%\n",
      "Time elapsed: 26.12 min\n",
      "Epoch: 039/100 | Batch 000/192 | Cost: 1.3905\n",
      "Epoch: 039/100 | Batch 120/192 | Cost: 1.3764\n",
      "Epoch: 039/100 Train Acc.: 53.12% | Validation Acc.: 52.00%\n",
      "Time elapsed: 26.81 min\n",
      "Epoch: 040/100 | Batch 000/192 | Cost: 1.4032\n",
      "Epoch: 040/100 | Batch 120/192 | Cost: 1.2904\n",
      "Epoch: 040/100 Train Acc.: 52.87% | Validation Acc.: 51.40%\n",
      "Time elapsed: 27.50 min\n",
      "Epoch: 041/100 | Batch 000/192 | Cost: 1.2923\n",
      "Epoch: 041/100 | Batch 120/192 | Cost: 1.3308\n",
      "Epoch: 041/100 Train Acc.: 53.12% | Validation Acc.: 51.20%\n",
      "Time elapsed: 28.19 min\n",
      "Epoch: 042/100 | Batch 000/192 | Cost: 1.2213\n",
      "Epoch: 042/100 | Batch 120/192 | Cost: 1.1304\n",
      "Epoch: 042/100 Train Acc.: 53.54% | Validation Acc.: 50.70%\n",
      "Time elapsed: 28.88 min\n",
      "Epoch: 043/100 | Batch 000/192 | Cost: 1.4206\n",
      "Epoch: 043/100 | Batch 120/192 | Cost: 1.2797\n",
      "Epoch: 043/100 Train Acc.: 53.64% | Validation Acc.: 50.40%\n",
      "Time elapsed: 29.56 min\n",
      "Epoch: 044/100 | Batch 000/192 | Cost: 1.3518\n",
      "Epoch: 044/100 | Batch 120/192 | Cost: 1.2296\n",
      "Epoch: 044/100 Train Acc.: 53.99% | Validation Acc.: 51.50%\n",
      "Time elapsed: 30.25 min\n",
      "Epoch: 045/100 | Batch 000/192 | Cost: 1.2444\n",
      "Epoch: 045/100 | Batch 120/192 | Cost: 1.2529\n",
      "Epoch: 045/100 Train Acc.: 54.10% | Validation Acc.: 51.40%\n",
      "Time elapsed: 30.94 min\n",
      "Epoch: 046/100 | Batch 000/192 | Cost: 1.2657\n",
      "Epoch: 046/100 | Batch 120/192 | Cost: 1.3066\n",
      "Epoch: 046/100 Train Acc.: 54.40% | Validation Acc.: 52.90%\n",
      "Time elapsed: 31.62 min\n",
      "Epoch: 047/100 | Batch 000/192 | Cost: 1.2320\n",
      "Epoch: 047/100 | Batch 120/192 | Cost: 1.4888\n",
      "Epoch: 047/100 Train Acc.: 52.72% | Validation Acc.: 49.50%\n",
      "Time elapsed: 32.31 min\n",
      "Epoch: 048/100 | Batch 000/192 | Cost: 1.2613\n",
      "Epoch: 048/100 | Batch 120/192 | Cost: 1.2502\n",
      "Epoch: 048/100 Train Acc.: 54.46% | Validation Acc.: 51.20%\n",
      "Time elapsed: 33.00 min\n",
      "Epoch: 049/100 | Batch 000/192 | Cost: 1.2742\n",
      "Epoch: 049/100 | Batch 120/192 | Cost: 1.2886\n",
      "Epoch: 049/100 Train Acc.: 54.47% | Validation Acc.: 52.10%\n",
      "Time elapsed: 33.68 min\n",
      "Epoch: 050/100 | Batch 000/192 | Cost: 1.2729\n",
      "Epoch: 050/100 | Batch 120/192 | Cost: 1.2522\n",
      "Epoch: 050/100 Train Acc.: 54.78% | Validation Acc.: 52.30%\n",
      "Time elapsed: 34.37 min\n",
      "Epoch: 051/100 | Batch 000/192 | Cost: 1.2534\n",
      "Epoch: 051/100 | Batch 120/192 | Cost: 1.2861\n",
      "Epoch: 051/100 Train Acc.: 54.93% | Validation Acc.: 52.40%\n",
      "Time elapsed: 35.06 min\n",
      "Epoch: 052/100 | Batch 000/192 | Cost: 1.3173\n",
      "Epoch: 052/100 | Batch 120/192 | Cost: 1.3006\n",
      "Epoch: 052/100 Train Acc.: 54.10% | Validation Acc.: 51.40%\n",
      "Time elapsed: 35.74 min\n",
      "Epoch: 053/100 | Batch 000/192 | Cost: 1.3331\n",
      "Epoch: 053/100 | Batch 120/192 | Cost: 1.1745\n",
      "Epoch: 053/100 Train Acc.: 54.91% | Validation Acc.: 51.70%\n",
      "Time elapsed: 36.43 min\n",
      "Epoch: 054/100 | Batch 000/192 | Cost: 1.2526\n",
      "Epoch: 054/100 | Batch 120/192 | Cost: 1.3622\n",
      "Epoch: 054/100 Train Acc.: 54.75% | Validation Acc.: 51.30%\n",
      "Time elapsed: 37.12 min\n",
      "Epoch: 055/100 | Batch 000/192 | Cost: 1.3133\n",
      "Epoch: 055/100 | Batch 120/192 | Cost: 1.3588\n",
      "Epoch: 055/100 Train Acc.: 54.87% | Validation Acc.: 51.10%\n",
      "Time elapsed: 37.81 min\n",
      "Epoch: 056/100 | Batch 000/192 | Cost: 1.3668\n",
      "Epoch: 056/100 | Batch 120/192 | Cost: 1.2235\n",
      "Epoch: 056/100 Train Acc.: 55.22% | Validation Acc.: 51.70%\n",
      "Time elapsed: 38.50 min\n",
      "Epoch: 057/100 | Batch 000/192 | Cost: 1.2594\n",
      "Epoch: 057/100 | Batch 120/192 | Cost: 1.1859\n",
      "Epoch: 057/100 Train Acc.: 55.49% | Validation Acc.: 51.80%\n",
      "Time elapsed: 39.18 min\n",
      "Epoch: 058/100 | Batch 000/192 | Cost: 1.1861\n",
      "Epoch: 058/100 | Batch 120/192 | Cost: 1.1048\n",
      "Epoch: 058/100 Train Acc.: 54.85% | Validation Acc.: 51.70%\n",
      "Time elapsed: 39.87 min\n",
      "Epoch: 059/100 | Batch 000/192 | Cost: 1.1739\n",
      "Epoch: 059/100 | Batch 120/192 | Cost: 1.3442\n",
      "Epoch: 059/100 Train Acc.: 55.34% | Validation Acc.: 51.10%\n",
      "Time elapsed: 40.55 min\n",
      "Epoch: 060/100 | Batch 000/192 | Cost: 1.1542\n",
      "Epoch: 060/100 | Batch 120/192 | Cost: 1.3044\n",
      "Epoch: 060/100 Train Acc.: 55.42% | Validation Acc.: 52.10%\n",
      "Time elapsed: 41.24 min\n",
      "Epoch: 061/100 | Batch 000/192 | Cost: 1.2380\n",
      "Epoch: 061/100 | Batch 120/192 | Cost: 1.2878\n",
      "Epoch: 061/100 Train Acc.: 55.73% | Validation Acc.: 52.30%\n",
      "Time elapsed: 41.93 min\n",
      "Epoch: 062/100 | Batch 000/192 | Cost: 1.1496\n",
      "Epoch: 062/100 | Batch 120/192 | Cost: 1.1683\n",
      "Epoch: 062/100 Train Acc.: 55.75% | Validation Acc.: 52.10%\n",
      "Time elapsed: 42.62 min\n",
      "Epoch: 063/100 | Batch 000/192 | Cost: 1.2187\n",
      "Epoch: 063/100 | Batch 120/192 | Cost: 1.1926\n",
      "Epoch: 063/100 Train Acc.: 55.42% | Validation Acc.: 50.90%\n",
      "Time elapsed: 43.30 min\n",
      "Epoch: 064/100 | Batch 000/192 | Cost: 1.1361\n",
      "Epoch: 064/100 | Batch 120/192 | Cost: 1.2035\n",
      "Epoch: 064/100 Train Acc.: 55.96% | Validation Acc.: 51.10%\n",
      "Time elapsed: 43.99 min\n",
      "Epoch: 065/100 | Batch 000/192 | Cost: 1.1166\n",
      "Epoch: 065/100 | Batch 120/192 | Cost: 1.2105\n",
      "Epoch: 065/100 Train Acc.: 56.19% | Validation Acc.: 52.10%\n",
      "Time elapsed: 44.68 min\n",
      "Epoch: 066/100 | Batch 000/192 | Cost: 1.0981\n",
      "Epoch: 066/100 | Batch 120/192 | Cost: 1.1886\n",
      "Epoch: 066/100 Train Acc.: 56.29% | Validation Acc.: 52.30%\n",
      "Time elapsed: 45.37 min\n",
      "Epoch: 067/100 | Batch 000/192 | Cost: 1.0785\n",
      "Epoch: 067/100 | Batch 120/192 | Cost: 1.1128\n",
      "Epoch: 067/100 Train Acc.: 55.86% | Validation Acc.: 49.80%\n",
      "Time elapsed: 46.05 min\n",
      "Epoch: 068/100 | Batch 000/192 | Cost: 1.1233\n",
      "Epoch: 068/100 | Batch 120/192 | Cost: 1.1195\n",
      "Epoch: 068/100 Train Acc.: 56.31% | Validation Acc.: 52.90%\n",
      "Time elapsed: 46.74 min\n",
      "Epoch: 069/100 | Batch 000/192 | Cost: 1.2083\n",
      "Epoch: 069/100 | Batch 120/192 | Cost: 1.1423\n",
      "Epoch: 069/100 Train Acc.: 56.56% | Validation Acc.: 52.40%\n",
      "Time elapsed: 47.43 min\n",
      "Epoch: 070/100 | Batch 000/192 | Cost: 1.1390\n",
      "Epoch: 070/100 | Batch 120/192 | Cost: 1.2640\n",
      "Epoch: 070/100 Train Acc.: 56.39% | Validation Acc.: 52.20%\n",
      "Time elapsed: 48.11 min\n",
      "Epoch: 071/100 | Batch 000/192 | Cost: 1.1672\n",
      "Epoch: 071/100 | Batch 120/192 | Cost: 1.1611\n",
      "Epoch: 071/100 Train Acc.: 56.45% | Validation Acc.: 51.50%\n",
      "Time elapsed: 48.80 min\n",
      "Epoch: 072/100 | Batch 000/192 | Cost: 1.1020\n",
      "Epoch: 072/100 | Batch 120/192 | Cost: 1.2255\n",
      "Epoch: 072/100 Train Acc.: 56.65% | Validation Acc.: 52.70%\n",
      "Time elapsed: 49.49 min\n",
      "Epoch: 073/100 | Batch 000/192 | Cost: 1.0892\n",
      "Epoch: 073/100 | Batch 120/192 | Cost: 1.0811\n",
      "Epoch: 073/100 Train Acc.: 56.68% | Validation Acc.: 52.30%\n",
      "Time elapsed: 50.18 min\n",
      "Epoch: 074/100 | Batch 000/192 | Cost: 1.3432\n",
      "Epoch: 074/100 | Batch 120/192 | Cost: 1.1573\n",
      "Epoch: 074/100 Train Acc.: 55.08% | Validation Acc.: 49.40%\n",
      "Time elapsed: 50.87 min\n",
      "Epoch: 075/100 | Batch 000/192 | Cost: 1.1745\n",
      "Epoch: 075/100 | Batch 120/192 | Cost: 1.1693\n",
      "Epoch: 075/100 Train Acc.: 55.98% | Validation Acc.: 50.60%\n",
      "Time elapsed: 51.55 min\n",
      "Epoch: 076/100 | Batch 000/192 | Cost: 1.1414\n",
      "Epoch: 076/100 | Batch 120/192 | Cost: 1.1436\n",
      "Epoch: 076/100 Train Acc.: 56.49% | Validation Acc.: 52.40%\n",
      "Time elapsed: 52.24 min\n",
      "Epoch: 077/100 | Batch 000/192 | Cost: 1.1934\n",
      "Epoch: 077/100 | Batch 120/192 | Cost: 1.1312\n",
      "Epoch: 077/100 Train Acc.: 56.73% | Validation Acc.: 51.90%\n",
      "Time elapsed: 52.93 min\n",
      "Epoch: 078/100 | Batch 000/192 | Cost: 1.1385\n",
      "Epoch: 078/100 | Batch 120/192 | Cost: 1.0715\n",
      "Epoch: 078/100 Train Acc.: 56.53% | Validation Acc.: 51.20%\n",
      "Time elapsed: 53.61 min\n",
      "Epoch: 079/100 | Batch 000/192 | Cost: 1.1026\n",
      "Epoch: 079/100 | Batch 120/192 | Cost: 1.2461\n",
      "Epoch: 079/100 Train Acc.: 56.53% | Validation Acc.: 52.50%\n",
      "Time elapsed: 54.30 min\n",
      "Epoch: 080/100 | Batch 000/192 | Cost: 1.3168\n",
      "Epoch: 080/100 | Batch 120/192 | Cost: 1.0846\n",
      "Epoch: 080/100 Train Acc.: 56.78% | Validation Acc.: 51.70%\n",
      "Time elapsed: 54.98 min\n",
      "Epoch: 081/100 | Batch 000/192 | Cost: 1.1684\n",
      "Epoch: 081/100 | Batch 120/192 | Cost: 1.0222\n",
      "Epoch: 081/100 Train Acc.: 56.39% | Validation Acc.: 51.70%\n",
      "Time elapsed: 55.67 min\n",
      "Epoch: 082/100 | Batch 000/192 | Cost: 1.1617\n",
      "Epoch: 082/100 | Batch 120/192 | Cost: 1.2250\n",
      "Epoch: 082/100 Train Acc.: 56.99% | Validation Acc.: 51.40%\n",
      "Time elapsed: 56.36 min\n",
      "Epoch: 083/100 | Batch 000/192 | Cost: 1.1555\n",
      "Epoch: 083/100 | Batch 120/192 | Cost: 1.1152\n",
      "Epoch: 083/100 Train Acc.: 57.19% | Validation Acc.: 51.50%\n",
      "Time elapsed: 57.04 min\n",
      "Epoch: 084/100 | Batch 000/192 | Cost: 1.1182\n",
      "Epoch: 084/100 | Batch 120/192 | Cost: 1.0643\n",
      "Epoch: 084/100 Train Acc.: 56.71% | Validation Acc.: 51.80%\n",
      "Time elapsed: 57.73 min\n",
      "Epoch: 085/100 | Batch 000/192 | Cost: 1.2132\n",
      "Epoch: 085/100 | Batch 120/192 | Cost: 1.0953\n",
      "Epoch: 085/100 Train Acc.: 56.96% | Validation Acc.: 51.60%\n",
      "Time elapsed: 58.42 min\n",
      "Epoch: 086/100 | Batch 000/192 | Cost: 1.1115\n",
      "Epoch: 086/100 | Batch 120/192 | Cost: 1.0187\n",
      "Epoch: 086/100 Train Acc.: 57.24% | Validation Acc.: 52.40%\n",
      "Time elapsed: 59.11 min\n",
      "Epoch: 087/100 | Batch 000/192 | Cost: 1.1224\n",
      "Epoch: 087/100 | Batch 120/192 | Cost: 1.2185\n",
      "Epoch: 087/100 Train Acc.: 56.72% | Validation Acc.: 51.10%\n",
      "Time elapsed: 59.80 min\n",
      "Epoch: 088/100 | Batch 000/192 | Cost: 1.0191\n",
      "Epoch: 088/100 | Batch 120/192 | Cost: 1.0906\n",
      "Epoch: 088/100 Train Acc.: 57.15% | Validation Acc.: 51.10%\n",
      "Time elapsed: 60.48 min\n",
      "Epoch: 089/100 | Batch 000/192 | Cost: 1.0994\n",
      "Epoch: 089/100 | Batch 120/192 | Cost: 1.1327\n",
      "Epoch: 089/100 Train Acc.: 56.81% | Validation Acc.: 50.40%\n",
      "Time elapsed: 61.17 min\n",
      "Epoch: 090/100 | Batch 000/192 | Cost: 1.0435\n",
      "Epoch: 090/100 | Batch 120/192 | Cost: 1.0819\n",
      "Epoch: 090/100 Train Acc.: 57.28% | Validation Acc.: 51.00%\n",
      "Time elapsed: 61.86 min\n",
      "Epoch: 091/100 | Batch 000/192 | Cost: 0.9963\n",
      "Epoch: 091/100 | Batch 120/192 | Cost: 1.0446\n",
      "Epoch: 091/100 Train Acc.: 57.14% | Validation Acc.: 51.80%\n",
      "Time elapsed: 62.54 min\n",
      "Epoch: 092/100 | Batch 000/192 | Cost: 1.1563\n",
      "Epoch: 092/100 | Batch 120/192 | Cost: 1.1555\n",
      "Epoch: 092/100 Train Acc.: 57.54% | Validation Acc.: 52.20%\n",
      "Time elapsed: 63.23 min\n",
      "Epoch: 093/100 | Batch 000/192 | Cost: 1.1692\n",
      "Epoch: 093/100 | Batch 120/192 | Cost: 1.1148\n",
      "Epoch: 093/100 Train Acc.: 57.22% | Validation Acc.: 51.20%\n",
      "Time elapsed: 63.92 min\n",
      "Epoch: 094/100 | Batch 000/192 | Cost: 1.1867\n",
      "Epoch: 094/100 | Batch 120/192 | Cost: 1.0234\n",
      "Epoch: 094/100 Train Acc.: 57.39% | Validation Acc.: 52.20%\n",
      "Time elapsed: 64.60 min\n",
      "Epoch: 095/100 | Batch 000/192 | Cost: 1.2886\n",
      "Epoch: 095/100 | Batch 120/192 | Cost: 0.9822\n",
      "Epoch: 095/100 Train Acc.: 57.54% | Validation Acc.: 51.10%\n",
      "Time elapsed: 65.29 min\n",
      "Epoch: 096/100 | Batch 000/192 | Cost: 1.1160\n",
      "Epoch: 096/100 | Batch 120/192 | Cost: 1.1037\n",
      "Epoch: 096/100 Train Acc.: 56.81% | Validation Acc.: 51.10%\n",
      "Time elapsed: 65.98 min\n",
      "Epoch: 097/100 | Batch 000/192 | Cost: 1.0804\n",
      "Epoch: 097/100 | Batch 120/192 | Cost: 1.1405\n",
      "Epoch: 097/100 Train Acc.: 57.70% | Validation Acc.: 52.20%\n",
      "Time elapsed: 66.67 min\n",
      "Epoch: 098/100 | Batch 000/192 | Cost: 1.0924\n",
      "Epoch: 098/100 | Batch 120/192 | Cost: 1.1486\n",
      "Epoch: 098/100 Train Acc.: 57.15% | Validation Acc.: 51.50%\n",
      "Time elapsed: 67.35 min\n",
      "Epoch: 099/100 | Batch 000/192 | Cost: 1.1529\n",
      "Epoch: 099/100 | Batch 120/192 | Cost: 1.0167\n",
      "Epoch: 099/100 Train Acc.: 57.31% | Validation Acc.: 52.10%\n",
      "Time elapsed: 68.04 min\n",
      "Epoch: 100/100 | Batch 000/192 | Cost: 1.1769\n",
      "Epoch: 100/100 | Batch 120/192 | Cost: 1.1572\n",
      "Epoch: 100/100 Train Acc.: 57.53% | Validation Acc.: 50.60%\n",
      "Time elapsed: 68.73 min\n",
      "Total Training Time: 68.73 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)  # 将特征转移到指定设备\n",
    "        targets = targets.to(device)  # 将目标标签转移到指定设备\n",
    "\n",
    "        logits, probas = model(features)  # 前向传播，获取输出的logits和概率\n",
    "        _, predicted_labels = torch.max(probas, 1)  # 获取最大概率的标签\n",
    "        num_examples += targets.size(0)  # 更新总样本数\n",
    "        correct_pred += (predicted_labels == targets).sum()  # 统计预测正确的样本数\n",
    "    return correct_pred.float()/num_examples * 100  # 返回准确率（百分比）\n",
    "\n",
    "\n",
    "start_time = time.time()  # 记录开始时间\n",
    "for epoch in range(NUM_EPOCHS):  # 循环遍历每个epoch\n",
    "    \n",
    "    model.train()  # 设置模型为训练模式\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):  # 循环遍历每个批次\n",
    "    \n",
    "        ### 准备小批量数据\n",
    "        features = features.to(DEVICE)  # 将特征转移到指定设备\n",
    "        targets = targets.to(DEVICE)  # 将目标标签转移到指定设备\n",
    "            \n",
    "        ### 前向传播和反向传播\n",
    "        logits, probas = model(features)  # 获取模型的输出\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        \n",
    "        cost.backward()  # 反向传播计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()  # 使用优化器更新参数\n",
    "        \n",
    "        ### 日志记录\n",
    "        if not batch_idx % 120:  # 每120个批次输出一次日志\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # 计算准确率时不需要构建计算图以进行反向传播\n",
    "    with torch.set_grad_enabled(False):  # 禁用梯度计算\n",
    "        train_acc = compute_accuracy(model, train_loader, device=DEVICE)  # 计算训练集准确率\n",
    "        valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)  # 计算验证集准确率\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')  # 输出准确率\n",
    "    \n",
    "    elapsed = (time.time() - start_time)/60  # 计算已经过去的时间（分钟）\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')  # 输出已用时间\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60  # 计算总训练时间（分钟）\n",
    "print(f'Total Training Time: {elapsed:.2f} min')  # 输出总训练时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 50.97%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # 在推理过程中禁用梯度计算，节省内存\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchNorm before Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "class NiN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NiN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # 定义网络的分类器部分\n",
    "        self.classifier = nn.Sequential(\n",
    "                # 第一层卷积层：输入通道为 3，输出通道为 192，卷积核大小为 5，步幅为 1，padding 为 2，bias=False 不使用偏置\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "                nn.BatchNorm2d(192),  # 批归一化层，用于加速训练并稳定训练过程\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第二层卷积层：输入通道为 192，输出通道为 160，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(160),  # 批归一化层\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第三层卷积层：输入通道为 160，输出通道为 96，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(96),  # 批归一化层\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 最大池化层：卷积后的输出通过最大池化层进行下采样，卷积核大小为 3，步幅为 2，padding 为 1\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                \n",
    "                # Dropout 层：在训练时随机丢弃部分神经元，防止过拟合\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                # 第四层卷积层：输入通道为 96，输出通道为 192，卷积核大小为 5，步幅为 1，padding 为 2，bias=False 不使用偏置\n",
    "                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第五层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第六层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 平均池化层：卷积后的输出通过平均池化层进行下采样，卷积核大小为 3，步幅为 2，padding 为 1\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                \n",
    "                # Dropout 层：在训练时随机丢弃部分神经元，防止过拟合\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                # 第七层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 3，步幅为 1，padding 为 1，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第八层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 第九层卷积层：输入通道为 192，输出通道为 10，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 平均池化层：卷积后的输出通过平均池化层进行下采样，卷积核大小为 8，步幅为 1，padding 为 0\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播过程\n",
    "        x = self.classifier(x)  # 通过分类器进行计算\n",
    "        logits = x.view(x.size(0), self.num_classes)  # 将输出展平，形状为 [batch_size, num_classes]\n",
    "        probas = torch.softmax(logits, dim=1)  # 使用 softmax 激活函数获得每个类的概率分布\n",
    "        return logits, probas  # 返回 logits 和概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = NiN(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100 | Batch 000/192 | Cost: 2.3090\n",
      "Epoch: 001/100 | Batch 120/192 | Cost: 1.2568\n",
      "Epoch: 001/100 Train Acc.: 61.16% | Validation Acc.: 61.30%\n",
      "Time elapsed: 0.82 min\n",
      "Epoch: 002/100 | Batch 000/192 | Cost: 1.2059\n",
      "Epoch: 002/100 | Batch 120/192 | Cost: 0.9759\n",
      "Epoch: 002/100 Train Acc.: 69.01% | Validation Acc.: 67.20%\n",
      "Time elapsed: 1.65 min\n",
      "Epoch: 003/100 | Batch 000/192 | Cost: 0.9362\n",
      "Epoch: 003/100 | Batch 120/192 | Cost: 0.9533\n",
      "Epoch: 003/100 Train Acc.: 73.57% | Validation Acc.: 72.00%\n",
      "Time elapsed: 2.47 min\n",
      "Epoch: 004/100 | Batch 000/192 | Cost: 0.9013\n",
      "Epoch: 004/100 | Batch 120/192 | Cost: 0.7463\n",
      "Epoch: 004/100 Train Acc.: 75.14% | Validation Acc.: 73.60%\n",
      "Time elapsed: 3.30 min\n",
      "Epoch: 005/100 | Batch 000/192 | Cost: 0.7775\n",
      "Epoch: 005/100 | Batch 120/192 | Cost: 0.7081\n",
      "Epoch: 005/100 Train Acc.: 78.69% | Validation Acc.: 75.70%\n",
      "Time elapsed: 4.13 min\n",
      "Epoch: 006/100 | Batch 000/192 | Cost: 0.6839\n",
      "Epoch: 006/100 | Batch 120/192 | Cost: 0.6343\n",
      "Epoch: 006/100 Train Acc.: 79.81% | Validation Acc.: 77.60%\n",
      "Time elapsed: 4.95 min\n",
      "Epoch: 007/100 | Batch 000/192 | Cost: 0.6167\n",
      "Epoch: 007/100 | Batch 120/192 | Cost: 0.6706\n",
      "Epoch: 007/100 Train Acc.: 80.99% | Validation Acc.: 78.40%\n",
      "Time elapsed: 5.78 min\n",
      "Epoch: 008/100 | Batch 000/192 | Cost: 0.6167\n",
      "Epoch: 008/100 | Batch 120/192 | Cost: 0.5362\n",
      "Epoch: 008/100 Train Acc.: 83.03% | Validation Acc.: 79.30%\n",
      "Time elapsed: 6.60 min\n",
      "Epoch: 009/100 | Batch 000/192 | Cost: 0.4607\n",
      "Epoch: 009/100 | Batch 120/192 | Cost: 0.5376\n",
      "Epoch: 009/100 Train Acc.: 84.42% | Validation Acc.: 79.70%\n",
      "Time elapsed: 7.43 min\n",
      "Epoch: 010/100 | Batch 000/192 | Cost: 0.4961\n",
      "Epoch: 010/100 | Batch 120/192 | Cost: 0.5361\n",
      "Epoch: 010/100 Train Acc.: 84.00% | Validation Acc.: 81.30%\n",
      "Time elapsed: 8.25 min\n",
      "Epoch: 011/100 | Batch 000/192 | Cost: 0.4586\n",
      "Epoch: 011/100 | Batch 120/192 | Cost: 0.4478\n",
      "Epoch: 011/100 Train Acc.: 85.94% | Validation Acc.: 81.90%\n",
      "Time elapsed: 9.08 min\n",
      "Epoch: 012/100 | Batch 000/192 | Cost: 0.3573\n",
      "Epoch: 012/100 | Batch 120/192 | Cost: 0.3495\n",
      "Epoch: 012/100 Train Acc.: 86.44% | Validation Acc.: 81.50%\n",
      "Time elapsed: 9.90 min\n",
      "Epoch: 013/100 | Batch 000/192 | Cost: 0.3700\n",
      "Epoch: 013/100 | Batch 120/192 | Cost: 0.4273\n",
      "Epoch: 013/100 Train Acc.: 87.24% | Validation Acc.: 83.10%\n",
      "Time elapsed: 10.73 min\n",
      "Epoch: 014/100 | Batch 000/192 | Cost: 0.4645\n",
      "Epoch: 014/100 | Batch 120/192 | Cost: 0.3735\n",
      "Epoch: 014/100 Train Acc.: 87.55% | Validation Acc.: 82.70%\n",
      "Time elapsed: 11.55 min\n",
      "Epoch: 015/100 | Batch 000/192 | Cost: 0.3503\n",
      "Epoch: 015/100 | Batch 120/192 | Cost: 0.4603\n",
      "Epoch: 015/100 Train Acc.: 88.12% | Validation Acc.: 85.30%\n",
      "Time elapsed: 12.38 min\n",
      "Epoch: 016/100 | Batch 000/192 | Cost: 0.3079\n",
      "Epoch: 016/100 | Batch 120/192 | Cost: 0.4223\n",
      "Epoch: 016/100 Train Acc.: 88.12% | Validation Acc.: 83.10%\n",
      "Time elapsed: 13.21 min\n",
      "Epoch: 017/100 | Batch 000/192 | Cost: 0.2779\n",
      "Epoch: 017/100 | Batch 120/192 | Cost: 0.2977\n",
      "Epoch: 017/100 Train Acc.: 89.47% | Validation Acc.: 82.90%\n",
      "Time elapsed: 14.03 min\n",
      "Epoch: 018/100 | Batch 000/192 | Cost: 0.2081\n",
      "Epoch: 018/100 | Batch 120/192 | Cost: 0.3031\n",
      "Epoch: 018/100 Train Acc.: 89.65% | Validation Acc.: 84.10%\n",
      "Time elapsed: 14.86 min\n",
      "Epoch: 019/100 | Batch 000/192 | Cost: 0.3163\n",
      "Epoch: 019/100 | Batch 120/192 | Cost: 0.3002\n",
      "Epoch: 019/100 Train Acc.: 90.40% | Validation Acc.: 83.90%\n",
      "Time elapsed: 15.68 min\n",
      "Epoch: 020/100 | Batch 000/192 | Cost: 0.3113\n",
      "Epoch: 020/100 | Batch 120/192 | Cost: 0.3644\n",
      "Epoch: 020/100 Train Acc.: 89.92% | Validation Acc.: 85.30%\n",
      "Time elapsed: 16.51 min\n",
      "Epoch: 021/100 | Batch 000/192 | Cost: 0.2450\n",
      "Epoch: 021/100 | Batch 120/192 | Cost: 0.2355\n",
      "Epoch: 021/100 Train Acc.: 91.16% | Validation Acc.: 84.20%\n",
      "Time elapsed: 17.33 min\n",
      "Epoch: 022/100 | Batch 000/192 | Cost: 0.3208\n",
      "Epoch: 022/100 | Batch 120/192 | Cost: 0.2898\n",
      "Epoch: 022/100 Train Acc.: 91.83% | Validation Acc.: 86.10%\n",
      "Time elapsed: 18.16 min\n",
      "Epoch: 023/100 | Batch 000/192 | Cost: 0.2202\n",
      "Epoch: 023/100 | Batch 120/192 | Cost: 0.3236\n",
      "Epoch: 023/100 Train Acc.: 91.31% | Validation Acc.: 84.00%\n",
      "Time elapsed: 18.98 min\n",
      "Epoch: 024/100 | Batch 000/192 | Cost: 0.2961\n",
      "Epoch: 024/100 | Batch 120/192 | Cost: 0.2375\n",
      "Epoch: 024/100 Train Acc.: 91.96% | Validation Acc.: 85.30%\n",
      "Time elapsed: 19.81 min\n",
      "Epoch: 025/100 | Batch 000/192 | Cost: 0.2183\n",
      "Epoch: 025/100 | Batch 120/192 | Cost: 0.2247\n",
      "Epoch: 025/100 Train Acc.: 92.30% | Validation Acc.: 85.80%\n",
      "Time elapsed: 20.63 min\n",
      "Epoch: 026/100 | Batch 000/192 | Cost: 0.2051\n",
      "Epoch: 026/100 | Batch 120/192 | Cost: 0.1759\n",
      "Epoch: 026/100 Train Acc.: 92.81% | Validation Acc.: 84.40%\n",
      "Time elapsed: 21.46 min\n",
      "Epoch: 027/100 | Batch 000/192 | Cost: 0.1955\n",
      "Epoch: 027/100 | Batch 120/192 | Cost: 0.1989\n",
      "Epoch: 027/100 Train Acc.: 92.92% | Validation Acc.: 84.30%\n",
      "Time elapsed: 22.29 min\n",
      "Epoch: 028/100 | Batch 000/192 | Cost: 0.2230\n",
      "Epoch: 028/100 | Batch 120/192 | Cost: 0.1892\n",
      "Epoch: 028/100 Train Acc.: 93.34% | Validation Acc.: 86.00%\n",
      "Time elapsed: 23.11 min\n",
      "Epoch: 029/100 | Batch 000/192 | Cost: 0.1457\n",
      "Epoch: 029/100 | Batch 120/192 | Cost: 0.1618\n",
      "Epoch: 029/100 Train Acc.: 93.38% | Validation Acc.: 86.70%\n",
      "Time elapsed: 23.94 min\n",
      "Epoch: 030/100 | Batch 000/192 | Cost: 0.2090\n",
      "Epoch: 030/100 | Batch 120/192 | Cost: 0.1699\n",
      "Epoch: 030/100 Train Acc.: 93.15% | Validation Acc.: 84.70%\n",
      "Time elapsed: 24.76 min\n",
      "Epoch: 031/100 | Batch 000/192 | Cost: 0.1668\n",
      "Epoch: 031/100 | Batch 120/192 | Cost: 0.1430\n",
      "Epoch: 031/100 Train Acc.: 93.56% | Validation Acc.: 85.00%\n",
      "Time elapsed: 25.59 min\n",
      "Epoch: 032/100 | Batch 000/192 | Cost: 0.1130\n",
      "Epoch: 032/100 | Batch 120/192 | Cost: 0.1707\n",
      "Epoch: 032/100 Train Acc.: 93.84% | Validation Acc.: 85.20%\n",
      "Time elapsed: 26.41 min\n",
      "Epoch: 033/100 | Batch 000/192 | Cost: 0.1791\n",
      "Epoch: 033/100 | Batch 120/192 | Cost: 0.2127\n",
      "Epoch: 033/100 Train Acc.: 94.00% | Validation Acc.: 85.20%\n",
      "Time elapsed: 27.24 min\n",
      "Epoch: 034/100 | Batch 000/192 | Cost: 0.1222\n",
      "Epoch: 034/100 | Batch 120/192 | Cost: 0.1785\n",
      "Epoch: 034/100 Train Acc.: 94.74% | Validation Acc.: 84.60%\n",
      "Time elapsed: 28.06 min\n",
      "Epoch: 035/100 | Batch 000/192 | Cost: 0.2471\n",
      "Epoch: 035/100 | Batch 120/192 | Cost: 0.1607\n",
      "Epoch: 035/100 Train Acc.: 94.33% | Validation Acc.: 85.20%\n",
      "Time elapsed: 28.89 min\n",
      "Epoch: 036/100 | Batch 000/192 | Cost: 0.1382\n",
      "Epoch: 036/100 | Batch 120/192 | Cost: 0.1766\n",
      "Epoch: 036/100 Train Acc.: 94.69% | Validation Acc.: 85.00%\n",
      "Time elapsed: 29.72 min\n",
      "Epoch: 037/100 | Batch 000/192 | Cost: 0.1601\n",
      "Epoch: 037/100 | Batch 120/192 | Cost: 0.1629\n",
      "Epoch: 037/100 Train Acc.: 95.13% | Validation Acc.: 85.20%\n",
      "Time elapsed: 30.54 min\n",
      "Epoch: 038/100 | Batch 000/192 | Cost: 0.1943\n",
      "Epoch: 038/100 | Batch 120/192 | Cost: 0.1350\n",
      "Epoch: 038/100 Train Acc.: 95.34% | Validation Acc.: 85.90%\n",
      "Time elapsed: 31.37 min\n",
      "Epoch: 039/100 | Batch 000/192 | Cost: 0.1257\n",
      "Epoch: 039/100 | Batch 120/192 | Cost: 0.1518\n",
      "Epoch: 039/100 Train Acc.: 95.47% | Validation Acc.: 85.80%\n",
      "Time elapsed: 32.19 min\n",
      "Epoch: 040/100 | Batch 000/192 | Cost: 0.1215\n",
      "Epoch: 040/100 | Batch 120/192 | Cost: 0.1198\n",
      "Epoch: 040/100 Train Acc.: 95.26% | Validation Acc.: 85.20%\n",
      "Time elapsed: 33.02 min\n",
      "Epoch: 041/100 | Batch 000/192 | Cost: 0.1075\n",
      "Epoch: 041/100 | Batch 120/192 | Cost: 0.1673\n",
      "Epoch: 041/100 Train Acc.: 95.23% | Validation Acc.: 85.90%\n",
      "Time elapsed: 33.85 min\n",
      "Epoch: 042/100 | Batch 000/192 | Cost: 0.0864\n",
      "Epoch: 042/100 | Batch 120/192 | Cost: 0.1438\n",
      "Epoch: 042/100 Train Acc.: 95.68% | Validation Acc.: 85.40%\n",
      "Time elapsed: 34.67 min\n",
      "Epoch: 043/100 | Batch 000/192 | Cost: 0.1338\n",
      "Epoch: 043/100 | Batch 120/192 | Cost: 0.1735\n",
      "Epoch: 043/100 Train Acc.: 96.17% | Validation Acc.: 84.50%\n",
      "Time elapsed: 35.50 min\n",
      "Epoch: 044/100 | Batch 000/192 | Cost: 0.1029\n",
      "Epoch: 044/100 | Batch 120/192 | Cost: 0.1679\n",
      "Epoch: 044/100 Train Acc.: 96.05% | Validation Acc.: 85.80%\n",
      "Time elapsed: 36.32 min\n",
      "Epoch: 045/100 | Batch 000/192 | Cost: 0.1107\n",
      "Epoch: 045/100 | Batch 120/192 | Cost: 0.0928\n",
      "Epoch: 045/100 Train Acc.: 95.77% | Validation Acc.: 86.90%\n",
      "Time elapsed: 37.15 min\n",
      "Epoch: 046/100 | Batch 000/192 | Cost: 0.1033\n",
      "Epoch: 046/100 | Batch 120/192 | Cost: 0.1524\n",
      "Epoch: 046/100 Train Acc.: 96.18% | Validation Acc.: 86.30%\n",
      "Time elapsed: 37.98 min\n",
      "Epoch: 047/100 | Batch 000/192 | Cost: 0.0913\n",
      "Epoch: 047/100 | Batch 120/192 | Cost: 0.1377\n",
      "Epoch: 047/100 Train Acc.: 96.22% | Validation Acc.: 86.90%\n",
      "Time elapsed: 38.80 min\n",
      "Epoch: 048/100 | Batch 000/192 | Cost: 0.1329\n",
      "Epoch: 048/100 | Batch 120/192 | Cost: 0.1661\n",
      "Epoch: 048/100 Train Acc.: 96.31% | Validation Acc.: 85.90%\n",
      "Time elapsed: 39.63 min\n",
      "Epoch: 049/100 | Batch 000/192 | Cost: 0.1511\n",
      "Epoch: 049/100 | Batch 120/192 | Cost: 0.0935\n",
      "Epoch: 049/100 Train Acc.: 96.21% | Validation Acc.: 85.40%\n",
      "Time elapsed: 40.45 min\n",
      "Epoch: 050/100 | Batch 000/192 | Cost: 0.0974\n",
      "Epoch: 050/100 | Batch 120/192 | Cost: 0.1145\n",
      "Epoch: 050/100 Train Acc.: 96.34% | Validation Acc.: 85.90%\n",
      "Time elapsed: 41.28 min\n",
      "Epoch: 051/100 | Batch 000/192 | Cost: 0.1119\n",
      "Epoch: 051/100 | Batch 120/192 | Cost: 0.1066\n",
      "Epoch: 051/100 Train Acc.: 96.64% | Validation Acc.: 85.80%\n",
      "Time elapsed: 42.10 min\n",
      "Epoch: 052/100 | Batch 000/192 | Cost: 0.0900\n",
      "Epoch: 052/100 | Batch 120/192 | Cost: 0.0831\n",
      "Epoch: 052/100 Train Acc.: 96.58% | Validation Acc.: 85.50%\n",
      "Time elapsed: 42.93 min\n",
      "Epoch: 053/100 | Batch 000/192 | Cost: 0.0865\n",
      "Epoch: 053/100 | Batch 120/192 | Cost: 0.1537\n",
      "Epoch: 053/100 Train Acc.: 96.25% | Validation Acc.: 86.20%\n",
      "Time elapsed: 43.76 min\n",
      "Epoch: 054/100 | Batch 000/192 | Cost: 0.1357\n",
      "Epoch: 054/100 | Batch 120/192 | Cost: 0.1461\n",
      "Epoch: 054/100 Train Acc.: 96.95% | Validation Acc.: 87.40%\n",
      "Time elapsed: 44.58 min\n",
      "Epoch: 055/100 | Batch 000/192 | Cost: 0.0751\n",
      "Epoch: 055/100 | Batch 120/192 | Cost: 0.1167\n",
      "Epoch: 055/100 Train Acc.: 96.62% | Validation Acc.: 86.70%\n",
      "Time elapsed: 45.41 min\n",
      "Epoch: 056/100 | Batch 000/192 | Cost: 0.0918\n",
      "Epoch: 056/100 | Batch 120/192 | Cost: 0.1635\n",
      "Epoch: 056/100 Train Acc.: 96.26% | Validation Acc.: 85.10%\n",
      "Time elapsed: 46.23 min\n",
      "Epoch: 057/100 | Batch 000/192 | Cost: 0.1249\n",
      "Epoch: 057/100 | Batch 120/192 | Cost: 0.0754\n",
      "Epoch: 057/100 Train Acc.: 97.42% | Validation Acc.: 87.20%\n",
      "Time elapsed: 47.06 min\n",
      "Epoch: 058/100 | Batch 000/192 | Cost: 0.0630\n",
      "Epoch: 058/100 | Batch 120/192 | Cost: 0.1199\n",
      "Epoch: 058/100 Train Acc.: 96.73% | Validation Acc.: 85.70%\n",
      "Time elapsed: 47.88 min\n",
      "Epoch: 059/100 | Batch 000/192 | Cost: 0.0882\n",
      "Epoch: 059/100 | Batch 120/192 | Cost: 0.0527\n",
      "Epoch: 059/100 Train Acc.: 97.00% | Validation Acc.: 86.50%\n",
      "Time elapsed: 48.71 min\n",
      "Epoch: 060/100 | Batch 000/192 | Cost: 0.0683\n",
      "Epoch: 060/100 | Batch 120/192 | Cost: 0.1035\n",
      "Epoch: 060/100 Train Acc.: 96.78% | Validation Acc.: 86.60%\n",
      "Time elapsed: 49.53 min\n",
      "Epoch: 061/100 | Batch 000/192 | Cost: 0.1094\n",
      "Epoch: 061/100 | Batch 120/192 | Cost: 0.0787\n",
      "Epoch: 061/100 Train Acc.: 97.13% | Validation Acc.: 85.70%\n",
      "Time elapsed: 50.36 min\n",
      "Epoch: 062/100 | Batch 000/192 | Cost: 0.0933\n",
      "Epoch: 062/100 | Batch 120/192 | Cost: 0.1111\n",
      "Epoch: 062/100 Train Acc.: 97.16% | Validation Acc.: 85.90%\n",
      "Time elapsed: 51.18 min\n",
      "Epoch: 063/100 | Batch 000/192 | Cost: 0.0946\n",
      "Epoch: 063/100 | Batch 120/192 | Cost: 0.0533\n",
      "Epoch: 063/100 Train Acc.: 96.93% | Validation Acc.: 85.80%\n",
      "Time elapsed: 52.01 min\n",
      "Epoch: 064/100 | Batch 000/192 | Cost: 0.0600\n",
      "Epoch: 064/100 | Batch 120/192 | Cost: 0.0844\n",
      "Epoch: 064/100 Train Acc.: 97.04% | Validation Acc.: 86.10%\n",
      "Time elapsed: 52.84 min\n",
      "Epoch: 065/100 | Batch 000/192 | Cost: 0.0343\n",
      "Epoch: 065/100 | Batch 120/192 | Cost: 0.0721\n",
      "Epoch: 065/100 Train Acc.: 97.44% | Validation Acc.: 86.30%\n",
      "Time elapsed: 53.66 min\n",
      "Epoch: 066/100 | Batch 000/192 | Cost: 0.0576\n",
      "Epoch: 066/100 | Batch 120/192 | Cost: 0.1207\n",
      "Epoch: 066/100 Train Acc.: 97.52% | Validation Acc.: 85.80%\n",
      "Time elapsed: 54.49 min\n",
      "Epoch: 067/100 | Batch 000/192 | Cost: 0.0790\n",
      "Epoch: 067/100 | Batch 120/192 | Cost: 0.1015\n",
      "Epoch: 067/100 Train Acc.: 97.29% | Validation Acc.: 85.20%\n",
      "Time elapsed: 55.31 min\n",
      "Epoch: 068/100 | Batch 000/192 | Cost: 0.0455\n",
      "Epoch: 068/100 | Batch 120/192 | Cost: 0.0597\n",
      "Epoch: 068/100 Train Acc.: 97.36% | Validation Acc.: 85.20%\n",
      "Time elapsed: 56.14 min\n",
      "Epoch: 069/100 | Batch 000/192 | Cost: 0.0725\n",
      "Epoch: 069/100 | Batch 120/192 | Cost: 0.0823\n",
      "Epoch: 069/100 Train Acc.: 97.31% | Validation Acc.: 85.40%\n",
      "Time elapsed: 56.96 min\n",
      "Epoch: 070/100 | Batch 000/192 | Cost: 0.0409\n",
      "Epoch: 070/100 | Batch 120/192 | Cost: 0.0957\n",
      "Epoch: 070/100 Train Acc.: 97.59% | Validation Acc.: 86.50%\n",
      "Time elapsed: 57.79 min\n",
      "Epoch: 071/100 | Batch 000/192 | Cost: 0.0541\n",
      "Epoch: 071/100 | Batch 120/192 | Cost: 0.1053\n",
      "Epoch: 071/100 Train Acc.: 97.69% | Validation Acc.: 85.40%\n",
      "Time elapsed: 58.61 min\n",
      "Epoch: 072/100 | Batch 000/192 | Cost: 0.0696\n",
      "Epoch: 072/100 | Batch 120/192 | Cost: 0.0671\n",
      "Epoch: 072/100 Train Acc.: 97.64% | Validation Acc.: 85.90%\n",
      "Time elapsed: 59.44 min\n",
      "Epoch: 073/100 | Batch 000/192 | Cost: 0.0715\n",
      "Epoch: 073/100 | Batch 120/192 | Cost: 0.0812\n",
      "Epoch: 073/100 Train Acc.: 97.61% | Validation Acc.: 86.80%\n",
      "Time elapsed: 60.27 min\n",
      "Epoch: 074/100 | Batch 000/192 | Cost: 0.0343\n",
      "Epoch: 074/100 | Batch 120/192 | Cost: 0.0978\n",
      "Epoch: 074/100 Train Acc.: 97.49% | Validation Acc.: 87.40%\n",
      "Time elapsed: 61.09 min\n",
      "Epoch: 075/100 | Batch 000/192 | Cost: 0.0500\n",
      "Epoch: 075/100 | Batch 120/192 | Cost: 0.0593\n",
      "Epoch: 075/100 Train Acc.: 97.70% | Validation Acc.: 87.00%\n",
      "Time elapsed: 61.92 min\n",
      "Epoch: 076/100 | Batch 000/192 | Cost: 0.0690\n",
      "Epoch: 076/100 | Batch 120/192 | Cost: 0.0539\n",
      "Epoch: 076/100 Train Acc.: 97.64% | Validation Acc.: 87.20%\n",
      "Time elapsed: 62.74 min\n",
      "Epoch: 077/100 | Batch 000/192 | Cost: 0.0387\n",
      "Epoch: 077/100 | Batch 120/192 | Cost: 0.1137\n",
      "Epoch: 077/100 Train Acc.: 97.60% | Validation Acc.: 86.10%\n",
      "Time elapsed: 63.57 min\n",
      "Epoch: 078/100 | Batch 000/192 | Cost: 0.0532\n",
      "Epoch: 078/100 | Batch 120/192 | Cost: 0.0832\n",
      "Epoch: 078/100 Train Acc.: 97.49% | Validation Acc.: 84.70%\n",
      "Time elapsed: 64.39 min\n",
      "Epoch: 079/100 | Batch 000/192 | Cost: 0.0412\n",
      "Epoch: 079/100 | Batch 120/192 | Cost: 0.0730\n",
      "Epoch: 079/100 Train Acc.: 98.07% | Validation Acc.: 85.60%\n",
      "Time elapsed: 65.22 min\n",
      "Epoch: 080/100 | Batch 000/192 | Cost: 0.0453\n",
      "Epoch: 080/100 | Batch 120/192 | Cost: 0.0487\n",
      "Epoch: 080/100 Train Acc.: 97.77% | Validation Acc.: 85.80%\n",
      "Time elapsed: 66.04 min\n",
      "Epoch: 081/100 | Batch 000/192 | Cost: 0.0668\n",
      "Epoch: 081/100 | Batch 120/192 | Cost: 0.1084\n",
      "Epoch: 081/100 Train Acc.: 97.62% | Validation Acc.: 86.70%\n",
      "Time elapsed: 66.87 min\n",
      "Epoch: 082/100 | Batch 000/192 | Cost: 0.0610\n",
      "Epoch: 082/100 | Batch 120/192 | Cost: 0.0448\n",
      "Epoch: 082/100 Train Acc.: 97.74% | Validation Acc.: 86.80%\n",
      "Time elapsed: 67.69 min\n",
      "Epoch: 083/100 | Batch 000/192 | Cost: 0.0876\n",
      "Epoch: 083/100 | Batch 120/192 | Cost: 0.0981\n",
      "Epoch: 083/100 Train Acc.: 97.99% | Validation Acc.: 86.10%\n",
      "Time elapsed: 68.52 min\n",
      "Epoch: 084/100 | Batch 000/192 | Cost: 0.0353\n",
      "Epoch: 084/100 | Batch 120/192 | Cost: 0.0441\n",
      "Epoch: 084/100 Train Acc.: 97.80% | Validation Acc.: 86.00%\n",
      "Time elapsed: 69.35 min\n",
      "Epoch: 085/100 | Batch 000/192 | Cost: 0.0777\n",
      "Epoch: 085/100 | Batch 120/192 | Cost: 0.0564\n",
      "Epoch: 085/100 Train Acc.: 98.04% | Validation Acc.: 87.80%\n",
      "Time elapsed: 70.17 min\n",
      "Epoch: 086/100 | Batch 000/192 | Cost: 0.0797\n",
      "Epoch: 086/100 | Batch 120/192 | Cost: 0.0361\n",
      "Epoch: 086/100 Train Acc.: 97.82% | Validation Acc.: 85.40%\n",
      "Time elapsed: 71.00 min\n",
      "Epoch: 087/100 | Batch 000/192 | Cost: 0.0469\n",
      "Epoch: 087/100 | Batch 120/192 | Cost: 0.0547\n",
      "Epoch: 087/100 Train Acc.: 98.00% | Validation Acc.: 85.50%\n",
      "Time elapsed: 71.82 min\n",
      "Epoch: 088/100 | Batch 000/192 | Cost: 0.0544\n",
      "Epoch: 088/100 | Batch 120/192 | Cost: 0.0617\n",
      "Epoch: 088/100 Train Acc.: 97.96% | Validation Acc.: 86.80%\n",
      "Time elapsed: 72.65 min\n",
      "Epoch: 089/100 | Batch 000/192 | Cost: 0.0489\n",
      "Epoch: 089/100 | Batch 120/192 | Cost: 0.0194\n",
      "Epoch: 089/100 Train Acc.: 98.16% | Validation Acc.: 86.20%\n",
      "Time elapsed: 73.47 min\n",
      "Epoch: 090/100 | Batch 000/192 | Cost: 0.0246\n",
      "Epoch: 090/100 | Batch 120/192 | Cost: 0.0566\n",
      "Epoch: 090/100 Train Acc.: 98.08% | Validation Acc.: 85.40%\n",
      "Time elapsed: 74.30 min\n",
      "Epoch: 091/100 | Batch 000/192 | Cost: 0.0500\n",
      "Epoch: 091/100 | Batch 120/192 | Cost: 0.0292\n",
      "Epoch: 091/100 Train Acc.: 98.25% | Validation Acc.: 86.20%\n",
      "Time elapsed: 75.12 min\n",
      "Epoch: 092/100 | Batch 000/192 | Cost: 0.0837\n",
      "Epoch: 092/100 | Batch 120/192 | Cost: 0.0684\n",
      "Epoch: 092/100 Train Acc.: 98.10% | Validation Acc.: 86.30%\n",
      "Time elapsed: 75.95 min\n",
      "Epoch: 093/100 | Batch 000/192 | Cost: 0.0225\n",
      "Epoch: 093/100 | Batch 120/192 | Cost: 0.0426\n",
      "Epoch: 093/100 Train Acc.: 98.14% | Validation Acc.: 87.80%\n",
      "Time elapsed: 76.77 min\n",
      "Epoch: 094/100 | Batch 000/192 | Cost: 0.0673\n",
      "Epoch: 094/100 | Batch 120/192 | Cost: 0.0807\n",
      "Epoch: 094/100 Train Acc.: 97.97% | Validation Acc.: 84.60%\n",
      "Time elapsed: 77.60 min\n",
      "Epoch: 095/100 | Batch 000/192 | Cost: 0.0410\n",
      "Epoch: 095/100 | Batch 120/192 | Cost: 0.0349\n",
      "Epoch: 095/100 Train Acc.: 97.94% | Validation Acc.: 86.40%\n",
      "Time elapsed: 78.43 min\n",
      "Epoch: 096/100 | Batch 000/192 | Cost: 0.0936\n",
      "Epoch: 096/100 | Batch 120/192 | Cost: 0.0302\n",
      "Epoch: 096/100 Train Acc.: 98.02% | Validation Acc.: 85.70%\n",
      "Time elapsed: 79.25 min\n",
      "Epoch: 097/100 | Batch 000/192 | Cost: 0.0399\n",
      "Epoch: 097/100 | Batch 120/192 | Cost: 0.0965\n",
      "Epoch: 097/100 Train Acc.: 98.18% | Validation Acc.: 85.80%\n",
      "Time elapsed: 80.08 min\n",
      "Epoch: 098/100 | Batch 000/192 | Cost: 0.0489\n",
      "Epoch: 098/100 | Batch 120/192 | Cost: 0.0576\n",
      "Epoch: 098/100 Train Acc.: 98.20% | Validation Acc.: 86.80%\n",
      "Time elapsed: 80.90 min\n",
      "Epoch: 099/100 | Batch 000/192 | Cost: 0.0643\n",
      "Epoch: 099/100 | Batch 120/192 | Cost: 0.0403\n",
      "Epoch: 099/100 Train Acc.: 98.04% | Validation Acc.: 85.80%\n",
      "Time elapsed: 81.73 min\n",
      "Epoch: 100/100 | Batch 000/192 | Cost: 0.0224\n",
      "Epoch: 100/100 | Batch 120/192 | Cost: 0.0212\n",
      "Epoch: 100/100 Train Acc.: 98.27% | Validation Acc.: 86.50%\n",
      "Time elapsed: 82.55 min\n",
      "Total Training Time: 82.55 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  # 记录开始时间\n",
    "for epoch in range(NUM_EPOCHS):  # 循环遍历每个epoch\n",
    "    \n",
    "    model.train()  # 设置模型为训练模式\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):  # 循环遍历每个批次\n",
    "    \n",
    "        ### 准备小批量数据\n",
    "        features = features.to(DEVICE)  # 将特征转移到指定设备\n",
    "        targets = targets.to(DEVICE)  # 将目标标签转移到指定设备\n",
    "            \n",
    "        ### 前向传播和反向传播\n",
    "        logits, probas = model(features)  # 获取模型的输出\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        \n",
    "        cost.backward()  # 反向传播计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()  # 使用优化器更新参数\n",
    "        \n",
    "        ### 日志记录\n",
    "        if not batch_idx % 120:  # 每120个批次输出一次日志\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # 计算准确率时不需要构建计算图以进行反向传播\n",
    "    with torch.set_grad_enabled(False):  # 禁用梯度计算\n",
    "        train_acc = compute_accuracy(model, train_loader, device=DEVICE)  # 计算训练集准确率\n",
    "        valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)  # 计算验证集准确率\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')  # 输出准确率\n",
    "    \n",
    "    elapsed = (time.time() - start_time)/60  # 计算已经过去的时间（分钟）\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')  # 输出已用时间\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60  # 计算总训练时间（分钟）\n",
    "print(f'Total Training Time: {elapsed:.2f} min')  # 输出总训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 85.12%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # 在推理过程中禁用梯度计算，节省内存\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchNorm after Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "class NiN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NiN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # 定义网络的分类器部分\n",
    "        self.classifier = nn.Sequential(\n",
    "                # 第一层卷积层：输入通道为 3，输出通道为 192，卷积核大小为 5，步幅为 1，padding 为 2，bias=False 不使用偏置\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(192),  # 批归一化层，用于加速训练并稳定训练过程\n",
    "                \n",
    "                # 第二层卷积层：输入通道为 192，输出通道为 160，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(160),  # 批归一化层\n",
    "                \n",
    "                # 第三层卷积层：输入通道为 160，输出通道为 96，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(96),  # 批归一化层\n",
    "                \n",
    "                # 最大池化层：卷积后的输出通过最大池化层进行下采样，卷积核大小为 3，步幅为 2，padding 为 1\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                \n",
    "                # Dropout 层：在训练时随机丢弃部分神经元，防止过拟合\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                # 第四层卷积层：输入通道为 96，输出通道为 192，卷积核大小为 5，步幅为 1，padding 为 2，bias=False 不使用偏置\n",
    "                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                \n",
    "                # 第五层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                \n",
    "                # 第六层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                \n",
    "                # 平均池化层：卷积后的输出通过平均池化层进行下采样，卷积核大小为 3，步幅为 2，padding 为 1\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                \n",
    "                # Dropout 层：在训练时随机丢弃部分神经元，防止过拟合\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                # 第七层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 3，步幅为 1，padding 为 1，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                \n",
    "                # 第八层卷积层：输入通道为 192，输出通道为 192，卷积核大小为 1，步幅为 1，padding 为 0，bias=False 不使用偏置\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                nn.BatchNorm2d(192),  # 批归一化层\n",
    "                \n",
    "                # 第九层卷积层：输入通道为 192，输出通道为 10，卷积核大小为 1，步幅为 1，padding 为 0\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),  # 激活函数 ReLU\n",
    "                \n",
    "                # 平均池化层：卷积后的输出通过平均池化层进行下采样，卷积核大小为 8，步幅为 1，padding 为 0\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播过程\n",
    "        x = self.classifier(x)  # 通过分类器进行计算\n",
    "        logits = x.view(x.size(0), self.num_classes)  # 将输出展平，形状为 [batch_size, num_classes]\n",
    "        probas = torch.softmax(logits, dim=1)  # 使用 softmax 激活函数获得每个类的概率分布\n",
    "        return logits, probas  # 返回 logits 和概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = NiN(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100 | Batch 000/192 | Cost: 2.3065\n",
      "Epoch: 001/100 | Batch 120/192 | Cost: 1.2000\n",
      "Epoch: 001/100 Train Acc.: 63.83% | Validation Acc.: 62.40%\n",
      "Time elapsed: 0.83 min\n",
      "Epoch: 002/100 | Batch 000/192 | Cost: 1.1581\n",
      "Epoch: 002/100 | Batch 120/192 | Cost: 0.9258\n",
      "Epoch: 002/100 Train Acc.: 71.11% | Validation Acc.: 69.10%\n",
      "Time elapsed: 1.65 min\n",
      "Epoch: 003/100 | Batch 000/192 | Cost: 0.9431\n",
      "Epoch: 003/100 | Batch 120/192 | Cost: 0.9069\n",
      "Epoch: 003/100 Train Acc.: 75.49% | Validation Acc.: 73.20%\n",
      "Time elapsed: 2.48 min\n",
      "Epoch: 004/100 | Batch 000/192 | Cost: 0.8423\n",
      "Epoch: 004/100 | Batch 120/192 | Cost: 0.6647\n",
      "Epoch: 004/100 Train Acc.: 78.95% | Validation Acc.: 75.90%\n",
      "Time elapsed: 3.30 min\n",
      "Epoch: 005/100 | Batch 000/192 | Cost: 0.6592\n",
      "Epoch: 005/100 | Batch 120/192 | Cost: 0.5978\n",
      "Epoch: 005/100 Train Acc.: 81.32% | Validation Acc.: 79.40%\n",
      "Time elapsed: 4.13 min\n",
      "Epoch: 006/100 | Batch 000/192 | Cost: 0.5774\n",
      "Epoch: 006/100 | Batch 120/192 | Cost: 0.6013\n",
      "Epoch: 006/100 Train Acc.: 83.19% | Validation Acc.: 78.20%\n",
      "Time elapsed: 4.96 min\n",
      "Epoch: 007/100 | Batch 000/192 | Cost: 0.4587\n",
      "Epoch: 007/100 | Batch 120/192 | Cost: 0.6179\n",
      "Epoch: 007/100 Train Acc.: 84.42% | Validation Acc.: 80.80%\n",
      "Time elapsed: 5.78 min\n",
      "Epoch: 008/100 | Batch 000/192 | Cost: 0.4814\n",
      "Epoch: 008/100 | Batch 120/192 | Cost: 0.4414\n",
      "Epoch: 008/100 Train Acc.: 85.09% | Validation Acc.: 80.60%\n",
      "Time elapsed: 6.61 min\n",
      "Epoch: 009/100 | Batch 000/192 | Cost: 0.4221\n",
      "Epoch: 009/100 | Batch 120/192 | Cost: 0.4388\n",
      "Epoch: 009/100 Train Acc.: 86.57% | Validation Acc.: 82.00%\n",
      "Time elapsed: 7.43 min\n",
      "Epoch: 010/100 | Batch 000/192 | Cost: 0.4010\n",
      "Epoch: 010/100 | Batch 120/192 | Cost: 0.4813\n",
      "Epoch: 010/100 Train Acc.: 87.66% | Validation Acc.: 82.50%\n",
      "Time elapsed: 8.26 min\n",
      "Epoch: 011/100 | Batch 000/192 | Cost: 0.3371\n",
      "Epoch: 011/100 | Batch 120/192 | Cost: 0.3759\n",
      "Epoch: 011/100 Train Acc.: 88.71% | Validation Acc.: 81.10%\n",
      "Time elapsed: 9.08 min\n",
      "Epoch: 012/100 | Batch 000/192 | Cost: 0.2882\n",
      "Epoch: 012/100 | Batch 120/192 | Cost: 0.2974\n",
      "Epoch: 012/100 Train Acc.: 89.00% | Validation Acc.: 82.50%\n",
      "Time elapsed: 9.91 min\n",
      "Epoch: 013/100 | Batch 000/192 | Cost: 0.3448\n",
      "Epoch: 013/100 | Batch 120/192 | Cost: 0.3772\n",
      "Epoch: 013/100 Train Acc.: 90.39% | Validation Acc.: 85.00%\n",
      "Time elapsed: 10.73 min\n",
      "Epoch: 014/100 | Batch 000/192 | Cost: 0.3644\n",
      "Epoch: 014/100 | Batch 120/192 | Cost: 0.3209\n",
      "Epoch: 014/100 Train Acc.: 90.24% | Validation Acc.: 83.00%\n",
      "Time elapsed: 11.56 min\n",
      "Epoch: 015/100 | Batch 000/192 | Cost: 0.3776\n",
      "Epoch: 015/100 | Batch 120/192 | Cost: 0.3450\n",
      "Epoch: 015/100 Train Acc.: 90.92% | Validation Acc.: 83.00%\n",
      "Time elapsed: 12.38 min\n",
      "Epoch: 016/100 | Batch 000/192 | Cost: 0.2440\n",
      "Epoch: 016/100 | Batch 120/192 | Cost: 0.3278\n",
      "Epoch: 016/100 Train Acc.: 91.83% | Validation Acc.: 83.60%\n",
      "Time elapsed: 13.21 min\n",
      "Epoch: 017/100 | Batch 000/192 | Cost: 0.2447\n",
      "Epoch: 017/100 | Batch 120/192 | Cost: 0.2268\n",
      "Epoch: 017/100 Train Acc.: 92.14% | Validation Acc.: 83.90%\n",
      "Time elapsed: 14.04 min\n",
      "Epoch: 018/100 | Batch 000/192 | Cost: 0.1466\n",
      "Epoch: 018/100 | Batch 120/192 | Cost: 0.2399\n",
      "Epoch: 018/100 Train Acc.: 92.37% | Validation Acc.: 84.80%\n",
      "Time elapsed: 14.86 min\n",
      "Epoch: 019/100 | Batch 000/192 | Cost: 0.2329\n",
      "Epoch: 019/100 | Batch 120/192 | Cost: 0.2016\n",
      "Epoch: 019/100 Train Acc.: 93.10% | Validation Acc.: 84.30%\n",
      "Time elapsed: 15.69 min\n",
      "Epoch: 020/100 | Batch 000/192 | Cost: 0.2318\n",
      "Epoch: 020/100 | Batch 120/192 | Cost: 0.2221\n",
      "Epoch: 020/100 Train Acc.: 93.33% | Validation Acc.: 84.40%\n",
      "Time elapsed: 16.51 min\n",
      "Epoch: 021/100 | Batch 000/192 | Cost: 0.1731\n",
      "Epoch: 021/100 | Batch 120/192 | Cost: 0.2091\n",
      "Epoch: 021/100 Train Acc.: 94.01% | Validation Acc.: 84.30%\n",
      "Time elapsed: 17.34 min\n",
      "Epoch: 022/100 | Batch 000/192 | Cost: 0.1905\n",
      "Epoch: 022/100 | Batch 120/192 | Cost: 0.2155\n",
      "Epoch: 022/100 Train Acc.: 94.30% | Validation Acc.: 85.20%\n",
      "Time elapsed: 18.16 min\n",
      "Epoch: 023/100 | Batch 000/192 | Cost: 0.1622\n",
      "Epoch: 023/100 | Batch 120/192 | Cost: 0.2053\n",
      "Epoch: 023/100 Train Acc.: 94.46% | Validation Acc.: 84.00%\n",
      "Time elapsed: 18.99 min\n",
      "Epoch: 024/100 | Batch 000/192 | Cost: 0.2076\n",
      "Epoch: 024/100 | Batch 120/192 | Cost: 0.1643\n",
      "Epoch: 024/100 Train Acc.: 95.09% | Validation Acc.: 83.00%\n",
      "Time elapsed: 19.81 min\n",
      "Epoch: 025/100 | Batch 000/192 | Cost: 0.1485\n",
      "Epoch: 025/100 | Batch 120/192 | Cost: 0.1158\n",
      "Epoch: 025/100 Train Acc.: 95.14% | Validation Acc.: 84.80%\n",
      "Time elapsed: 20.64 min\n",
      "Epoch: 026/100 | Batch 000/192 | Cost: 0.1065\n",
      "Epoch: 026/100 | Batch 120/192 | Cost: 0.1678\n",
      "Epoch: 026/100 Train Acc.: 95.15% | Validation Acc.: 84.40%\n",
      "Time elapsed: 21.46 min\n",
      "Epoch: 027/100 | Batch 000/192 | Cost: 0.1641\n",
      "Epoch: 027/100 | Batch 120/192 | Cost: 0.1254\n",
      "Epoch: 027/100 Train Acc.: 95.12% | Validation Acc.: 84.80%\n",
      "Time elapsed: 22.29 min\n",
      "Epoch: 028/100 | Batch 000/192 | Cost: 0.1410\n",
      "Epoch: 028/100 | Batch 120/192 | Cost: 0.1308\n",
      "Epoch: 028/100 Train Acc.: 95.59% | Validation Acc.: 84.40%\n",
      "Time elapsed: 23.12 min\n",
      "Epoch: 029/100 | Batch 000/192 | Cost: 0.1367\n",
      "Epoch: 029/100 | Batch 120/192 | Cost: 0.1475\n",
      "Epoch: 029/100 Train Acc.: 95.44% | Validation Acc.: 86.20%\n",
      "Time elapsed: 23.94 min\n",
      "Epoch: 030/100 | Batch 000/192 | Cost: 0.1230\n",
      "Epoch: 030/100 | Batch 120/192 | Cost: 0.1161\n",
      "Epoch: 030/100 Train Acc.: 95.87% | Validation Acc.: 84.90%\n",
      "Time elapsed: 24.77 min\n",
      "Epoch: 031/100 | Batch 000/192 | Cost: 0.1087\n",
      "Epoch: 031/100 | Batch 120/192 | Cost: 0.1265\n",
      "Epoch: 031/100 Train Acc.: 96.29% | Validation Acc.: 85.60%\n",
      "Time elapsed: 25.60 min\n",
      "Epoch: 032/100 | Batch 000/192 | Cost: 0.0596\n",
      "Epoch: 032/100 | Batch 120/192 | Cost: 0.1820\n",
      "Epoch: 032/100 Train Acc.: 96.18% | Validation Acc.: 83.70%\n",
      "Time elapsed: 26.42 min\n",
      "Epoch: 033/100 | Batch 000/192 | Cost: 0.1351\n",
      "Epoch: 033/100 | Batch 120/192 | Cost: 0.1201\n",
      "Epoch: 033/100 Train Acc.: 95.86% | Validation Acc.: 84.80%\n",
      "Time elapsed: 27.25 min\n",
      "Epoch: 034/100 | Batch 000/192 | Cost: 0.0998\n",
      "Epoch: 034/100 | Batch 120/192 | Cost: 0.1142\n",
      "Epoch: 034/100 Train Acc.: 96.45% | Validation Acc.: 85.90%\n",
      "Time elapsed: 28.07 min\n",
      "Epoch: 035/100 | Batch 000/192 | Cost: 0.1386\n",
      "Epoch: 035/100 | Batch 120/192 | Cost: 0.1233\n",
      "Epoch: 035/100 Train Acc.: 96.60% | Validation Acc.: 85.00%\n",
      "Time elapsed: 28.90 min\n",
      "Epoch: 036/100 | Batch 000/192 | Cost: 0.0731\n",
      "Epoch: 036/100 | Batch 120/192 | Cost: 0.1126\n",
      "Epoch: 036/100 Train Acc.: 96.38% | Validation Acc.: 85.40%\n",
      "Time elapsed: 29.73 min\n",
      "Epoch: 037/100 | Batch 000/192 | Cost: 0.0683\n",
      "Epoch: 037/100 | Batch 120/192 | Cost: 0.1004\n",
      "Epoch: 037/100 Train Acc.: 96.76% | Validation Acc.: 84.90%\n",
      "Time elapsed: 30.55 min\n",
      "Epoch: 038/100 | Batch 000/192 | Cost: 0.0939\n",
      "Epoch: 038/100 | Batch 120/192 | Cost: 0.1551\n",
      "Epoch: 038/100 Train Acc.: 96.58% | Validation Acc.: 85.30%\n",
      "Time elapsed: 31.38 min\n",
      "Epoch: 039/100 | Batch 000/192 | Cost: 0.1708\n",
      "Epoch: 039/100 | Batch 120/192 | Cost: 0.0990\n",
      "Epoch: 039/100 Train Acc.: 96.88% | Validation Acc.: 84.10%\n",
      "Time elapsed: 32.20 min\n",
      "Epoch: 040/100 | Batch 000/192 | Cost: 0.0689\n",
      "Epoch: 040/100 | Batch 120/192 | Cost: 0.0948\n",
      "Epoch: 040/100 Train Acc.: 96.78% | Validation Acc.: 84.20%\n",
      "Time elapsed: 33.03 min\n",
      "Epoch: 041/100 | Batch 000/192 | Cost: 0.0887\n",
      "Epoch: 041/100 | Batch 120/192 | Cost: 0.0966\n",
      "Epoch: 041/100 Train Acc.: 96.84% | Validation Acc.: 86.40%\n",
      "Time elapsed: 33.85 min\n",
      "Epoch: 042/100 | Batch 000/192 | Cost: 0.0812\n",
      "Epoch: 042/100 | Batch 120/192 | Cost: 0.1228\n",
      "Epoch: 042/100 Train Acc.: 97.16% | Validation Acc.: 85.90%\n",
      "Time elapsed: 34.68 min\n",
      "Epoch: 043/100 | Batch 000/192 | Cost: 0.0699\n",
      "Epoch: 043/100 | Batch 120/192 | Cost: 0.0879\n",
      "Epoch: 043/100 Train Acc.: 97.10% | Validation Acc.: 84.70%\n",
      "Time elapsed: 35.51 min\n",
      "Epoch: 044/100 | Batch 000/192 | Cost: 0.1214\n",
      "Epoch: 044/100 | Batch 120/192 | Cost: 0.0916\n",
      "Epoch: 044/100 Train Acc.: 97.24% | Validation Acc.: 86.60%\n",
      "Time elapsed: 36.33 min\n",
      "Epoch: 045/100 | Batch 000/192 | Cost: 0.0546\n",
      "Epoch: 045/100 | Batch 120/192 | Cost: 0.0709\n",
      "Epoch: 045/100 Train Acc.: 97.40% | Validation Acc.: 86.40%\n",
      "Time elapsed: 37.16 min\n",
      "Epoch: 046/100 | Batch 000/192 | Cost: 0.0773\n",
      "Epoch: 046/100 | Batch 120/192 | Cost: 0.0619\n",
      "Epoch: 046/100 Train Acc.: 97.19% | Validation Acc.: 87.30%\n",
      "Time elapsed: 37.98 min\n",
      "Epoch: 047/100 | Batch 000/192 | Cost: 0.0843\n",
      "Epoch: 047/100 | Batch 120/192 | Cost: 0.0789\n",
      "Epoch: 047/100 Train Acc.: 97.28% | Validation Acc.: 87.20%\n",
      "Time elapsed: 38.81 min\n",
      "Epoch: 048/100 | Batch 000/192 | Cost: 0.0855\n",
      "Epoch: 048/100 | Batch 120/192 | Cost: 0.1135\n",
      "Epoch: 048/100 Train Acc.: 97.34% | Validation Acc.: 84.40%\n",
      "Time elapsed: 39.63 min\n",
      "Epoch: 049/100 | Batch 000/192 | Cost: 0.0707\n",
      "Epoch: 049/100 | Batch 120/192 | Cost: 0.0769\n",
      "Epoch: 049/100 Train Acc.: 97.28% | Validation Acc.: 84.90%\n",
      "Time elapsed: 40.46 min\n",
      "Epoch: 050/100 | Batch 000/192 | Cost: 0.0811\n",
      "Epoch: 050/100 | Batch 120/192 | Cost: 0.1402\n",
      "Epoch: 050/100 Train Acc.: 97.36% | Validation Acc.: 85.90%\n",
      "Time elapsed: 41.28 min\n",
      "Epoch: 051/100 | Batch 000/192 | Cost: 0.0882\n",
      "Epoch: 051/100 | Batch 120/192 | Cost: 0.1034\n",
      "Epoch: 051/100 Train Acc.: 97.47% | Validation Acc.: 86.30%\n",
      "Time elapsed: 42.11 min\n",
      "Epoch: 052/100 | Batch 000/192 | Cost: 0.1064\n",
      "Epoch: 052/100 | Batch 120/192 | Cost: 0.0791\n",
      "Epoch: 052/100 Train Acc.: 97.52% | Validation Acc.: 85.30%\n",
      "Time elapsed: 42.94 min\n",
      "Epoch: 053/100 | Batch 000/192 | Cost: 0.0544\n",
      "Epoch: 053/100 | Batch 120/192 | Cost: 0.1170\n",
      "Epoch: 053/100 Train Acc.: 97.84% | Validation Acc.: 86.00%\n",
      "Time elapsed: 43.76 min\n",
      "Epoch: 054/100 | Batch 000/192 | Cost: 0.0514\n",
      "Epoch: 054/100 | Batch 120/192 | Cost: 0.0837\n",
      "Epoch: 054/100 Train Acc.: 97.67% | Validation Acc.: 85.10%\n",
      "Time elapsed: 44.59 min\n",
      "Epoch: 055/100 | Batch 000/192 | Cost: 0.0496\n",
      "Epoch: 055/100 | Batch 120/192 | Cost: 0.0583\n",
      "Epoch: 055/100 Train Acc.: 97.74% | Validation Acc.: 84.50%\n",
      "Time elapsed: 45.41 min\n",
      "Epoch: 056/100 | Batch 000/192 | Cost: 0.0295\n",
      "Epoch: 056/100 | Batch 120/192 | Cost: 0.0643\n",
      "Epoch: 056/100 Train Acc.: 97.72% | Validation Acc.: 85.00%\n",
      "Time elapsed: 46.24 min\n",
      "Epoch: 057/100 | Batch 000/192 | Cost: 0.0732\n",
      "Epoch: 057/100 | Batch 120/192 | Cost: 0.0378\n",
      "Epoch: 057/100 Train Acc.: 97.91% | Validation Acc.: 85.90%\n",
      "Time elapsed: 47.06 min\n",
      "Epoch: 058/100 | Batch 000/192 | Cost: 0.0788\n",
      "Epoch: 058/100 | Batch 120/192 | Cost: 0.0705\n",
      "Epoch: 058/100 Train Acc.: 97.84% | Validation Acc.: 86.50%\n",
      "Time elapsed: 47.89 min\n",
      "Epoch: 059/100 | Batch 000/192 | Cost: 0.0589\n",
      "Epoch: 059/100 | Batch 120/192 | Cost: 0.0403\n",
      "Epoch: 059/100 Train Acc.: 97.78% | Validation Acc.: 84.00%\n",
      "Time elapsed: 48.71 min\n",
      "Epoch: 060/100 | Batch 000/192 | Cost: 0.0596\n",
      "Epoch: 060/100 | Batch 120/192 | Cost: 0.0517\n",
      "Epoch: 060/100 Train Acc.: 98.10% | Validation Acc.: 85.30%\n",
      "Time elapsed: 49.54 min\n",
      "Epoch: 061/100 | Batch 000/192 | Cost: 0.0364\n",
      "Epoch: 061/100 | Batch 120/192 | Cost: 0.0661\n",
      "Epoch: 061/100 Train Acc.: 97.43% | Validation Acc.: 84.70%\n",
      "Time elapsed: 50.36 min\n",
      "Epoch: 062/100 | Batch 000/192 | Cost: 0.0601\n",
      "Epoch: 062/100 | Batch 120/192 | Cost: 0.0988\n",
      "Epoch: 062/100 Train Acc.: 97.87% | Validation Acc.: 85.60%\n",
      "Time elapsed: 51.19 min\n",
      "Epoch: 063/100 | Batch 000/192 | Cost: 0.0352\n",
      "Epoch: 063/100 | Batch 120/192 | Cost: 0.0365\n",
      "Epoch: 063/100 Train Acc.: 98.03% | Validation Acc.: 86.20%\n",
      "Time elapsed: 52.02 min\n",
      "Epoch: 064/100 | Batch 000/192 | Cost: 0.0439\n",
      "Epoch: 064/100 | Batch 120/192 | Cost: 0.0490\n",
      "Epoch: 064/100 Train Acc.: 98.19% | Validation Acc.: 86.40%\n",
      "Time elapsed: 52.84 min\n",
      "Epoch: 065/100 | Batch 000/192 | Cost: 0.0456\n",
      "Epoch: 065/100 | Batch 120/192 | Cost: 0.0485\n",
      "Epoch: 065/100 Train Acc.: 97.90% | Validation Acc.: 85.80%\n",
      "Time elapsed: 53.67 min\n",
      "Epoch: 066/100 | Batch 000/192 | Cost: 0.0608\n",
      "Epoch: 066/100 | Batch 120/192 | Cost: 0.0788\n",
      "Epoch: 066/100 Train Acc.: 98.19% | Validation Acc.: 85.60%\n",
      "Time elapsed: 54.49 min\n",
      "Epoch: 067/100 | Batch 000/192 | Cost: 0.1072\n",
      "Epoch: 067/100 | Batch 120/192 | Cost: 0.0825\n",
      "Epoch: 067/100 Train Acc.: 98.05% | Validation Acc.: 86.20%\n",
      "Time elapsed: 55.32 min\n",
      "Epoch: 068/100 | Batch 000/192 | Cost: 0.0545\n",
      "Epoch: 068/100 | Batch 120/192 | Cost: 0.0915\n",
      "Epoch: 068/100 Train Acc.: 98.14% | Validation Acc.: 85.90%\n",
      "Time elapsed: 56.14 min\n",
      "Epoch: 069/100 | Batch 000/192 | Cost: 0.0594\n",
      "Epoch: 069/100 | Batch 120/192 | Cost: 0.0427\n",
      "Epoch: 069/100 Train Acc.: 98.46% | Validation Acc.: 85.70%\n",
      "Time elapsed: 56.97 min\n",
      "Epoch: 070/100 | Batch 000/192 | Cost: 0.0493\n",
      "Epoch: 070/100 | Batch 120/192 | Cost: 0.0360\n",
      "Epoch: 070/100 Train Acc.: 98.44% | Validation Acc.: 86.20%\n",
      "Time elapsed: 57.80 min\n",
      "Epoch: 071/100 | Batch 000/192 | Cost: 0.0335\n",
      "Epoch: 071/100 | Batch 120/192 | Cost: 0.0859\n",
      "Epoch: 071/100 Train Acc.: 97.87% | Validation Acc.: 84.90%\n",
      "Time elapsed: 58.62 min\n",
      "Epoch: 072/100 | Batch 000/192 | Cost: 0.0306\n",
      "Epoch: 072/100 | Batch 120/192 | Cost: 0.0836\n",
      "Epoch: 072/100 Train Acc.: 97.95% | Validation Acc.: 85.40%\n",
      "Time elapsed: 59.45 min\n",
      "Epoch: 073/100 | Batch 000/192 | Cost: 0.0510\n",
      "Epoch: 073/100 | Batch 120/192 | Cost: 0.0725\n",
      "Epoch: 073/100 Train Acc.: 98.22% | Validation Acc.: 85.70%\n",
      "Time elapsed: 60.28 min\n",
      "Epoch: 074/100 | Batch 000/192 | Cost: 0.0375\n",
      "Epoch: 074/100 | Batch 120/192 | Cost: 0.0903\n",
      "Epoch: 074/100 Train Acc.: 98.29% | Validation Acc.: 85.50%\n",
      "Time elapsed: 61.10 min\n",
      "Epoch: 075/100 | Batch 000/192 | Cost: 0.0392\n",
      "Epoch: 075/100 | Batch 120/192 | Cost: 0.0365\n",
      "Epoch: 075/100 Train Acc.: 98.29% | Validation Acc.: 85.30%\n",
      "Time elapsed: 61.93 min\n",
      "Epoch: 076/100 | Batch 000/192 | Cost: 0.1071\n",
      "Epoch: 076/100 | Batch 120/192 | Cost: 0.0261\n",
      "Epoch: 076/100 Train Acc.: 98.41% | Validation Acc.: 85.80%\n",
      "Time elapsed: 62.75 min\n",
      "Epoch: 077/100 | Batch 000/192 | Cost: 0.0611\n",
      "Epoch: 077/100 | Batch 120/192 | Cost: 0.1131\n",
      "Epoch: 077/100 Train Acc.: 98.42% | Validation Acc.: 86.20%\n",
      "Time elapsed: 63.58 min\n",
      "Epoch: 078/100 | Batch 000/192 | Cost: 0.0522\n",
      "Epoch: 078/100 | Batch 120/192 | Cost: 0.0263\n",
      "Epoch: 078/100 Train Acc.: 98.16% | Validation Acc.: 85.60%\n",
      "Time elapsed: 64.41 min\n",
      "Epoch: 079/100 | Batch 000/192 | Cost: 0.0576\n",
      "Epoch: 079/100 | Batch 120/192 | Cost: 0.0462\n",
      "Epoch: 079/100 Train Acc.: 98.20% | Validation Acc.: 86.20%\n",
      "Time elapsed: 65.23 min\n",
      "Epoch: 080/100 | Batch 000/192 | Cost: 0.0580\n",
      "Epoch: 080/100 | Batch 120/192 | Cost: 0.0245\n",
      "Epoch: 080/100 Train Acc.: 98.37% | Validation Acc.: 85.70%\n",
      "Time elapsed: 66.06 min\n",
      "Epoch: 081/100 | Batch 000/192 | Cost: 0.0499\n",
      "Epoch: 081/100 | Batch 120/192 | Cost: 0.0384\n",
      "Epoch: 081/100 Train Acc.: 98.39% | Validation Acc.: 87.10%\n",
      "Time elapsed: 66.88 min\n",
      "Epoch: 082/100 | Batch 000/192 | Cost: 0.0154\n",
      "Epoch: 082/100 | Batch 120/192 | Cost: 0.0824\n",
      "Epoch: 082/100 Train Acc.: 98.04% | Validation Acc.: 86.60%\n",
      "Time elapsed: 67.71 min\n",
      "Epoch: 083/100 | Batch 000/192 | Cost: 0.0872\n",
      "Epoch: 083/100 | Batch 120/192 | Cost: 0.0491\n",
      "Epoch: 083/100 Train Acc.: 98.26% | Validation Acc.: 84.40%\n",
      "Time elapsed: 68.53 min\n",
      "Epoch: 084/100 | Batch 000/192 | Cost: 0.0194\n",
      "Epoch: 084/100 | Batch 120/192 | Cost: 0.0214\n",
      "Epoch: 084/100 Train Acc.: 98.63% | Validation Acc.: 87.20%\n",
      "Time elapsed: 69.36 min\n",
      "Epoch: 085/100 | Batch 000/192 | Cost: 0.0320\n",
      "Epoch: 085/100 | Batch 120/192 | Cost: 0.0316\n",
      "Epoch: 085/100 Train Acc.: 98.56% | Validation Acc.: 85.90%\n",
      "Time elapsed: 70.18 min\n",
      "Epoch: 086/100 | Batch 000/192 | Cost: 0.0562\n",
      "Epoch: 086/100 | Batch 120/192 | Cost: 0.0283\n",
      "Epoch: 086/100 Train Acc.: 98.47% | Validation Acc.: 86.20%\n",
      "Time elapsed: 71.01 min\n",
      "Epoch: 087/100 | Batch 000/192 | Cost: 0.0770\n",
      "Epoch: 087/100 | Batch 120/192 | Cost: 0.0719\n",
      "Epoch: 087/100 Train Acc.: 98.33% | Validation Acc.: 85.20%\n",
      "Time elapsed: 71.84 min\n",
      "Epoch: 088/100 | Batch 000/192 | Cost: 0.0591\n",
      "Epoch: 088/100 | Batch 120/192 | Cost: 0.0468\n",
      "Epoch: 088/100 Train Acc.: 98.46% | Validation Acc.: 86.40%\n",
      "Time elapsed: 72.66 min\n",
      "Epoch: 089/100 | Batch 000/192 | Cost: 0.0435\n",
      "Epoch: 089/100 | Batch 120/192 | Cost: 0.0248\n",
      "Epoch: 089/100 Train Acc.: 98.45% | Validation Acc.: 85.50%\n",
      "Time elapsed: 73.49 min\n",
      "Epoch: 090/100 | Batch 000/192 | Cost: 0.0452\n",
      "Epoch: 090/100 | Batch 120/192 | Cost: 0.0479\n",
      "Epoch: 090/100 Train Acc.: 98.60% | Validation Acc.: 86.70%\n",
      "Time elapsed: 74.31 min\n",
      "Epoch: 091/100 | Batch 000/192 | Cost: 0.0208\n",
      "Epoch: 091/100 | Batch 120/192 | Cost: 0.0224\n",
      "Epoch: 091/100 Train Acc.: 98.67% | Validation Acc.: 87.10%\n",
      "Time elapsed: 75.14 min\n",
      "Epoch: 092/100 | Batch 000/192 | Cost: 0.0497\n",
      "Epoch: 092/100 | Batch 120/192 | Cost: 0.0285\n",
      "Epoch: 092/100 Train Acc.: 98.76% | Validation Acc.: 86.90%\n",
      "Time elapsed: 75.96 min\n",
      "Epoch: 093/100 | Batch 000/192 | Cost: 0.0267\n",
      "Epoch: 093/100 | Batch 120/192 | Cost: 0.0270\n",
      "Epoch: 093/100 Train Acc.: 98.57% | Validation Acc.: 85.70%\n",
      "Time elapsed: 76.79 min\n",
      "Epoch: 094/100 | Batch 000/192 | Cost: 0.0233\n",
      "Epoch: 094/100 | Batch 120/192 | Cost: 0.0565\n",
      "Epoch: 094/100 Train Acc.: 98.56% | Validation Acc.: 86.40%\n",
      "Time elapsed: 77.61 min\n",
      "Epoch: 095/100 | Batch 000/192 | Cost: 0.0161\n",
      "Epoch: 095/100 | Batch 120/192 | Cost: 0.0442\n",
      "Epoch: 095/100 Train Acc.: 98.51% | Validation Acc.: 86.00%\n",
      "Time elapsed: 78.44 min\n",
      "Epoch: 096/100 | Batch 000/192 | Cost: 0.0369\n",
      "Epoch: 096/100 | Batch 120/192 | Cost: 0.0702\n",
      "Epoch: 096/100 Train Acc.: 98.51% | Validation Acc.: 85.90%\n",
      "Time elapsed: 79.26 min\n",
      "Epoch: 097/100 | Batch 000/192 | Cost: 0.0336\n",
      "Epoch: 097/100 | Batch 120/192 | Cost: 0.0442\n",
      "Epoch: 097/100 Train Acc.: 98.62% | Validation Acc.: 85.50%\n",
      "Time elapsed: 80.09 min\n",
      "Epoch: 098/100 | Batch 000/192 | Cost: 0.0641\n",
      "Epoch: 098/100 | Batch 120/192 | Cost: 0.0848\n",
      "Epoch: 098/100 Train Acc.: 98.67% | Validation Acc.: 86.70%\n",
      "Time elapsed: 80.92 min\n",
      "Epoch: 099/100 | Batch 000/192 | Cost: 0.0203\n",
      "Epoch: 099/100 | Batch 120/192 | Cost: 0.0482\n",
      "Epoch: 099/100 Train Acc.: 98.55% | Validation Acc.: 86.10%\n",
      "Time elapsed: 81.74 min\n",
      "Epoch: 100/100 | Batch 000/192 | Cost: 0.0496\n",
      "Epoch: 100/100 | Batch 120/192 | Cost: 0.0195\n",
      "Epoch: 100/100 Train Acc.: 98.64% | Validation Acc.: 86.10%\n",
      "Time elapsed: 82.57 min\n",
      "Total Training Time: 82.57 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  # 记录开始时间\n",
    "for epoch in range(NUM_EPOCHS):  # 循环遍历每个epoch\n",
    "    \n",
    "    model.train()  # 设置模型为训练模式\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):  # 循环遍历每个批次\n",
    "    \n",
    "        ### 准备小批量数据\n",
    "        features = features.to(DEVICE)  # 将特征转移到指定设备\n",
    "        targets = targets.to(DEVICE)  # 将目标标签转移到指定设备\n",
    "            \n",
    "        ### 前向传播和反向传播\n",
    "        logits, probas = model(features)  # 获取模型的输出\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        \n",
    "        cost.backward()  # 反向传播计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()  # 使用优化器更新参数\n",
    "        \n",
    "        ### 日志记录\n",
    "        if not batch_idx % 120:  # 每120个批次输出一次日志\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # 计算准确率时不需要构建计算图以进行反向传播\n",
    "    with torch.set_grad_enabled(False):  # 禁用梯度计算\n",
    "        train_acc = compute_accuracy(model, train_loader, device=DEVICE)  # 计算训练集准确率\n",
    "        valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)  # 计算验证集准确率\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')  # 输出准确率\n",
    "    \n",
    "    elapsed = (time.time() - start_time)/60  # 计算已经过去的时间（分钟）\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')  # 输出已用时间\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60  # 计算总训练时间（分钟）\n",
    "print(f'Total Training Time: {elapsed:.2f} min')  # 输出总训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 84.85%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # 在推理过程中禁用梯度计算，节省内存\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL        : 11.0.0\n",
      "pandas     : 2.2.3\n",
      "torchvision: 0.21.0+cu126\n",
      "matplotlib : 3.10.1\n",
      "numpy      : 2.1.2\n",
      "torch      : 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
