{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "*Accompanying code examples of the book \"Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python\" by [Sebastian Raschka](https://sebastianraschka.com). All code examples are released under the [MIT license](https://github.com/rasbt/deep-learning-book/blob/master/LICENSE). If you find this content useful, please consider supporting the work by buying a [copy of the book](https://leanpub.com/ann-and-deeplearning).*\n",
    "  \n",
    "Other code examples and content are available on [GitHub](https://github.com/rasbt/deep-learning-book). The PDF and ebook versions of the book are available through [Leanpub](https://leanpub.com/ann-and-deeplearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 9.0.2\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# Model Zoo -- ResNet-34 MNIST Digits Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network in this notebook is an implementation of the ResNet-34 [1] architecture on the MNIST digits dataset (http://yann.lecun.com/exdb/mnist/) to train a handwritten digit classifier.  \n",
    "本笔记本中的网络是基于MNIST数字数据集（http://yann.lecun.com/exdb/mnist/）实现的ResNet-34 [1]架构，用于训练手写数字分类器。\n",
    "\n",
    "References  \n",
    "参考文献\n",
    "\n",
    "- [1] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778). ([CVPR Link](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html))  \n",
    "- [1] He, K., Zhang, X., Ren, S., & Sun, J. (2016). 深度残差学习用于图像识别。在IEEE计算机视觉与模式识别会议论文集（第770-778页）。([CVPR 链接](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html))\n",
    "\n",
    "- [2] http://yann.lecun.com/exdb/mnist/  \n",
    "- [2] http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "![](../images/resnets/resnet34/resnet34-arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure illustrates residual blocks with skip connections such that the input passed via the shortcut matches the dimensions of the main path's output, which allows the network to learn identity functions.  \n",
    "下图展示了带有跳跃连接的残差块，使得通过快捷方式传递的输入与主路径输出的维度相匹配，从而使网络能够学习恒等函数。\n",
    "\n",
    "![](../images/resnets/resnet-ex-1-1.png)\n",
    "\n",
    "The ResNet-34 architecture actually uses residual blocks with skip connections such that the input passed via the shortcut matches is resized to dimensions of the main path's output. Such a residual block is illustrated below:  \n",
    "ResNet-34架构实际上使用带有跳跃连接的残差块，使得通过快捷方式传递的输入被调整为与主路径输出的维度匹配。下图展示了这样的残差块：\n",
    "\n",
    "![](../images/resnets/resnet-ex-1-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more detailed explanation see the other notebook, [resnet-ex-1.ipynb](resnet-ex-1.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.set_per_process_memory_fraction(0.5, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### 设置\n",
    "##########################\n",
    "\n",
    "# 超参数\n",
    "RANDOM_SEED = 1  # 随机种子，用于确保实验结果可复现\n",
    "LEARNING_RATE = 0.001  # 学习率\n",
    "BATCH_SIZE = 128  # 批次大小\n",
    "NUM_EPOCHS = 10  # 训练的总轮数\n",
    "\n",
    "# 网络架构\n",
    "NUM_FEATURES = 28*28  # 输入特征数（假设输入图像大小为28x28）\n",
    "NUM_CLASSES = 10  # 分类数目（例如，手写数字分类任务中的0-9，共10类）\n",
    "\n",
    "# 其他设置\n",
    "DEVICE = \"cuda:0\"  # 指定使用的设备，这里选择第三个GPU（cuda:0）\n",
    "GRAYSCALE = True  # 是否使用灰度图像（True表示使用灰度图像，False表示使用RGB图像）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像批次维度: torch.Size([128, 1, 28, 28])\n",
      "图像标签维度: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### MNIST 数据集\n",
    "##########################\n",
    "\n",
    "# 注意 transforms.ToTensor() 会将输入图像缩放到 0-1 范围\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True,  # 训练集\n",
    "                               transform=transforms.ToTensor(),  # 转换为Tensor格式\n",
    "                               download=True)  # 如果数据集不存在，下载数据集\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False,  # 测试集\n",
    "                              transform=transforms.ToTensor())  # 转换为Tensor格式\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,  # 设置批量大小\n",
    "                          shuffle=True)  # 是否打乱数据\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,  # 设置批量大小\n",
    "                         shuffle=False)  # 不打乱测试数据\n",
    "\n",
    "# 检查数据集\n",
    "for images, labels in train_loader:  # 遍历训练数据加载器中的每个batch  \n",
    "    print('图像批次维度:', images.shape)  # 打印图像的维度\n",
    "    print('图像标签维度:', labels.shape)  # 打印标签的维度\n",
    "    break  # 只打印一次数据维度，避免浪费计算资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell that implements the ResNet-34 architecture is a derivative of the code provided at https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3卷积，带填充\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # 第一层卷积层\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        # 第一层BatchNorm层\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # 激活函数ReLU\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 第二层卷积层\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        # 第二层BatchNorm层\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        # 下采样层（如果有的话）\n",
    "        self.downsample = downsample\n",
    "        # 步幅\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        # 经过第一层卷积、BatchNorm和ReLU\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 经过第二层卷积和BatchNorm\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 如果有下采样，修改残差\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        # 残差连接\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        # 判断是否为灰度图像\n",
    "        if grayscale:\n",
    "            in_dim = 1  # 灰度图像通道数为1\n",
    "        else:\n",
    "            in_dim = 3  # RGB图像通道数为3\n",
    "        super(ResNet, self).__init__()\n",
    "        # 第一层卷积，7x7的卷积核\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        # 第一层BatchNorm层\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # 激活函数ReLU\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 最大池化层\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 第一个残差块\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        # 第二个残差块\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        # 第三个残差块\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        # 第四个残差块\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        # 平均池化层（为了做分类而做的池化）\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # 初始化网络参数\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        # 判断是否需要下采样\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # 添加第一个block\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        # 添加后续的block\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一层卷积\n",
    "        x = self.conv1(x)\n",
    "        # 第一层BatchNorm\n",
    "        x = self.bn1(x)\n",
    "        # 激活函数ReLU\n",
    "        x = self.relu(x)\n",
    "        # 最大池化\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # 通过四个残差层\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # MNIST数据集已经是1x1的图像，可以跳过平均池化\n",
    "        # x = self.avgpool(x)\n",
    "        \n",
    "        # 展平处理，传入全连接层\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        # 计算预测的概率分布\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "def resnet34(num_classes):\n",
    "    \"\"\"构建ResNet-34模型\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=num_classes,\n",
    "                   grayscale=True)  # 默认非灰度图像\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = resnet34(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0469 | Cost: 2.5540\n",
      "Epoch: 001/010 | Batch 0050/0469 | Cost: 0.2696\n",
      "Epoch: 001/010 | Batch 0100/0469 | Cost: 0.1280\n",
      "Epoch: 001/010 | Batch 0150/0469 | Cost: 0.0498\n",
      "Epoch: 001/010 | Batch 0200/0469 | Cost: 0.1965\n",
      "Epoch: 001/010 | Batch 0250/0469 | Cost: 0.0673\n",
      "Epoch: 001/010 | Batch 0300/0469 | Cost: 0.0767\n",
      "Epoch: 001/010 | Batch 0350/0469 | Cost: 0.0612\n",
      "Epoch: 001/010 | Batch 0400/0469 | Cost: 0.0386\n",
      "Epoch: 001/010 | Batch 0450/0469 | Cost: 0.1125\n",
      "Epoch: 001/010 | Train: 97.845%\n",
      "Time elapsed: 0.19 min\n",
      "Epoch: 002/010 | Batch 0000/0469 | Cost: 0.0290\n",
      "Epoch: 002/010 | Batch 0050/0469 | Cost: 0.0456\n",
      "Epoch: 002/010 | Batch 0100/0469 | Cost: 0.0969\n",
      "Epoch: 002/010 | Batch 0150/0469 | Cost: 0.0422\n",
      "Epoch: 002/010 | Batch 0200/0469 | Cost: 0.0439\n",
      "Epoch: 002/010 | Batch 0250/0469 | Cost: 0.0133\n",
      "Epoch: 002/010 | Batch 0300/0469 | Cost: 0.0454\n",
      "Epoch: 002/010 | Batch 0350/0469 | Cost: 0.0352\n",
      "Epoch: 002/010 | Batch 0400/0469 | Cost: 0.0623\n",
      "Epoch: 002/010 | Batch 0450/0469 | Cost: 0.0845\n",
      "Epoch: 002/010 | Train: 96.153%\n",
      "Time elapsed: 0.37 min\n",
      "Epoch: 003/010 | Batch 0000/0469 | Cost: 0.0379\n",
      "Epoch: 003/010 | Batch 0050/0469 | Cost: 0.0205\n",
      "Epoch: 003/010 | Batch 0100/0469 | Cost: 0.0354\n",
      "Epoch: 003/010 | Batch 0150/0469 | Cost: 0.0475\n",
      "Epoch: 003/010 | Batch 0200/0469 | Cost: 0.0552\n",
      "Epoch: 003/010 | Batch 0250/0469 | Cost: 0.0140\n",
      "Epoch: 003/010 | Batch 0300/0469 | Cost: 0.0808\n",
      "Epoch: 003/010 | Batch 0350/0469 | Cost: 0.0641\n",
      "Epoch: 003/010 | Batch 0400/0469 | Cost: 0.0501\n",
      "Epoch: 003/010 | Batch 0450/0469 | Cost: 0.0202\n",
      "Epoch: 003/010 | Train: 98.290%\n",
      "Time elapsed: 0.55 min\n",
      "Epoch: 004/010 | Batch 0000/0469 | Cost: 0.0299\n",
      "Epoch: 004/010 | Batch 0050/0469 | Cost: 0.0348\n",
      "Epoch: 004/010 | Batch 0100/0469 | Cost: 0.0207\n",
      "Epoch: 004/010 | Batch 0150/0469 | Cost: 0.0170\n",
      "Epoch: 004/010 | Batch 0200/0469 | Cost: 0.0167\n",
      "Epoch: 004/010 | Batch 0250/0469 | Cost: 0.0088\n",
      "Epoch: 004/010 | Batch 0300/0469 | Cost: 0.0244\n",
      "Epoch: 004/010 | Batch 0350/0469 | Cost: 0.0197\n",
      "Epoch: 004/010 | Batch 0400/0469 | Cost: 0.0160\n",
      "Epoch: 004/010 | Batch 0450/0469 | Cost: 0.0454\n",
      "Epoch: 004/010 | Train: 98.795%\n",
      "Time elapsed: 0.73 min\n",
      "Epoch: 005/010 | Batch 0000/0469 | Cost: 0.0110\n",
      "Epoch: 005/010 | Batch 0050/0469 | Cost: 0.0231\n",
      "Epoch: 005/010 | Batch 0100/0469 | Cost: 0.0187\n",
      "Epoch: 005/010 | Batch 0150/0469 | Cost: 0.0456\n",
      "Epoch: 005/010 | Batch 0200/0469 | Cost: 0.1351\n",
      "Epoch: 005/010 | Batch 0250/0469 | Cost: 0.0486\n",
      "Epoch: 005/010 | Batch 0300/0469 | Cost: 0.0104\n",
      "Epoch: 005/010 | Batch 0350/0469 | Cost: 0.0065\n",
      "Epoch: 005/010 | Batch 0400/0469 | Cost: 0.0349\n",
      "Epoch: 005/010 | Batch 0450/0469 | Cost: 0.0251\n",
      "Epoch: 005/010 | Train: 99.050%\n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 006/010 | Batch 0000/0469 | Cost: 0.0199\n",
      "Epoch: 006/010 | Batch 0050/0469 | Cost: 0.0165\n",
      "Epoch: 006/010 | Batch 0100/0469 | Cost: 0.0351\n",
      "Epoch: 006/010 | Batch 0150/0469 | Cost: 0.0527\n",
      "Epoch: 006/010 | Batch 0200/0469 | Cost: 0.1192\n",
      "Epoch: 006/010 | Batch 0250/0469 | Cost: 0.0186\n",
      "Epoch: 006/010 | Batch 0300/0469 | Cost: 0.0156\n",
      "Epoch: 006/010 | Batch 0350/0469 | Cost: 0.0343\n",
      "Epoch: 006/010 | Batch 0400/0469 | Cost: 0.0131\n",
      "Epoch: 006/010 | Batch 0450/0469 | Cost: 0.0240\n",
      "Epoch: 006/010 | Train: 99.250%\n",
      "Time elapsed: 1.09 min\n",
      "Epoch: 007/010 | Batch 0000/0469 | Cost: 0.0041\n",
      "Epoch: 007/010 | Batch 0050/0469 | Cost: 0.0130\n",
      "Epoch: 007/010 | Batch 0100/0469 | Cost: 0.0166\n",
      "Epoch: 007/010 | Batch 0150/0469 | Cost: 0.0042\n",
      "Epoch: 007/010 | Batch 0200/0469 | Cost: 0.0799\n",
      "Epoch: 007/010 | Batch 0250/0469 | Cost: 0.0136\n",
      "Epoch: 007/010 | Batch 0300/0469 | Cost: 0.0515\n",
      "Epoch: 007/010 | Batch 0350/0469 | Cost: 0.0192\n",
      "Epoch: 007/010 | Batch 0400/0469 | Cost: 0.0311\n",
      "Epoch: 007/010 | Batch 0450/0469 | Cost: 0.0686\n",
      "Epoch: 007/010 | Train: 97.977%\n",
      "Time elapsed: 1.28 min\n",
      "Epoch: 008/010 | Batch 0000/0469 | Cost: 0.0423\n",
      "Epoch: 008/010 | Batch 0050/0469 | Cost: 0.0125\n",
      "Epoch: 008/010 | Batch 0100/0469 | Cost: 0.0274\n",
      "Epoch: 008/010 | Batch 0150/0469 | Cost: 0.0093\n",
      "Epoch: 008/010 | Batch 0200/0469 | Cost: 0.0073\n",
      "Epoch: 008/010 | Batch 0250/0469 | Cost: 0.0042\n",
      "Epoch: 008/010 | Batch 0300/0469 | Cost: 0.0145\n",
      "Epoch: 008/010 | Batch 0350/0469 | Cost: 0.0068\n",
      "Epoch: 008/010 | Batch 0400/0469 | Cost: 0.0932\n",
      "Epoch: 008/010 | Batch 0450/0469 | Cost: 0.0149\n",
      "Epoch: 008/010 | Train: 99.128%\n",
      "Time elapsed: 1.46 min\n",
      "Epoch: 009/010 | Batch 0000/0469 | Cost: 0.0019\n",
      "Epoch: 009/010 | Batch 0050/0469 | Cost: 0.0466\n",
      "Epoch: 009/010 | Batch 0100/0469 | Cost: 0.0008\n",
      "Epoch: 009/010 | Batch 0150/0469 | Cost: 0.0067\n",
      "Epoch: 009/010 | Batch 0200/0469 | Cost: 0.0444\n",
      "Epoch: 009/010 | Batch 0250/0469 | Cost: 0.0130\n",
      "Epoch: 009/010 | Batch 0300/0469 | Cost: 0.0272\n",
      "Epoch: 009/010 | Batch 0350/0469 | Cost: 0.0143\n",
      "Epoch: 009/010 | Batch 0400/0469 | Cost: 0.0037\n",
      "Epoch: 009/010 | Batch 0450/0469 | Cost: 0.0045\n",
      "Epoch: 009/010 | Train: 99.245%\n",
      "Time elapsed: 1.64 min\n",
      "Epoch: 010/010 | Batch 0000/0469 | Cost: 0.0018\n",
      "Epoch: 010/010 | Batch 0050/0469 | Cost: 0.0009\n",
      "Epoch: 010/010 | Batch 0100/0469 | Cost: 0.0089\n",
      "Epoch: 010/010 | Batch 0150/0469 | Cost: 0.0006\n",
      "Epoch: 010/010 | Batch 0200/0469 | Cost: 0.0014\n",
      "Epoch: 010/010 | Batch 0250/0469 | Cost: 0.0113\n",
      "Epoch: 010/010 | Batch 0300/0469 | Cost: 0.0278\n",
      "Epoch: 010/010 | Batch 0350/0469 | Cost: 0.0641\n",
      "Epoch: 010/010 | Batch 0400/0469 | Cost: 0.0035\n",
      "Epoch: 010/010 | Batch 0450/0469 | Cost: 0.0100\n",
      "Epoch: 010/010 | Train: 99.442%\n",
      "Time elapsed: 1.82 min\n",
      "Total Training Time: 1.82 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0  # 初始化正确预测的数量和总样本数\n",
    "    for i, (features, targets) in enumerate(data_loader):  # 遍历数据加载器中的每个批次\n",
    "        features = features.to(device)  # 将特征移到指定设备\n",
    "        targets = targets.to(device)  # 将标签移到指定设备\n",
    "\n",
    "        logits, probas = model(features)  # 前向传播，得到logits和预测概率\n",
    "        _, predicted_labels = torch.max(probas, 1)  # 获取概率最大的类别\n",
    "        num_examples += targets.size(0)  # 增加批次中的样本数\n",
    "        correct_pred += (predicted_labels == targets).sum()  # 计算正确预测的数量\n",
    "    # 返回准确率（百分比），使用float()转换为浮点数\n",
    "    return correct_pred.float()/num_examples * 100  \n",
    "\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "for epoch in range(NUM_EPOCHS):  # 遍历所有训练轮次\n",
    "    \n",
    "    model.train()  # 设置模型为训练模式\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):  # 遍历训练数据\n",
    "        features = features.to(DEVICE)  # 将特征移到指定设备\n",
    "        targets = targets.to(DEVICE)  # 将标签移到指定设备\n",
    "            \n",
    "        ### 正向传播和反向传播\n",
    "        logits, probas = model(features)  # 前向传播，得到logits和预测概率\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清空之前的梯度\n",
    "        \n",
    "        cost.backward()  # 反向传播，计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        \n",
    "        ### 记录日志\n",
    "        if not batch_idx % 50:  # 每50个批次打印一次日志\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    # 设置模型为评估模式，以防在推理过程中更新批归一化参数\n",
    "    model.eval()  \n",
    "    with torch.set_grad_enabled(False):  # 在推理过程中禁用梯度计算，节省内存\n",
    "        # 打印训练集上的准确率\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))  \n",
    "\n",
    "    # 打印已用时间，单位：分钟\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))  \n",
    "    \n",
    "# 打印总训练时间，单位：分钟\n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.92%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # 在推理过程中禁用梯度计算，节省内存\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "    \n",
    "    \n",
    "nhwc_img = np.transpose(features[0], axes=(1, 2, 0))\n",
    "nhw_img = np.squeeze(nhwc_img.numpy(), axis=2)\n",
    "plt.imshow(nhw_img, cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability 7 100.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "logits, probas = model(features.to(device)[0, None])\n",
    "print('Probability 7 %.2f%%' % (probas[0][7]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch      : 2.6.0+cu126\n",
      "numpy      : 1.26.4\n",
      "matplotlib : 3.10.1\n",
      "pandas     : 2.2.3\n",
      "PIL        : 11.1.0\n",
      "torchvision: 0.21.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
