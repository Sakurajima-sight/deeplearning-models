{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
    "- Author: Sebastian Raschka\n",
    "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 8.30.0\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Runs on CPU or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo -Standardizing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example for working with standardized images, that is, images where the image pixels in each image has mean zero and unit variance across the channel.\n",
    "本笔记本提供了一个标准化图像的示例，即图像中每个像素在各通道中具有零均值和单位方差的图像。\n",
    "\n",
    "The general equation for z-score standardization is computed as\n",
    "z-score标准化的通用公式如下计算：\n",
    "\n",
    "$$x' = \\frac{x_i - \\mu}{\\sigma}$$\n",
    "\n",
    "where $\\mu$ is the mean and $\\sigma$ is the standard deviation of the training set, respectively. Then $x_i'$ is the scaled feature feature value, and $x_i$ is the original feature value.\n",
    "其中，$\\mu$ 是训练集的均值，$\\sigma$ 是标准差。然后 $x_i'$ 是缩放后的特征值，$x_i$ 是原始特征值。\n",
    "\n",
    "I.e, for grayscale images, we would obtain 1 mean and 1 standard deviation. For RGB images (3 color channels), we would obtain 3 mean values and 3 standard deviations.\n",
    "也就是说，对于灰度图像，我们将获得一个均值和一个标准差。对于RGB图像（3个颜色通道），我们将获得3个均值和3个标准差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 设置\n",
    "##########################\n",
    "\n",
    "# 设备设置\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # 如果GPU可用，使用GPU，否则使用CPU\n",
    "\n",
    "# 超参数设置\n",
    "random_seed = 1  # 随机种子\n",
    "learning_rate = 0.05  # 学习率\n",
    "num_epochs = 10  # 训练的轮次\n",
    "batch_size = 128  # 每个批次的样本数\n",
    "\n",
    "# 网络架构设置\n",
    "num_classes = 10  # 类别数量（CIFAR-10有10个类别）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Mean and Standard Deviation for Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to determine the mean and standard deviation for each color channel in the training set.  \n",
    "首先，我们需要确定训练集中每个颜色通道的均值和标准差。\n",
    "\n",
    "Since we assume the entire dataset does not fit into the computer memory all at once, we do this in an incremental fashion, as shown below.  \n",
    "由于我们假设整个数据集无法一次性加载到计算机内存中，因此我们采用增量方式进行处理，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.1307])\n",
      "Std Dev: tensor([0.3077])\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "### 初步数据加载器\n",
    "##############################\n",
    "\n",
    "\n",
    "# 加载MNIST训练数据集\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True,  # 训练集\n",
    "                               transform=transforms.ToTensor(),  # 转换为Tensor格式\n",
    "                               download=True)  # 如果数据集不存在，则下载\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size,  # 批次大小\n",
    "                          shuffle=False)  # 不打乱数据\n",
    "\n",
    "# 初始化存储均值和标准差的列表\n",
    "train_mean = []\n",
    "train_std = []\n",
    "\n",
    "# 计算训练集的均值和标准差\n",
    "for i, image in enumerate(train_loader, 0):  # 遍历数据加载器\n",
    "    numpy_image = image[0].numpy()  # 将图像数据转换为numpy数组\n",
    "    \n",
    "    # 计算当前批次的均值和标准差，axis=(0, 2, 3)表示按（通道，高度，宽度）维度计算\n",
    "    batch_mean = np.mean(numpy_image, axis=(0, 2, 3))\n",
    "    batch_std = np.std(numpy_image, axis=(0, 2, 3))\n",
    "    \n",
    "    # 将批次的均值和标准差添加到列表中\n",
    "    train_mean.append(batch_mean)\n",
    "    train_std.append(batch_std)\n",
    "\n",
    "# 计算整个训练集的均值和标准差\n",
    "train_mean = torch.tensor(np.mean(train_mean, axis=0))  # 计算均值\n",
    "train_std = torch.tensor(np.mean(train_std, axis=0))  # 计算标准差\n",
    "\n",
    "# 打印训练集的均值和标准差\n",
    "print('Mean:', train_mean)\n",
    "print('Std Dev:', train_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that**  \n",
    "**请注意，**\n",
    "\n",
    "- For RGB images (3 color channels), we would get 3 means and 3 standard deviations.  \n",
    "- 对于RGB图像（3个颜色通道），我们会得到3个均值和3个标准差。\n",
    "\n",
    "- The transforms.ToTensor() method converts images to [0, 1] range, which is why the mean and standard deviation values are below 1.  \n",
    "- transforms.ToTensor()方法将图像转换为[0, 1]范围，这就是为什么均值和标准差值低于1的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Dataset Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use a custom transform function to standardize the dataset according to the mean and standard deviation we computed above.  \n",
    "现在我们可以使用自定义转换函数，根据我们上面计算的均值和标准差对数据集进行标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=train_mean, std=train_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MNIST 数据集\n",
    "##########################\n",
    "\n",
    "# 注意：transforms.ToTensor() 将输入图像缩放到0到1的范围内\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True,  # 使用训练集\n",
    "                               transform=custom_transform,  # 自定义的数据转换操作\n",
    "                               download=True)  # 如果数据集不存在，则下载\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False,  # 使用测试集\n",
    "                              transform=custom_transform)  # 自定义的数据转换操作\n",
    "\n",
    "\n",
    "# 创建训练数据加载器\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size,  # 批次大小\n",
    "                          shuffle=True)  # 打乱数据\n",
    "\n",
    "# 创建测试数据加载器\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,  # 批次大小\n",
    "                         shuffle=False)  # 不打乱数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the dataset can be loaded:  \n",
    "检查数据集是否可以加载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given batch, check that the channel means and standard deviations are roughly 0 and 1, respectively:  \n",
    "对于给定的批次，检查各通道的均值和标准差是否分别接近0和1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel mean: tensor(-0.0112)\n",
      "Channel std: tensor(0.9893)\n"
     ]
    }
   ],
   "source": [
    "print('Channel mean:', torch.mean(images[:, 0, :, :]))\n",
    "print('Channel std:', torch.std(images[:, 0, :, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # 计算相同填充（same padding）：\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "        \n",
    "        # 28x28x1 => 28x28x4\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=1,  # 输入通道数为1（灰度图像）\n",
    "                                      out_channels=4,  # 输出通道数为4\n",
    "                                      kernel_size=(3, 3),  # 卷积核大小为3x3\n",
    "                                      stride=(1, 1),  # 步幅为1\n",
    "                                      padding=1)  # 填充为1，保持尺寸不变（计算：p = (1(28-1) - 28 + 3) / 2 = 1）\n",
    "        # 28x28x4 => 14x14x4\n",
    "        self.pool_1 = torch.nn.MaxPool2d(kernel_size=(2, 2),  # 最大池化层，池化大小为2x2\n",
    "                                         stride=(2, 2),  # 步幅为2\n",
    "                                         padding=0)  # 填充为0（计算：p = (2(14-1) - 28 + 2) = 0）\n",
    "                                       \n",
    "        # 14x14x4 => 14x14x8\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=4,  # 输入通道数为4\n",
    "                                      out_channels=8,  # 输出通道数为8\n",
    "                                      kernel_size=(3, 3),  # 卷积核大小为3x3\n",
    "                                      stride=(1, 1),  # 步幅为1\n",
    "                                      padding=1)  # 填充为1，保持尺寸不变（计算：p = (1(14-1) - 14 + 3) / 2 = 1）\n",
    "                 \n",
    "        # 14x14x8 => 7x7x8\n",
    "        self.pool_2 = torch.nn.MaxPool2d(kernel_size=(2, 2),  # 最大池化层，池化大小为2x2\n",
    "                                         stride=(2, 2),  # 步幅为2\n",
    "                                         padding=0)  # 填充为0（计算：p = (2(7-1) - 14 + 2) = 0）\n",
    "        \n",
    "        # 全连接层，将7*7*8个特征压缩为num_classes个类别\n",
    "        self.linear_1 = torch.nn.Linear(7*7*8, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 前向传播过程\n",
    "        out = self.conv_1(x)  # 经过第一层卷积\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "        out = self.pool_1(out)  # 经过池化层\n",
    "\n",
    "        out = self.conv_2(out)  # 经过第二层卷积\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "        out = self.pool_2(out)  # 经过池化层\n",
    "        \n",
    "        logits = self.linear_1(out.view(-1, 7*7*8))  # 将特征展平并通过全连接层\n",
    "        probas = F.softmax(logits, dim=1)  # 计算Softmax概率分布\n",
    "        return logits, probas  # 返回logits和概率分布\n",
    "\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# 初始化模型\n",
    "model = ConvNet(num_classes=num_classes)\n",
    "\n",
    "# 将模型转移到指定的设备（CPU或GPU）\n",
    "model = model.to(device)\n",
    "\n",
    "# 设置优化器，这里使用随机梯度下降（SGD）\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/469 | Cost: 2.3226\n",
      "Epoch: 001/010 | Batch 050/469 | Cost: 0.6868\n",
      "Epoch: 001/010 | Batch 100/469 | Cost: 0.3672\n",
      "Epoch: 001/010 | Batch 150/469 | Cost: 0.1709\n",
      "Epoch: 001/010 | Batch 200/469 | Cost: 0.1694\n",
      "Epoch: 001/010 | Batch 250/469 | Cost: 0.1217\n",
      "Epoch: 001/010 | Batch 300/469 | Cost: 0.1377\n",
      "Epoch: 001/010 | Batch 350/469 | Cost: 0.1646\n",
      "Epoch: 001/010 | Batch 400/469 | Cost: 0.1692\n",
      "Epoch: 001/010 | Batch 450/469 | Cost: 0.1302\n",
      "Epoch: 001/010 training accuracy: 93.54%\n",
      "Time elapsed: 0.09 min\n",
      "Epoch: 002/010 | Batch 000/469 | Cost: 0.3378\n",
      "Epoch: 002/010 | Batch 050/469 | Cost: 0.0870\n",
      "Epoch: 002/010 | Batch 100/469 | Cost: 0.1784\n",
      "Epoch: 002/010 | Batch 150/469 | Cost: 0.1351\n",
      "Epoch: 002/010 | Batch 200/469 | Cost: 0.1303\n",
      "Epoch: 002/010 | Batch 250/469 | Cost: 0.1283\n",
      "Epoch: 002/010 | Batch 300/469 | Cost: 0.0808\n",
      "Epoch: 002/010 | Batch 350/469 | Cost: 0.1514\n",
      "Epoch: 002/010 | Batch 400/469 | Cost: 0.1341\n",
      "Epoch: 002/010 | Batch 450/469 | Cost: 0.0904\n",
      "Epoch: 002/010 training accuracy: 96.52%\n",
      "Time elapsed: 0.18 min\n",
      "Epoch: 003/010 | Batch 000/469 | Cost: 0.1465\n",
      "Epoch: 003/010 | Batch 050/469 | Cost: 0.1320\n",
      "Epoch: 003/010 | Batch 100/469 | Cost: 0.1193\n",
      "Epoch: 003/010 | Batch 150/469 | Cost: 0.2385\n",
      "Epoch: 003/010 | Batch 200/469 | Cost: 0.1536\n",
      "Epoch: 003/010 | Batch 250/469 | Cost: 0.0505\n",
      "Epoch: 003/010 | Batch 300/469 | Cost: 0.1139\n",
      "Epoch: 003/010 | Batch 350/469 | Cost: 0.0742\n",
      "Epoch: 003/010 | Batch 400/469 | Cost: 0.0583\n",
      "Epoch: 003/010 | Batch 450/469 | Cost: 0.1205\n",
      "Epoch: 003/010 training accuracy: 96.99%\n",
      "Time elapsed: 0.27 min\n",
      "Epoch: 004/010 | Batch 000/469 | Cost: 0.0459\n",
      "Epoch: 004/010 | Batch 050/469 | Cost: 0.0913\n",
      "Epoch: 004/010 | Batch 100/469 | Cost: 0.1832\n",
      "Epoch: 004/010 | Batch 150/469 | Cost: 0.0748\n",
      "Epoch: 004/010 | Batch 200/469 | Cost: 0.0533\n",
      "Epoch: 004/010 | Batch 250/469 | Cost: 0.1223\n",
      "Epoch: 004/010 | Batch 300/469 | Cost: 0.0863\n",
      "Epoch: 004/010 | Batch 350/469 | Cost: 0.1308\n",
      "Epoch: 004/010 | Batch 400/469 | Cost: 0.0726\n",
      "Epoch: 004/010 | Batch 450/469 | Cost: 0.0690\n",
      "Epoch: 004/010 training accuracy: 96.91%\n",
      "Time elapsed: 0.35 min\n",
      "Epoch: 005/010 | Batch 000/469 | Cost: 0.0727\n",
      "Epoch: 005/010 | Batch 050/469 | Cost: 0.0864\n",
      "Epoch: 005/010 | Batch 100/469 | Cost: 0.0737\n",
      "Epoch: 005/010 | Batch 150/469 | Cost: 0.1257\n",
      "Epoch: 005/010 | Batch 200/469 | Cost: 0.0363\n",
      "Epoch: 005/010 | Batch 250/469 | Cost: 0.0399\n",
      "Epoch: 005/010 | Batch 300/469 | Cost: 0.0280\n",
      "Epoch: 005/010 | Batch 350/469 | Cost: 0.0841\n",
      "Epoch: 005/010 | Batch 400/469 | Cost: 0.0619\n",
      "Epoch: 005/010 | Batch 450/469 | Cost: 0.0932\n",
      "Epoch: 005/010 training accuracy: 97.62%\n",
      "Time elapsed: 0.44 min\n",
      "Epoch: 006/010 | Batch 000/469 | Cost: 0.0610\n",
      "Epoch: 006/010 | Batch 050/469 | Cost: 0.0787\n",
      "Epoch: 006/010 | Batch 100/469 | Cost: 0.1717\n",
      "Epoch: 006/010 | Batch 150/469 | Cost: 0.0761\n",
      "Epoch: 006/010 | Batch 200/469 | Cost: 0.0702\n",
      "Epoch: 006/010 | Batch 250/469 | Cost: 0.1072\n",
      "Epoch: 006/010 | Batch 300/469 | Cost: 0.1106\n",
      "Epoch: 006/010 | Batch 350/469 | Cost: 0.0973\n",
      "Epoch: 006/010 | Batch 400/469 | Cost: 0.0617\n",
      "Epoch: 006/010 | Batch 450/469 | Cost: 0.0263\n",
      "Epoch: 006/010 training accuracy: 97.93%\n",
      "Time elapsed: 0.53 min\n",
      "Epoch: 007/010 | Batch 000/469 | Cost: 0.1347\n",
      "Epoch: 007/010 | Batch 050/469 | Cost: 0.0946\n",
      "Epoch: 007/010 | Batch 100/469 | Cost: 0.0482\n",
      "Epoch: 007/010 | Batch 150/469 | Cost: 0.0373\n",
      "Epoch: 007/010 | Batch 200/469 | Cost: 0.0524\n",
      "Epoch: 007/010 | Batch 250/469 | Cost: 0.1448\n",
      "Epoch: 007/010 | Batch 300/469 | Cost: 0.0886\n",
      "Epoch: 007/010 | Batch 350/469 | Cost: 0.0726\n",
      "Epoch: 007/010 | Batch 400/469 | Cost: 0.0649\n",
      "Epoch: 007/010 | Batch 450/469 | Cost: 0.0920\n",
      "Epoch: 007/010 training accuracy: 98.01%\n",
      "Time elapsed: 0.62 min\n",
      "Epoch: 008/010 | Batch 000/469 | Cost: 0.0642\n",
      "Epoch: 008/010 | Batch 050/469 | Cost: 0.0473\n",
      "Epoch: 008/010 | Batch 100/469 | Cost: 0.0651\n",
      "Epoch: 008/010 | Batch 150/469 | Cost: 0.0373\n",
      "Epoch: 008/010 | Batch 200/469 | Cost: 0.0673\n",
      "Epoch: 008/010 | Batch 250/469 | Cost: 0.0771\n",
      "Epoch: 008/010 | Batch 300/469 | Cost: 0.0159\n",
      "Epoch: 008/010 | Batch 350/469 | Cost: 0.1421\n",
      "Epoch: 008/010 | Batch 400/469 | Cost: 0.0729\n",
      "Epoch: 008/010 | Batch 450/469 | Cost: 0.0776\n",
      "Epoch: 008/010 training accuracy: 98.17%\n",
      "Time elapsed: 0.70 min\n",
      "Epoch: 009/010 | Batch 000/469 | Cost: 0.0940\n",
      "Epoch: 009/010 | Batch 050/469 | Cost: 0.0670\n",
      "Epoch: 009/010 | Batch 100/469 | Cost: 0.0202\n",
      "Epoch: 009/010 | Batch 150/469 | Cost: 0.0353\n",
      "Epoch: 009/010 | Batch 200/469 | Cost: 0.1585\n",
      "Epoch: 009/010 | Batch 250/469 | Cost: 0.0315\n",
      "Epoch: 009/010 | Batch 300/469 | Cost: 0.0720\n",
      "Epoch: 009/010 | Batch 350/469 | Cost: 0.1178\n",
      "Epoch: 009/010 | Batch 400/469 | Cost: 0.0394\n",
      "Epoch: 009/010 | Batch 450/469 | Cost: 0.0363\n",
      "Epoch: 009/010 training accuracy: 98.28%\n",
      "Time elapsed: 0.80 min\n",
      "Epoch: 010/010 | Batch 000/469 | Cost: 0.0536\n",
      "Epoch: 010/010 | Batch 050/469 | Cost: 0.0103\n",
      "Epoch: 010/010 | Batch 100/469 | Cost: 0.0297\n",
      "Epoch: 010/010 | Batch 150/469 | Cost: 0.0639\n",
      "Epoch: 010/010 | Batch 200/469 | Cost: 0.0607\n",
      "Epoch: 010/010 | Batch 250/469 | Cost: 0.0726\n",
      "Epoch: 010/010 | Batch 300/469 | Cost: 0.0404\n",
      "Epoch: 010/010 | Batch 350/469 | Cost: 0.0745\n",
      "Epoch: 010/010 | Batch 400/469 | Cost: 0.0267\n",
      "Epoch: 010/010 | Batch 450/469 | Cost: 0.0563\n",
      "Epoch: 010/010 training accuracy: 98.39%\n",
      "Time elapsed: 0.89 min\n",
      "Total Training Time: 0.89 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for features, targets in data_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "    \n",
    "    model = model.eval()\n",
    "    print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "          epoch+1, num_epochs, \n",
    "          compute_accuracy(model, train_loader)))\n",
    "    \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.27%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch      : 2.6.0+cu126\n",
      "torchvision: 0.21.0+cu126\n",
      "numpy      : 2.1.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
