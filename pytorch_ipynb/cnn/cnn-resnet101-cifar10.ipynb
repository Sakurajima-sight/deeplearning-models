{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
    "- Author: Sebastian Raschka\n",
    "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 9.0.2\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# ResNet-101 (on CIFAR-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network in this notebook is an implementation of the ResNet-101 [1] architecture on the CelebA face dataset [2] to train a gender classifier.  \n",
    "\n",
    "\n",
    "References\n",
    "    \n",
    "- [1] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778). ([CVPR Link](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html))\n",
    "\n",
    "- [2] Zhang, K., Tan, L., Li, Z., & Qiao, Y. (2016). Gender and smile classification using deep convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (pp. 34-38).\n",
    "\n",
    "The ResNet-101 architecture is similar to the ResNet-50 architecture, which is in turn similar to the ResNet-34 architecture shown below (from [1]) except that the ResNet 101 is using a Bootleneck block (compared to ResNet-34) and more layers than ResNet-50 (figure shows a screenshot from [1]):\n",
    "\n",
    "\n",
    "![](../images/resnets/resnet101/resnet101-arch-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure illustrates residual blocks with skip connections such that the input passed via the shortcut matches the dimensions of the main path's output, which allows the network to learn identity functions.\n",
    "\n",
    "![](../images/resnets/resnet-ex-1-1.png)\n",
    "\n",
    "\n",
    "The ResNet-34 architecture actually uses residual blocks with modified skip connections such that the input passed via the shortcut matches is resized to dimensions of the main path's output. Such a residual block is illustrated below:\n",
    "\n",
    "![](../images/resnets/resnet-ex-1-2.png)\n",
    "\n",
    "The ResNet-50/101/151 then uses a bottleneck as shown below:\n",
    "\n",
    "![](../images/resnets/resnet-ex-1-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more detailed explanation see the other notebook, [resnet-ex-1.ipynb](resnet-ex-1.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.set_per_process_memory_fraction(0.5, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### 设置参数\n",
    "##########################\n",
    "\n",
    "# 超参数（Hyperparameters）\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# 网络结构相关参数（Architecture）\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = torch.device('cuda:0')\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像批次维度: torch.Size([128, 3, 32, 32])\n",
      "训练集标签批次维度: torch.Size([128])\n",
      "测试集图像批次维度: torch.Size([128, 3, 32, 32])\n",
      "测试集标签批次维度: torch.Size([128])\n",
      "验证集图像批次维度: torch.Size([128, 3, 32, 32])\n",
      "验证集标签批次维度: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### CIFAR-10 数据集\n",
    "##########################\n",
    "\n",
    "# 注意：transforms.ToTensor() 会将输入图像缩放到 0-1 范围\n",
    "\n",
    "# 划分训练集和验证集的索引\n",
    "train_indices = torch.arange(0, 49000)       # 前49,000张作为训练集\n",
    "valid_indices = torch.arange(49000, 50000)   # 剩余1,000张作为验证集\n",
    "\n",
    "# 下载并加载 CIFAR-10 数据集（训练集）\n",
    "train_and_valid = datasets.CIFAR10(root='data', \n",
    "                                   train=True, \n",
    "                                   transform=transforms.ToTensor(),  # 转换为Tensor并归一化\n",
    "                                   download=True)\n",
    "\n",
    "# 根据索引划分训练集和验证集\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "\n",
    "# 加载测试集\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "#####################################################\n",
    "### 数据加载器（Data Loaders）\n",
    "#####################################################\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,   # 每批次样本数量\n",
    "                          num_workers=8,           # 使用8个子线程加速加载数据\n",
    "                          shuffle=True)            # 打乱训练数据\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          shuffle=False)           # 验证集不需要打乱顺序\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)            # 测试集同样不需要打乱\n",
    "\n",
    "#####################################################\n",
    "\n",
    "# 检查训练集数据维度\n",
    "for images, labels in train_loader:  \n",
    "    print('训练集图像批次维度:', images.shape)\n",
    "    print('训练集标签批次维度:', labels.shape)\n",
    "    break\n",
    "\n",
    "# 检查测试集数据维度\n",
    "for images, labels in test_loader:  \n",
    "    print('测试集图像批次维度:', images.shape)\n",
    "    print('测试集标签批次维度:', labels.shape)\n",
    "    break\n",
    "\n",
    "# 检查验证集数据维度\n",
    "for images, labels in valid_loader:  \n",
    "    print('验证集图像批次维度:', images.shape)\n",
    "    print('验证集标签批次维度:', labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell that implements the ResNet-34 architecture is a derivative of the code provided at https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型定义\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"带填充的3x3卷积层\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4  # Bottleneck模块的输出通道扩展倍数\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        # 第1层：1x1卷积用于降维\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        # 第2层：3x3卷积用于提取特征\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        # 第3层：1x1卷积用于升维\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)  # 激活函数\n",
    "        self.downsample = downsample       # 是否需要下采样\n",
    "        self.stride = stride               # 步幅\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # 残差连接分支\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # 如果维度不同或需要下采样，则对残差进行变换\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual  # 残差连接\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64  # 初始通道数\n",
    "        in_dim = 1 if grayscale else 3  # 灰度图像输入通道为1，RGB图像为3\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        # 输入图像的初始卷积层（7x7卷积 + BN + ReLU）\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 构建4个残差层，每层包含多个Bottleneck块\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])     # 输出通道256\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)  # 输出通道512\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)  # 输出通道1024\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)  # 输出通道2048\n",
    "\n",
    "        # 平均池化层（默认尺寸为7x7，加了padding=2是为了适配小图）\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        \n",
    "        # 全连接层输出分类结果\n",
    "        # self.fc = nn.Linear(2048 * block.expansion, num_classes)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        # 初始化所有卷积层和BatchNorm层的参数\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \"\"\"\n",
    "        构建每个残差层，由多个Bottleneck组成\n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        # 如果输入输出维度不一致，或步幅不为1，则需下采样\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # 添加第一个Bottleneck（带下采样）\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        # 添加后续不变尺寸的Bottleneck模块\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入图像先通过初始卷积层和池化层\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # 通过4个残差层\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # x = self.avgpool(x)  # 可启用平均池化\n",
    "        x = x.view(x.size(0), -1)  # 展平成一维向量\n",
    "        logits = self.fc(x)        # 全连接层输出\n",
    "        probas = F.softmax(logits, dim=1)  # 计算类别概率\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "def resnet101(num_classes, grayscale):\n",
    "    \"\"\"构建 ResNet-101 模型\"\"\"\n",
    "    model = ResNet(block=Bottleneck, \n",
    "                   layers=[3, 4, 23, 3],   # 每个阶段的Bottleneck模块数量\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=grayscale)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "##########################\n",
    "### 损失函数和优化器\n",
    "##########################\n",
    "\n",
    "model = resnet101(NUM_CLASSES, GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Batch 000/383 | Cost: 2.7590\n",
      "Epoch: 001/050 | Batch 120/383 | Cost: 2.2662\n",
      "Epoch: 001/050 | Batch 240/383 | Cost: 2.0029\n",
      "Epoch: 001/050 | Batch 360/383 | Cost: 1.9167\n",
      "Epoch: 001/050 Train Acc.: 26.79% | Validation Acc.: 28.40%\n",
      "Time elapsed: 0.56 min\n",
      "Epoch: 002/050 | Batch 000/383 | Cost: 1.8444\n",
      "Epoch: 002/050 | Batch 120/383 | Cost: 1.7140\n",
      "Epoch: 002/050 | Batch 240/383 | Cost: 1.8181\n",
      "Epoch: 002/050 | Batch 360/383 | Cost: 1.6982\n",
      "Epoch: 002/050 Train Acc.: 38.64% | Validation Acc.: 38.70%\n",
      "Time elapsed: 1.11 min\n",
      "Epoch: 003/050 | Batch 000/383 | Cost: 1.5503\n",
      "Epoch: 003/050 | Batch 120/383 | Cost: 1.6675\n",
      "Epoch: 003/050 | Batch 240/383 | Cost: 1.5916\n",
      "Epoch: 003/050 | Batch 360/383 | Cost: 1.5134\n",
      "Epoch: 003/050 Train Acc.: 46.71% | Validation Acc.: 48.30%\n",
      "Time elapsed: 1.65 min\n",
      "Epoch: 004/050 | Batch 000/383 | Cost: 1.2814\n",
      "Epoch: 004/050 | Batch 120/383 | Cost: 1.4845\n",
      "Epoch: 004/050 | Batch 240/383 | Cost: 1.3911\n",
      "Epoch: 004/050 | Batch 360/383 | Cost: 1.2463\n",
      "Epoch: 004/050 Train Acc.: 53.65% | Validation Acc.: 51.10%\n",
      "Time elapsed: 2.20 min\n",
      "Epoch: 005/050 | Batch 000/383 | Cost: 1.2976\n",
      "Epoch: 005/050 | Batch 120/383 | Cost: 1.2894\n",
      "Epoch: 005/050 | Batch 240/383 | Cost: 1.2982\n",
      "Epoch: 005/050 | Batch 360/383 | Cost: 1.0753\n",
      "Epoch: 005/050 Train Acc.: 60.86% | Validation Acc.: 57.40%\n",
      "Time elapsed: 2.74 min\n",
      "Epoch: 006/050 | Batch 000/383 | Cost: 1.2057\n",
      "Epoch: 006/050 | Batch 120/383 | Cost: 1.0181\n",
      "Epoch: 006/050 | Batch 240/383 | Cost: 1.0162\n",
      "Epoch: 006/050 | Batch 360/383 | Cost: 0.9303\n",
      "Epoch: 006/050 Train Acc.: 64.52% | Validation Acc.: 60.80%\n",
      "Time elapsed: 3.28 min\n",
      "Epoch: 007/050 | Batch 000/383 | Cost: 1.0781\n",
      "Epoch: 007/050 | Batch 120/383 | Cost: 1.1226\n",
      "Epoch: 007/050 | Batch 240/383 | Cost: 1.8178\n",
      "Epoch: 007/050 | Batch 360/383 | Cost: 1.4674\n",
      "Epoch: 007/050 Train Acc.: 48.68% | Validation Acc.: 47.90%\n",
      "Time elapsed: 3.83 min\n",
      "Epoch: 008/050 | Batch 000/383 | Cost: 1.4225\n",
      "Epoch: 008/050 | Batch 120/383 | Cost: 1.2539\n",
      "Epoch: 008/050 | Batch 240/383 | Cost: 1.1638\n",
      "Epoch: 008/050 | Batch 360/383 | Cost: 1.0989\n",
      "Epoch: 008/050 Train Acc.: 62.43% | Validation Acc.: 61.90%\n",
      "Time elapsed: 4.37 min\n",
      "Epoch: 009/050 | Batch 000/383 | Cost: 1.0672\n",
      "Epoch: 009/050 | Batch 120/383 | Cost: 1.0433\n",
      "Epoch: 009/050 | Batch 240/383 | Cost: 1.3776\n",
      "Epoch: 009/050 | Batch 360/383 | Cost: 1.0930\n",
      "Epoch: 009/050 Train Acc.: 61.80% | Validation Acc.: 60.70%\n",
      "Time elapsed: 4.92 min\n",
      "Epoch: 010/050 | Batch 000/383 | Cost: 1.2007\n",
      "Epoch: 010/050 | Batch 120/383 | Cost: 1.2254\n",
      "Epoch: 010/050 | Batch 240/383 | Cost: 1.1306\n",
      "Epoch: 010/050 | Batch 360/383 | Cost: 0.9057\n",
      "Epoch: 010/050 Train Acc.: 66.19% | Validation Acc.: 65.70%\n",
      "Time elapsed: 5.47 min\n",
      "Epoch: 011/050 | Batch 000/383 | Cost: 0.7991\n",
      "Epoch: 011/050 | Batch 120/383 | Cost: 0.8218\n",
      "Epoch: 011/050 | Batch 240/383 | Cost: 0.8918\n",
      "Epoch: 011/050 | Batch 360/383 | Cost: 0.8994\n",
      "Epoch: 011/050 Train Acc.: 70.41% | Validation Acc.: 69.60%\n",
      "Time elapsed: 6.01 min\n",
      "Epoch: 012/050 | Batch 000/383 | Cost: 0.6737\n",
      "Epoch: 012/050 | Batch 120/383 | Cost: 1.3126\n",
      "Epoch: 012/050 | Batch 240/383 | Cost: 0.8997\n",
      "Epoch: 012/050 | Batch 360/383 | Cost: 0.8823\n",
      "Epoch: 012/050 Train Acc.: 72.22% | Validation Acc.: 69.00%\n",
      "Time elapsed: 6.56 min\n",
      "Epoch: 013/050 | Batch 000/383 | Cost: 0.7315\n",
      "Epoch: 013/050 | Batch 120/383 | Cost: 0.9252\n",
      "Epoch: 013/050 | Batch 240/383 | Cost: 0.7744\n",
      "Epoch: 013/050 | Batch 360/383 | Cost: 1.1380\n",
      "Epoch: 013/050 Train Acc.: 76.36% | Validation Acc.: 70.60%\n",
      "Time elapsed: 7.09 min\n",
      "Epoch: 014/050 | Batch 000/383 | Cost: 0.6419\n",
      "Epoch: 014/050 | Batch 120/383 | Cost: 0.7656\n",
      "Epoch: 014/050 | Batch 240/383 | Cost: 0.7462\n",
      "Epoch: 014/050 | Batch 360/383 | Cost: 0.6704\n",
      "Epoch: 014/050 Train Acc.: 80.07% | Validation Acc.: 73.70%\n",
      "Time elapsed: 7.64 min\n",
      "Epoch: 015/050 | Batch 000/383 | Cost: 0.5898\n",
      "Epoch: 015/050 | Batch 120/383 | Cost: 0.5103\n",
      "Epoch: 015/050 | Batch 240/383 | Cost: 0.5964\n",
      "Epoch: 015/050 | Batch 360/383 | Cost: 0.5619\n",
      "Epoch: 015/050 Train Acc.: 82.22% | Validation Acc.: 73.60%\n",
      "Time elapsed: 8.18 min\n",
      "Epoch: 016/050 | Batch 000/383 | Cost: 0.4167\n",
      "Epoch: 016/050 | Batch 120/383 | Cost: 0.5876\n",
      "Epoch: 016/050 | Batch 240/383 | Cost: 0.5894\n",
      "Epoch: 016/050 | Batch 360/383 | Cost: 0.7807\n",
      "Epoch: 016/050 Train Acc.: 84.55% | Validation Acc.: 74.70%\n",
      "Time elapsed: 8.73 min\n",
      "Epoch: 017/050 | Batch 000/383 | Cost: 0.3682\n",
      "Epoch: 017/050 | Batch 120/383 | Cost: 0.7294\n",
      "Epoch: 017/050 | Batch 240/383 | Cost: 1.4470\n",
      "Epoch: 017/050 | Batch 360/383 | Cost: 1.1356\n",
      "Epoch: 017/050 Train Acc.: 63.61% | Validation Acc.: 60.80%\n",
      "Time elapsed: 9.27 min\n",
      "Epoch: 018/050 | Batch 000/383 | Cost: 1.0694\n",
      "Epoch: 018/050 | Batch 120/383 | Cost: 0.9390\n",
      "Epoch: 018/050 | Batch 240/383 | Cost: 0.7987\n",
      "Epoch: 018/050 | Batch 360/383 | Cost: 0.6113\n",
      "Epoch: 018/050 Train Acc.: 79.87% | Validation Acc.: 72.80%\n",
      "Time elapsed: 9.81 min\n",
      "Epoch: 019/050 | Batch 000/383 | Cost: 0.6499\n",
      "Epoch: 019/050 | Batch 120/383 | Cost: 0.6440\n",
      "Epoch: 019/050 | Batch 240/383 | Cost: 0.7846\n",
      "Epoch: 019/050 | Batch 360/383 | Cost: 0.4702\n",
      "Epoch: 019/050 Train Acc.: 85.01% | Validation Acc.: 74.70%\n",
      "Time elapsed: 10.36 min\n",
      "Epoch: 020/050 | Batch 000/383 | Cost: 0.4641\n",
      "Epoch: 020/050 | Batch 120/383 | Cost: 0.4650\n",
      "Epoch: 020/050 | Batch 240/383 | Cost: 0.3888\n",
      "Epoch: 020/050 | Batch 360/383 | Cost: 0.5737\n",
      "Epoch: 020/050 Train Acc.: 87.96% | Validation Acc.: 76.20%\n",
      "Time elapsed: 10.90 min\n",
      "Epoch: 021/050 | Batch 000/383 | Cost: 0.3391\n",
      "Epoch: 021/050 | Batch 120/383 | Cost: 0.5138\n",
      "Epoch: 021/050 | Batch 240/383 | Cost: 0.4947\n",
      "Epoch: 021/050 | Batch 360/383 | Cost: 0.2989\n",
      "Epoch: 021/050 Train Acc.: 90.42% | Validation Acc.: 77.00%\n",
      "Time elapsed: 11.44 min\n",
      "Epoch: 022/050 | Batch 000/383 | Cost: 0.3594\n",
      "Epoch: 022/050 | Batch 120/383 | Cost: 0.3239\n",
      "Epoch: 022/050 | Batch 240/383 | Cost: 0.3226\n",
      "Epoch: 022/050 | Batch 360/383 | Cost: 0.5633\n",
      "Epoch: 022/050 Train Acc.: 91.37% | Validation Acc.: 76.20%\n",
      "Time elapsed: 11.98 min\n",
      "Epoch: 023/050 | Batch 000/383 | Cost: 0.2911\n",
      "Epoch: 023/050 | Batch 120/383 | Cost: 0.2218\n",
      "Epoch: 023/050 | Batch 240/383 | Cost: 0.3159\n",
      "Epoch: 023/050 | Batch 360/383 | Cost: 0.5241\n",
      "Epoch: 023/050 Train Acc.: 90.20% | Validation Acc.: 76.30%\n",
      "Time elapsed: 12.53 min\n",
      "Epoch: 024/050 | Batch 000/383 | Cost: 0.2014\n",
      "Epoch: 024/050 | Batch 120/383 | Cost: 0.1883\n",
      "Epoch: 024/050 | Batch 240/383 | Cost: 0.3192\n",
      "Epoch: 024/050 | Batch 360/383 | Cost: 0.2087\n",
      "Epoch: 024/050 Train Acc.: 93.94% | Validation Acc.: 76.10%\n",
      "Time elapsed: 13.07 min\n",
      "Epoch: 025/050 | Batch 000/383 | Cost: 0.1883\n",
      "Epoch: 025/050 | Batch 120/383 | Cost: 0.2232\n",
      "Epoch: 025/050 | Batch 240/383 | Cost: 0.2200\n",
      "Epoch: 025/050 | Batch 360/383 | Cost: 0.2671\n",
      "Epoch: 025/050 Train Acc.: 94.71% | Validation Acc.: 77.20%\n",
      "Time elapsed: 13.62 min\n",
      "Epoch: 026/050 | Batch 000/383 | Cost: 0.1490\n",
      "Epoch: 026/050 | Batch 120/383 | Cost: 0.1707\n",
      "Epoch: 026/050 | Batch 240/383 | Cost: 0.2810\n",
      "Epoch: 026/050 | Batch 360/383 | Cost: 0.2216\n",
      "Epoch: 026/050 Train Acc.: 95.07% | Validation Acc.: 77.10%\n",
      "Time elapsed: 14.16 min\n",
      "Epoch: 027/050 | Batch 000/383 | Cost: 0.1418\n",
      "Epoch: 027/050 | Batch 120/383 | Cost: 0.2388\n",
      "Epoch: 027/050 | Batch 240/383 | Cost: 0.1411\n",
      "Epoch: 027/050 | Batch 360/383 | Cost: 0.1751\n",
      "Epoch: 027/050 Train Acc.: 95.04% | Validation Acc.: 76.20%\n",
      "Time elapsed: 14.71 min\n",
      "Epoch: 028/050 | Batch 000/383 | Cost: 0.1665\n",
      "Epoch: 028/050 | Batch 120/383 | Cost: 0.1831\n",
      "Epoch: 028/050 | Batch 240/383 | Cost: 0.1027\n",
      "Epoch: 028/050 | Batch 360/383 | Cost: 0.1966\n",
      "Epoch: 028/050 Train Acc.: 96.34% | Validation Acc.: 76.80%\n",
      "Time elapsed: 15.25 min\n",
      "Epoch: 029/050 | Batch 000/383 | Cost: 0.0824\n",
      "Epoch: 029/050 | Batch 120/383 | Cost: 0.1095\n",
      "Epoch: 029/050 | Batch 240/383 | Cost: 1.7558\n",
      "Epoch: 029/050 | Batch 360/383 | Cost: 1.6051\n",
      "Epoch: 029/050 Train Acc.: 51.02% | Validation Acc.: 50.00%\n",
      "Time elapsed: 15.79 min\n",
      "Epoch: 030/050 | Batch 000/383 | Cost: 1.4768\n",
      "Epoch: 030/050 | Batch 120/383 | Cost: 1.2594\n",
      "Epoch: 030/050 | Batch 240/383 | Cost: 1.2815\n",
      "Epoch: 030/050 | Batch 360/383 | Cost: 0.9977\n",
      "Epoch: 030/050 Train Acc.: 69.70% | Validation Acc.: 62.90%\n",
      "Time elapsed: 16.34 min\n",
      "Epoch: 031/050 | Batch 000/383 | Cost: 0.9013\n",
      "Epoch: 031/050 | Batch 120/383 | Cost: 0.6979\n",
      "Epoch: 031/050 | Batch 240/383 | Cost: 0.9239\n",
      "Epoch: 031/050 | Batch 360/383 | Cost: 0.7404\n",
      "Epoch: 031/050 Train Acc.: 77.79% | Validation Acc.: 70.30%\n",
      "Time elapsed: 16.88 min\n",
      "Epoch: 032/050 | Batch 000/383 | Cost: 0.6453\n",
      "Epoch: 032/050 | Batch 120/383 | Cost: 0.6122\n",
      "Epoch: 032/050 | Batch 240/383 | Cost: 0.5894\n",
      "Epoch: 032/050 | Batch 360/383 | Cost: 0.4774\n",
      "Epoch: 032/050 Train Acc.: 88.96% | Validation Acc.: 74.90%\n",
      "Time elapsed: 17.43 min\n",
      "Epoch: 033/050 | Batch 000/383 | Cost: 0.3584\n",
      "Epoch: 033/050 | Batch 120/383 | Cost: 0.3739\n",
      "Epoch: 033/050 | Batch 240/383 | Cost: 0.3131\n",
      "Epoch: 033/050 | Batch 360/383 | Cost: 0.3469\n",
      "Epoch: 033/050 Train Acc.: 93.66% | Validation Acc.: 74.60%\n",
      "Time elapsed: 17.97 min\n",
      "Epoch: 034/050 | Batch 000/383 | Cost: 0.1920\n",
      "Epoch: 034/050 | Batch 120/383 | Cost: 0.2494\n",
      "Epoch: 034/050 | Batch 240/383 | Cost: 0.4727\n",
      "Epoch: 034/050 | Batch 360/383 | Cost: 0.1532\n",
      "Epoch: 034/050 Train Acc.: 95.46% | Validation Acc.: 75.70%\n",
      "Time elapsed: 18.52 min\n",
      "Epoch: 035/050 | Batch 000/383 | Cost: 0.0947\n",
      "Epoch: 035/050 | Batch 120/383 | Cost: 0.2032\n",
      "Epoch: 035/050 | Batch 240/383 | Cost: 0.1789\n",
      "Epoch: 035/050 | Batch 360/383 | Cost: 0.1250\n",
      "Epoch: 035/050 Train Acc.: 96.60% | Validation Acc.: 75.50%\n",
      "Time elapsed: 19.06 min\n",
      "Epoch: 036/050 | Batch 000/383 | Cost: 0.0771\n",
      "Epoch: 036/050 | Batch 120/383 | Cost: 0.1574\n",
      "Epoch: 036/050 | Batch 240/383 | Cost: 0.1072\n",
      "Epoch: 036/050 | Batch 360/383 | Cost: 0.1365\n",
      "Epoch: 036/050 Train Acc.: 97.14% | Validation Acc.: 76.70%\n",
      "Time elapsed: 19.60 min\n",
      "Epoch: 037/050 | Batch 000/383 | Cost: 0.1174\n",
      "Epoch: 037/050 | Batch 120/383 | Cost: 0.0712\n",
      "Epoch: 037/050 | Batch 240/383 | Cost: 0.1546\n",
      "Epoch: 037/050 | Batch 360/383 | Cost: 0.1602\n",
      "Epoch: 037/050 Train Acc.: 88.06% | Validation Acc.: 70.40%\n",
      "Time elapsed: 20.15 min\n",
      "Epoch: 038/050 | Batch 000/383 | Cost: 0.5394\n",
      "Epoch: 038/050 | Batch 120/383 | Cost: 0.2289\n",
      "Epoch: 038/050 | Batch 240/383 | Cost: 0.1047\n",
      "Epoch: 038/050 | Batch 360/383 | Cost: 0.1146\n",
      "Epoch: 038/050 Train Acc.: 96.90% | Validation Acc.: 75.50%\n",
      "Time elapsed: 20.70 min\n",
      "Epoch: 039/050 | Batch 000/383 | Cost: 0.1314\n",
      "Epoch: 039/050 | Batch 120/383 | Cost: 0.0254\n",
      "Epoch: 039/050 | Batch 240/383 | Cost: 0.1184\n",
      "Epoch: 039/050 | Batch 360/383 | Cost: 0.3157\n",
      "Epoch: 039/050 Train Acc.: 93.84% | Validation Acc.: 74.50%\n",
      "Time elapsed: 21.26 min\n",
      "Epoch: 040/050 | Batch 000/383 | Cost: 0.2028\n",
      "Epoch: 040/050 | Batch 120/383 | Cost: 0.1663\n",
      "Epoch: 040/050 | Batch 240/383 | Cost: 0.1053\n",
      "Epoch: 040/050 | Batch 360/383 | Cost: 0.1283\n",
      "Epoch: 040/050 Train Acc.: 98.45% | Validation Acc.: 78.50%\n",
      "Time elapsed: 21.81 min\n",
      "Epoch: 041/050 | Batch 000/383 | Cost: 0.0269\n",
      "Epoch: 041/050 | Batch 120/383 | Cost: 0.0646\n",
      "Epoch: 041/050 | Batch 240/383 | Cost: 0.0380\n",
      "Epoch: 041/050 | Batch 360/383 | Cost: 0.1914\n",
      "Epoch: 041/050 Train Acc.: 97.50% | Validation Acc.: 76.30%\n",
      "Time elapsed: 22.37 min\n",
      "Epoch: 042/050 | Batch 000/383 | Cost: 0.0228\n",
      "Epoch: 042/050 | Batch 120/383 | Cost: 0.0422\n",
      "Epoch: 042/050 | Batch 240/383 | Cost: 0.0175\n",
      "Epoch: 042/050 | Batch 360/383 | Cost: 0.0935\n",
      "Epoch: 042/050 Train Acc.: 97.99% | Validation Acc.: 74.90%\n",
      "Time elapsed: 22.92 min\n",
      "Epoch: 043/050 | Batch 000/383 | Cost: 0.0305\n",
      "Epoch: 043/050 | Batch 120/383 | Cost: 0.0357\n",
      "Epoch: 043/050 | Batch 240/383 | Cost: 0.0999\n",
      "Epoch: 043/050 | Batch 360/383 | Cost: 0.1549\n",
      "Epoch: 043/050 Train Acc.: 97.96% | Validation Acc.: 77.70%\n",
      "Time elapsed: 23.47 min\n",
      "Epoch: 044/050 | Batch 000/383 | Cost: 0.1186\n",
      "Epoch: 044/050 | Batch 120/383 | Cost: 0.0931\n",
      "Epoch: 044/050 | Batch 240/383 | Cost: 0.0198\n",
      "Epoch: 044/050 | Batch 360/383 | Cost: 0.0711\n",
      "Epoch: 044/050 Train Acc.: 98.34% | Validation Acc.: 76.00%\n",
      "Time elapsed: 24.01 min\n",
      "Epoch: 045/050 | Batch 000/383 | Cost: 0.0237\n",
      "Epoch: 045/050 | Batch 120/383 | Cost: 0.1273\n",
      "Epoch: 045/050 | Batch 240/383 | Cost: 0.0457\n",
      "Epoch: 045/050 | Batch 360/383 | Cost: 0.0465\n",
      "Epoch: 045/050 Train Acc.: 97.92% | Validation Acc.: 76.70%\n",
      "Time elapsed: 24.56 min\n",
      "Epoch: 046/050 | Batch 000/383 | Cost: 0.0365\n",
      "Epoch: 046/050 | Batch 120/383 | Cost: 0.0532\n",
      "Epoch: 046/050 | Batch 240/383 | Cost: 0.0792\n",
      "Epoch: 046/050 | Batch 360/383 | Cost: 0.1236\n",
      "Epoch: 046/050 Train Acc.: 98.39% | Validation Acc.: 76.50%\n",
      "Time elapsed: 25.11 min\n",
      "Epoch: 047/050 | Batch 000/383 | Cost: 0.0885\n",
      "Epoch: 047/050 | Batch 120/383 | Cost: 0.0469\n",
      "Epoch: 047/050 | Batch 240/383 | Cost: 0.1878\n",
      "Epoch: 047/050 | Batch 360/383 | Cost: 0.1784\n",
      "Epoch: 047/050 Train Acc.: 97.54% | Validation Acc.: 75.70%\n",
      "Time elapsed: 25.65 min\n",
      "Epoch: 048/050 | Batch 000/383 | Cost: 0.0583\n",
      "Epoch: 048/050 | Batch 120/383 | Cost: 0.1602\n",
      "Epoch: 048/050 | Batch 240/383 | Cost: 0.5865\n",
      "Epoch: 048/050 | Batch 360/383 | Cost: 0.3238\n",
      "Epoch: 048/050 Train Acc.: 94.63% | Validation Acc.: 75.80%\n",
      "Time elapsed: 26.19 min\n",
      "Epoch: 049/050 | Batch 000/383 | Cost: 0.2552\n",
      "Epoch: 049/050 | Batch 120/383 | Cost: 0.1535\n",
      "Epoch: 049/050 | Batch 240/383 | Cost: 0.0989\n",
      "Epoch: 049/050 | Batch 360/383 | Cost: 0.0812\n",
      "Epoch: 049/050 Train Acc.: 98.49% | Validation Acc.: 78.50%\n",
      "Time elapsed: 26.74 min\n",
      "Epoch: 050/050 | Batch 000/383 | Cost: 0.0739\n",
      "Epoch: 050/050 | Batch 120/383 | Cost: 0.0094\n",
      "Epoch: 050/050 | Batch 240/383 | Cost: 0.0207\n",
      "Epoch: 050/050 | Batch 360/383 | Cost: 0.0888\n",
      "Epoch: 050/050 Train Acc.: 98.89% | Validation Acc.: 76.40%\n",
      "Time elapsed: 27.29 min\n",
      "Total Training Time: 27.29 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    # 遍历数据加载器中的每一个批次\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "        # 将数据转移到GPU/CPU上\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # 模型前向传播，获取输出结果\n",
    "        logits, probas = model(features)\n",
    "        # 取概率最大的预测类别\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        # 统计总样本数\n",
    "        num_examples += targets.size(0)\n",
    "        # 累加预测正确的数量\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    # 返回百分比形式的准确率\n",
    "    return correct_pred.float() / num_examples * 100\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 设置随机种子，使每次运行的结果一致（这里影响批次打乱）\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()  # 设置为训练模式\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### 准备小批量数据\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### 前向传播与反向传播\n",
    "        logits, probas = model(features)                 # 前向传播\n",
    "        cost = F.cross_entropy(logits, targets)         # 计算交叉熵损失\n",
    "        optimizer.zero_grad()                           # 梯度清零\n",
    "        cost.backward()                                 # 反向传播计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()                                # 梯度下降更新权重\n",
    "        \n",
    "        ### 日志打印\n",
    "        if not batch_idx % 120:  # 每隔120个批次打印一次损失信息\n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                  f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                  f' Cost: {cost:.4f}')\n",
    "\n",
    "    # 评估模式下，不需要构建反向传播的计算图，节省资源\n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc = compute_accuracy(model, train_loader, device=DEVICE)\n",
    "        valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "        \n",
    "    # 每轮结束后打印已用时间\n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "# 训练全部完成后，打印总耗时\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 74.83%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # 在推理过程中禁用梯度计算，节省内存\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy      : 1.26.4\n",
      "pandas     : 2.2.3\n",
      "PIL        : 11.1.0\n",
      "matplotlib : 3.10.1\n",
      "torchvision: 0.21.0+cu126\n",
      "torch      : 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
