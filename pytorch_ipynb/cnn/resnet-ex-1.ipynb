{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accompanying code examples of the book \"Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python\" by [Sebastian Raschka](https://sebastianraschka.com). All code examples are released under the [MIT license](https://github.com/rasbt/deep-learning-book/blob/master/LICENSE). If you find this content useful, please consider supporting the work by buying a [copy of the book](https://leanpub.com/ann-and-deeplearning).*\n",
    "  \n",
    "Other code examples and content are available on [GitHub](https://github.com/rasbt/deep-learning-book). The PDF and ebook versions of the book are available through [Leanpub](https://leanpub.com/ann-and-deeplearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 9.0.2\n",
      "\n",
      "torch: 2.6.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Runs on CPU or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo -- Convolutional ResNet and Residual Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this example does not implement a really deep ResNet as described in literature but rather illustrates how the residual blocks described in He et al. [1] can be implemented in PyTorch.  \n",
    "请注意，这个例子并没有实现文献中描述的真正深度的ResNet，而是展示了如何在PyTorch中实现He等人[1]描述的残差块。\n",
    "\n",
    "- [1] He, Kaiming, et al. \"Deep residual learning for image recognition.\" *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016.  \n",
    "- [1] He, Kaiming等人，“深度残差学习用于图像识别。” *IEEE计算机视觉与模式识别会议论文集*，2016年。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.set_per_process_memory_fraction(0.5, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像批次的维度: torch.Size([128, 1, 28, 28])\n",
      "图像标签的维度: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### 配置参数\n",
    "##########################\n",
    "\n",
    "# 设备选择\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # 如果有可用的 GPU，则使用 GPU，否则使用 CPU\n",
    "\n",
    "# 超参数设置\n",
    "random_seed = 123  # 随机种子\n",
    "learning_rate = 0.01  # 学习率\n",
    "num_epochs = 10  # 训练轮数\n",
    "batch_size = 128  # 批次大小\n",
    "\n",
    "# 模型架构相关\n",
    "num_classes = 10  # 输出的类别数（MNIST数据集有10个数字类别）\n",
    "\n",
    "\n",
    "##########################\n",
    "### MNIST 数据集\n",
    "##########################\n",
    "\n",
    "# 注意 transforms.ToTensor() 会将输入图像缩放到 0-1 范围\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True,  # 使用训练集\n",
    "                               transform=transforms.ToTensor(),  # 将图像转换为 Tensor 类型\n",
    "                               download=True)  # 如果数据集不存在，则下载\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False,  # 使用测试集\n",
    "                              transform=transforms.ToTensor())  # 将图像转换为 Tensor 类型\n",
    "\n",
    "\n",
    "# 使用 DataLoader 加载训练集\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size,  # 每批次的大小\n",
    "                          shuffle=True)  # 是否打乱数据顺序\n",
    "\n",
    "# 使用 DataLoader 加载测试集\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,  # 每批次的大小\n",
    "                         shuffle=False)  # 测试集一般不打乱数据顺序\n",
    "\n",
    "\n",
    "# 检查数据集的形状\n",
    "for images, labels in train_loader:  \n",
    "    print('图像批次的维度:', images.shape)  # 打印图像的维度\n",
    "    print('图像标签的维度:', labels.shape)  # 打印标签的维度\n",
    "    break  # 只打印一次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet with identity blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements the residual blocks with skip connections such that the input passed via the shortcut matches the dimensions of the main path's output, which allows the network to learn identity functions.  \n",
    "以下代码实现了带有跳跃连接的残差块，使得通过快捷方式传递的输入与主路径输出的维度相匹配，从而使网络能够学习恒等函数。\n",
    "\n",
    "Such a residual block is illustrated below:  \n",
    "下图展示了这样的残差块：\n",
    "![](../images/resnets/resnet-ex-1-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #########################\n",
    "        ### 第一个残差块\n",
    "        #########################\n",
    "        # 输入: 28x28x1 -> 输出: 28x28x4\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                      out_channels=4,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)\n",
    "        self.conv_1_bn = torch.nn.BatchNorm2d(4)  # 批归一化\n",
    "        \n",
    "        # 输入: 28x28x4 -> 输出: 28x28x1\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=4,\n",
    "                                      out_channels=1,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1)   \n",
    "        self.conv_2_bn = torch.nn.BatchNorm2d(1)  # 批归一化\n",
    "        \n",
    "        \n",
    "        #########################\n",
    "        ### 第二个残差块\n",
    "        #########################\n",
    "        # 输入: 28x28x1 -> 输出: 28x28x4\n",
    "        self.conv_3 = torch.nn.Conv2d(in_channels=1,\n",
    "                                      out_channels=4,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)\n",
    "        self.conv_3_bn = torch.nn.BatchNorm2d(4)  # 批归一化\n",
    "        \n",
    "        # 输入: 28x28x4 -> 输出: 28x28x1\n",
    "        self.conv_4 = torch.nn.Conv2d(in_channels=4,\n",
    "                                      out_channels=1,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1)   \n",
    "        self.conv_4_bn = torch.nn.BatchNorm2d(1)  # 批归一化\n",
    "\n",
    "        #########################\n",
    "        ### 全连接层\n",
    "        #########################        \n",
    "        self.linear_1 = torch.nn.Linear(28*28*1, num_classes)  # 输入为展平后的28x28x1，输出为类别数\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #########################\n",
    "        ### 第一个残差块\n",
    "        #########################\n",
    "        shortcut = x  # 保存输入数据作为跳跃连接\n",
    "        \n",
    "        out = self.conv_1(x)  # 卷积操作\n",
    "        out = self.conv_1_bn(out)  # 批归一化\n",
    "        out = F.relu(out)  # ReLU 激活函数\n",
    "\n",
    "        out = self.conv_2(out)  # 卷积操作\n",
    "        out = self.conv_2_bn(out)  # 批归一化\n",
    "        \n",
    "        out += shortcut  # 跳跃连接\n",
    "        out = F.relu(out)  # ReLU 激活函数\n",
    "        \n",
    "        #########################\n",
    "        ### 第二个残差块\n",
    "        #########################\n",
    "        \n",
    "        shortcut = out  # 保存新的跳跃连接\n",
    "        \n",
    "        out = self.conv_3(out)  # 卷积操作\n",
    "        out = self.conv_3_bn(out)  # 批归一化\n",
    "        out = F.relu(out)  # ReLU 激活函数\n",
    "\n",
    "        out = self.conv_4(out)  # 卷积操作\n",
    "        out = self.conv_4_bn(out)  # 批归一化\n",
    "        \n",
    "        out += shortcut  # 跳跃连接\n",
    "        out = F.relu(out)  # ReLU 激活函数\n",
    "        \n",
    "        #########################\n",
    "        ### 全连接层\n",
    "        #########################   \n",
    "        logits = self.linear_1(out.view(-1, 28*28*1))  # 展平输出并通过全连接层\n",
    "        probas = F.softmax(logits, dim=1)  # softmax 得到概率分布\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "# 设置随机种子，确保实验可重复\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# 初始化模型\n",
    "model = ConvNet(num_classes=num_classes)\n",
    "model = model.to(device)  # 将模型移到指定设备\n",
    "\n",
    "# 设置优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # 使用 Adam 优化器\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/469 | Cost: 2.6800\n",
      "Epoch: 001/010 | Batch 050/469 | Cost: 0.2592\n",
      "Epoch: 001/010 | Batch 100/469 | Cost: 0.3554\n",
      "Epoch: 001/010 | Batch 150/469 | Cost: 0.2801\n",
      "Epoch: 001/010 | Batch 200/469 | Cost: 0.4034\n",
      "Epoch: 001/010 | Batch 250/469 | Cost: 0.3138\n",
      "Epoch: 001/010 | Batch 300/469 | Cost: 0.4060\n",
      "Epoch: 001/010 | Batch 350/469 | Cost: 0.2429\n",
      "Epoch: 001/010 | Batch 400/469 | Cost: 0.2464\n",
      "Epoch: 001/010 | Batch 450/469 | Cost: 0.3419\n",
      "Epoch: 001/010 training accuracy: 91.41%\n",
      "Time elapsed: 0.06 min\n",
      "Epoch: 002/010 | Batch 000/469 | Cost: 0.3225\n",
      "Epoch: 002/010 | Batch 050/469 | Cost: 0.2185\n",
      "Epoch: 002/010 | Batch 100/469 | Cost: 0.3148\n",
      "Epoch: 002/010 | Batch 150/469 | Cost: 0.2088\n",
      "Epoch: 002/010 | Batch 200/469 | Cost: 0.3212\n",
      "Epoch: 002/010 | Batch 250/469 | Cost: 0.2088\n",
      "Epoch: 002/010 | Batch 300/469 | Cost: 0.2894\n",
      "Epoch: 002/010 | Batch 350/469 | Cost: 0.3921\n",
      "Epoch: 002/010 | Batch 400/469 | Cost: 0.2781\n",
      "Epoch: 002/010 | Batch 450/469 | Cost: 0.2877\n",
      "Epoch: 002/010 training accuracy: 91.71%\n",
      "Time elapsed: 0.11 min\n",
      "Epoch: 003/010 | Batch 000/469 | Cost: 0.2043\n",
      "Epoch: 003/010 | Batch 050/469 | Cost: 0.4974\n",
      "Epoch: 003/010 | Batch 100/469 | Cost: 0.2077\n",
      "Epoch: 003/010 | Batch 150/469 | Cost: 0.2516\n",
      "Epoch: 003/010 | Batch 200/469 | Cost: 0.2802\n",
      "Epoch: 003/010 | Batch 250/469 | Cost: 0.2760\n",
      "Epoch: 003/010 | Batch 300/469 | Cost: 0.3193\n",
      "Epoch: 003/010 | Batch 350/469 | Cost: 0.3381\n",
      "Epoch: 003/010 | Batch 400/469 | Cost: 0.3323\n",
      "Epoch: 003/010 | Batch 450/469 | Cost: 0.3174\n",
      "Epoch: 003/010 training accuracy: 92.46%\n",
      "Time elapsed: 0.16 min\n",
      "Epoch: 004/010 | Batch 000/469 | Cost: 0.2792\n",
      "Epoch: 004/010 | Batch 050/469 | Cost: 0.1184\n",
      "Epoch: 004/010 | Batch 100/469 | Cost: 0.3775\n",
      "Epoch: 004/010 | Batch 150/469 | Cost: 0.3284\n",
      "Epoch: 004/010 | Batch 200/469 | Cost: 0.3497\n",
      "Epoch: 004/010 | Batch 250/469 | Cost: 0.3098\n",
      "Epoch: 004/010 | Batch 300/469 | Cost: 0.4625\n",
      "Epoch: 004/010 | Batch 350/469 | Cost: 0.2013\n",
      "Epoch: 004/010 | Batch 400/469 | Cost: 0.2576\n",
      "Epoch: 004/010 | Batch 450/469 | Cost: 0.2394\n",
      "Epoch: 004/010 training accuracy: 93.03%\n",
      "Time elapsed: 0.22 min\n",
      "Epoch: 005/010 | Batch 000/469 | Cost: 0.3527\n",
      "Epoch: 005/010 | Batch 050/469 | Cost: 0.2473\n",
      "Epoch: 005/010 | Batch 100/469 | Cost: 0.0829\n",
      "Epoch: 005/010 | Batch 150/469 | Cost: 0.2067\n",
      "Epoch: 005/010 | Batch 200/469 | Cost: 0.1517\n",
      "Epoch: 005/010 | Batch 250/469 | Cost: 0.2914\n",
      "Epoch: 005/010 | Batch 300/469 | Cost: 0.2876\n",
      "Epoch: 005/010 | Batch 350/469 | Cost: 0.2850\n",
      "Epoch: 005/010 | Batch 400/469 | Cost: 0.1697\n",
      "Epoch: 005/010 | Batch 450/469 | Cost: 0.3681\n",
      "Epoch: 005/010 training accuracy: 93.33%\n",
      "Time elapsed: 0.27 min\n",
      "Epoch: 006/010 | Batch 000/469 | Cost: 0.2538\n",
      "Epoch: 006/010 | Batch 050/469 | Cost: 0.1491\n",
      "Epoch: 006/010 | Batch 100/469 | Cost: 0.1624\n",
      "Epoch: 006/010 | Batch 150/469 | Cost: 0.1062\n",
      "Epoch: 006/010 | Batch 200/469 | Cost: 0.3258\n",
      "Epoch: 006/010 | Batch 250/469 | Cost: 0.2414\n",
      "Epoch: 006/010 | Batch 300/469 | Cost: 0.3435\n",
      "Epoch: 006/010 | Batch 350/469 | Cost: 0.2370\n",
      "Epoch: 006/010 | Batch 400/469 | Cost: 0.2385\n",
      "Epoch: 006/010 | Batch 450/469 | Cost: 0.2028\n",
      "Epoch: 006/010 training accuracy: 92.22%\n",
      "Time elapsed: 0.32 min\n",
      "Epoch: 007/010 | Batch 000/469 | Cost: 0.1958\n",
      "Epoch: 007/010 | Batch 050/469 | Cost: 0.3224\n",
      "Epoch: 007/010 | Batch 100/469 | Cost: 0.2105\n",
      "Epoch: 007/010 | Batch 150/469 | Cost: 0.2019\n",
      "Epoch: 007/010 | Batch 200/469 | Cost: 0.1924\n",
      "Epoch: 007/010 | Batch 250/469 | Cost: 0.1586\n",
      "Epoch: 007/010 | Batch 300/469 | Cost: 0.1899\n",
      "Epoch: 007/010 | Batch 350/469 | Cost: 0.2730\n",
      "Epoch: 007/010 | Batch 400/469 | Cost: 0.2373\n",
      "Epoch: 007/010 | Batch 450/469 | Cost: 0.1666\n",
      "Epoch: 007/010 training accuracy: 92.06%\n",
      "Time elapsed: 0.37 min\n",
      "Epoch: 008/010 | Batch 000/469 | Cost: 0.3734\n",
      "Epoch: 008/010 | Batch 050/469 | Cost: 0.1291\n",
      "Epoch: 008/010 | Batch 100/469 | Cost: 0.1620\n",
      "Epoch: 008/010 | Batch 150/469 | Cost: 0.2253\n",
      "Epoch: 008/010 | Batch 200/469 | Cost: 0.1698\n",
      "Epoch: 008/010 | Batch 250/469 | Cost: 0.3004\n",
      "Epoch: 008/010 | Batch 300/469 | Cost: 0.2716\n",
      "Epoch: 008/010 | Batch 350/469 | Cost: 0.2878\n",
      "Epoch: 008/010 | Batch 400/469 | Cost: 0.3478\n",
      "Epoch: 008/010 | Batch 450/469 | Cost: 0.2388\n",
      "Epoch: 008/010 training accuracy: 93.37%\n",
      "Time elapsed: 0.42 min\n",
      "Epoch: 009/010 | Batch 000/469 | Cost: 0.2052\n",
      "Epoch: 009/010 | Batch 050/469 | Cost: 0.2576\n",
      "Epoch: 009/010 | Batch 100/469 | Cost: 0.2328\n",
      "Epoch: 009/010 | Batch 150/469 | Cost: 0.2168\n",
      "Epoch: 009/010 | Batch 200/469 | Cost: 0.2133\n",
      "Epoch: 009/010 | Batch 250/469 | Cost: 0.1653\n",
      "Epoch: 009/010 | Batch 300/469 | Cost: 0.2631\n",
      "Epoch: 009/010 | Batch 350/469 | Cost: 0.2090\n",
      "Epoch: 009/010 | Batch 400/469 | Cost: 0.2175\n",
      "Epoch: 009/010 | Batch 450/469 | Cost: 0.2371\n",
      "Epoch: 009/010 training accuracy: 93.68%\n",
      "Time elapsed: 0.47 min\n",
      "Epoch: 010/010 | Batch 000/469 | Cost: 0.1413\n",
      "Epoch: 010/010 | Batch 050/469 | Cost: 0.2611\n",
      "Epoch: 010/010 | Batch 100/469 | Cost: 0.2182\n",
      "Epoch: 010/010 | Batch 150/469 | Cost: 0.1408\n",
      "Epoch: 010/010 | Batch 200/469 | Cost: 0.1967\n",
      "Epoch: 010/010 | Batch 250/469 | Cost: 0.2895\n",
      "Epoch: 010/010 | Batch 300/469 | Cost: 0.1945\n",
      "Epoch: 010/010 | Batch 350/469 | Cost: 0.2986\n",
      "Epoch: 010/010 | Batch 400/469 | Cost: 0.2303\n",
      "Epoch: 010/010 | Batch 450/469 | Cost: 0.2346\n",
      "Epoch: 010/010 training accuracy: 93.24%\n",
      "Time elapsed: 0.52 min\n",
      "Total Training Time: 0.52 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0  # 初始化正确预测的数量和总样本数\n",
    "    for i, (features, targets) in enumerate(data_loader):  # 遍历数据加载器中的每个批次\n",
    "        features = features.to(device)  # 将特征移到指定设备\n",
    "        targets = targets.to(device)  # 将标签移到指定设备\n",
    "        logits, probas = model(features)  # 前向传播，得到logits和预测概率\n",
    "        _, predicted_labels = torch.max(probas, 1)  # 获取概率最大的类别\n",
    "        num_examples += targets.size(0)  # 增加批次中的样本数\n",
    "        correct_pred += (predicted_labels == targets).sum()  # 计算正确预测的数量\n",
    "    return correct_pred.float()/num_examples * 100  # 返回准确率（百分比）\n",
    "\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "for epoch in range(num_epochs):  # 遍历所有训练轮次\n",
    "    model = model.train()  # 设置模型为训练模式\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):  # 遍历训练数据\n",
    "        features = features.to(device)  # 将特征移到指定设备\n",
    "        targets = targets.to(device)  # 将标签移到指定设备\n",
    "        \n",
    "        ### 正向传播和反向传播\n",
    "        logits, probas = model(features)  # 前向传播，得到logits和预测概率\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清空之前的梯度\n",
    "        \n",
    "        cost.backward()  # 反向传播，计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        ### 记录日志\n",
    "        if not batch_idx % 50:  # 每50个批次打印一次日志\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model = model.eval()  # 设置模型为评估模式，以防在推理过程中更新批归一化参数\n",
    "    with torch.set_grad_enabled(False):  # 推理时不需要计算梯度，节省内存\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader)))  # 打印训练集上的准确率\n",
    "\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))  # 打印已用时间\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))  # 打印总训练时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 92.03%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet with convolutional blocks for resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements the residual blocks with skip connections such that the input passed via the shortcut matches is resized to dimensions of the main path's output.  \n",
    "以下代码实现了带有跳跃连接的残差块，使得通过快捷方式传递的输入被调整为与主路径输出的维度匹配。\n",
    "\n",
    "Such a residual block is illustrated below:  \n",
    "下图展示了这样的残差块：\n",
    "\n",
    "![](../images/resnets/resnet-ex-1-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型\n",
    "##########################\n",
    "\n",
    "\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #########################\n",
    "        ### 第1个残差块\n",
    "        #########################\n",
    "        # 28x28x1 => 14x14x4 \n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                      out_channels=4,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1)\n",
    "        self.conv_1_bn = torch.nn.BatchNorm2d(4)  # 批归一化\n",
    "        \n",
    "        # 14x14x4 => 14x14x8\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=4,\n",
    "                                      out_channels=8,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)   \n",
    "        self.conv_2_bn = torch.nn.BatchNorm2d(8)  # 批归一化\n",
    "        \n",
    "        # 28x28x1 => 14x14x8\n",
    "        self.conv_shortcut_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                               out_channels=8,\n",
    "                                               kernel_size=(1, 1),\n",
    "                                               stride=(2, 2),\n",
    "                                               padding=0)   \n",
    "        self.conv_shortcut_1_bn = torch.nn.BatchNorm2d(8)  # 批归一化\n",
    "        \n",
    "        #########################\n",
    "        ### 第2个残差块\n",
    "        #########################\n",
    "        # 14x14x8 => 7x7x16 \n",
    "        self.conv_3 = torch.nn.Conv2d(in_channels=8,\n",
    "                                      out_channels=16,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1)\n",
    "        self.conv_3_bn = torch.nn.BatchNorm2d(16)  # 批归一化\n",
    "        \n",
    "        # 7x7x16 => 7x7x32\n",
    "        self.conv_4 = torch.nn.Conv2d(in_channels=16,\n",
    "                                      out_channels=32,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)   \n",
    "        self.conv_4_bn = torch.nn.BatchNorm2d(32)  # 批归一化\n",
    "        \n",
    "        # 14x14x8 => 7x7x32 \n",
    "        self.conv_shortcut_2 = torch.nn.Conv2d(in_channels=8,\n",
    "                                               out_channels=32,\n",
    "                                               kernel_size=(1, 1),\n",
    "                                               stride=(2, 2),\n",
    "                                               padding=0)   \n",
    "        self.conv_shortcut_2_bn = torch.nn.BatchNorm2d(32)  # 批归一化\n",
    "\n",
    "        #########################\n",
    "        ### 全连接层\n",
    "        #########################        \n",
    "        self.linear_1 = torch.nn.Linear(7*7*32, num_classes)  # 输出类别数\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #########################\n",
    "        ### 第1个残差块\n",
    "        #########################\n",
    "        shortcut = x  # 保存输入x用于后续跳跃连接\n",
    "        \n",
    "        out = self.conv_1(x) # 28x28x1 => 14x14x4 \n",
    "        out = self.conv_1_bn(out)  # 批归一化\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "\n",
    "        out = self.conv_2(out) # 14x14x4 => 14x14x8\n",
    "        out = self.conv_2_bn(out)  # 批归一化\n",
    "        \n",
    "        # 使用线性变换对shortcut进行维度匹配（不使用ReLU）\n",
    "        shortcut = self.conv_shortcut_1(shortcut)\n",
    "        shortcut = self.conv_shortcut_1_bn(shortcut)  # 批归一化\n",
    "        \n",
    "        out += shortcut  # 残差连接\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "        \n",
    "        #########################\n",
    "        ### 第2个残差块\n",
    "        #########################\n",
    "        \n",
    "        shortcut = out  # 保存当前输出作为跳跃连接\n",
    "        \n",
    "        out = self.conv_3(out) # 14x14x8 => 7x7x16 \n",
    "        out = self.conv_3_bn(out)  # 批归一化\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "\n",
    "        out = self.conv_4(out) # 7x7x16 => 7x7x32\n",
    "        out = self.conv_4_bn(out)  # 批归一化\n",
    "        \n",
    "        # 使用线性变换对shortcut进行维度匹配（不使用ReLU）\n",
    "        shortcut = self.conv_shortcut_2(shortcut)\n",
    "        shortcut = self.conv_shortcut_2_bn(shortcut)  # 批归一化\n",
    "        \n",
    "        out += shortcut  # 残差连接\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "        \n",
    "        #########################\n",
    "        ### 全连接层\n",
    "        #########################   \n",
    "        logits = self.linear_1(out.view(-1, 7*7*32))  # 扁平化并通过全连接层\n",
    "        probas = F.softmax(logits, dim=1)  # Softmax激活函数，用于计算每类的概率\n",
    "        return logits, probas  # 返回logits和概率\n",
    "\n",
    "\n",
    "torch.manual_seed(random_seed)  # 设置随机种子\n",
    "model = ConvNet(num_classes=num_classes)  # 初始化模型\n",
    "model = model.to(device)  # 将模型移至指定设备\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # 使用Adam优化器\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/469 | Cost: 2.3534\n",
      "Epoch: 001/010 | Batch 050/469 | Cost: 0.2719\n",
      "Epoch: 001/010 | Batch 100/469 | Cost: 0.2472\n",
      "Epoch: 001/010 | Batch 150/469 | Cost: 0.1019\n",
      "Epoch: 001/010 | Batch 200/469 | Cost: 0.0748\n",
      "Epoch: 001/010 | Batch 250/469 | Cost: 0.1162\n",
      "Epoch: 001/010 | Batch 300/469 | Cost: 0.2745\n",
      "Epoch: 001/010 | Batch 350/469 | Cost: 0.1792\n",
      "Epoch: 001/010 | Batch 400/469 | Cost: 0.0572\n",
      "Epoch: 001/010 | Batch 450/469 | Cost: 0.1089\n",
      "Epoch: 001/010 training accuracy: 97.42%\n",
      "Epoch: 002/010 | Batch 000/469 | Cost: 0.0958\n",
      "Epoch: 002/010 | Batch 050/469 | Cost: 0.0521\n",
      "Epoch: 002/010 | Batch 100/469 | Cost: 0.1024\n",
      "Epoch: 002/010 | Batch 150/469 | Cost: 0.1421\n",
      "Epoch: 002/010 | Batch 200/469 | Cost: 0.0985\n",
      "Epoch: 002/010 | Batch 250/469 | Cost: 0.0494\n",
      "Epoch: 002/010 | Batch 300/469 | Cost: 0.0252\n",
      "Epoch: 002/010 | Batch 350/469 | Cost: 0.0329\n",
      "Epoch: 002/010 | Batch 400/469 | Cost: 0.0230\n",
      "Epoch: 002/010 | Batch 450/469 | Cost: 0.1180\n",
      "Epoch: 002/010 training accuracy: 98.21%\n",
      "Epoch: 003/010 | Batch 000/469 | Cost: 0.0405\n",
      "Epoch: 003/010 | Batch 050/469 | Cost: 0.0425\n",
      "Epoch: 003/010 | Batch 100/469 | Cost: 0.1703\n",
      "Epoch: 003/010 | Batch 150/469 | Cost: 0.0206\n",
      "Epoch: 003/010 | Batch 200/469 | Cost: 0.0533\n",
      "Epoch: 003/010 | Batch 250/469 | Cost: 0.0476\n",
      "Epoch: 003/010 | Batch 300/469 | Cost: 0.0157\n",
      "Epoch: 003/010 | Batch 350/469 | Cost: 0.0129\n",
      "Epoch: 003/010 | Batch 400/469 | Cost: 0.0648\n",
      "Epoch: 003/010 | Batch 450/469 | Cost: 0.0250\n",
      "Epoch: 003/010 training accuracy: 98.67%\n",
      "Epoch: 004/010 | Batch 000/469 | Cost: 0.0138\n",
      "Epoch: 004/010 | Batch 050/469 | Cost: 0.0288\n",
      "Epoch: 004/010 | Batch 100/469 | Cost: 0.0808\n",
      "Epoch: 004/010 | Batch 150/469 | Cost: 0.0808\n",
      "Epoch: 004/010 | Batch 200/469 | Cost: 0.0613\n",
      "Epoch: 004/010 | Batch 250/469 | Cost: 0.0353\n",
      "Epoch: 004/010 | Batch 300/469 | Cost: 0.0434\n",
      "Epoch: 004/010 | Batch 350/469 | Cost: 0.0398\n",
      "Epoch: 004/010 | Batch 400/469 | Cost: 0.0357\n",
      "Epoch: 004/010 | Batch 450/469 | Cost: 0.0261\n",
      "Epoch: 004/010 training accuracy: 98.97%\n",
      "Epoch: 005/010 | Batch 000/469 | Cost: 0.0481\n",
      "Epoch: 005/010 | Batch 050/469 | Cost: 0.0075\n",
      "Epoch: 005/010 | Batch 100/469 | Cost: 0.0845\n",
      "Epoch: 005/010 | Batch 150/469 | Cost: 0.0468\n",
      "Epoch: 005/010 | Batch 200/469 | Cost: 0.0912\n",
      "Epoch: 005/010 | Batch 250/469 | Cost: 0.0446\n",
      "Epoch: 005/010 | Batch 300/469 | Cost: 0.0321\n",
      "Epoch: 005/010 | Batch 350/469 | Cost: 0.0474\n",
      "Epoch: 005/010 | Batch 400/469 | Cost: 0.0346\n",
      "Epoch: 005/010 | Batch 450/469 | Cost: 0.0474\n",
      "Epoch: 005/010 training accuracy: 98.82%\n",
      "Epoch: 006/010 | Batch 000/469 | Cost: 0.0447\n",
      "Epoch: 006/010 | Batch 050/469 | Cost: 0.0151\n",
      "Epoch: 006/010 | Batch 100/469 | Cost: 0.0126\n",
      "Epoch: 006/010 | Batch 150/469 | Cost: 0.0502\n",
      "Epoch: 006/010 | Batch 200/469 | Cost: 0.0142\n",
      "Epoch: 006/010 | Batch 250/469 | Cost: 0.0855\n",
      "Epoch: 006/010 | Batch 300/469 | Cost: 0.0030\n",
      "Epoch: 006/010 | Batch 350/469 | Cost: 0.0044\n",
      "Epoch: 006/010 | Batch 400/469 | Cost: 0.0308\n",
      "Epoch: 006/010 | Batch 450/469 | Cost: 0.0965\n",
      "Epoch: 006/010 training accuracy: 99.06%\n",
      "Epoch: 007/010 | Batch 000/469 | Cost: 0.0198\n",
      "Epoch: 007/010 | Batch 050/469 | Cost: 0.0400\n",
      "Epoch: 007/010 | Batch 100/469 | Cost: 0.0252\n",
      "Epoch: 007/010 | Batch 150/469 | Cost: 0.0131\n",
      "Epoch: 007/010 | Batch 200/469 | Cost: 0.0288\n",
      "Epoch: 007/010 | Batch 250/469 | Cost: 0.0073\n",
      "Epoch: 007/010 | Batch 300/469 | Cost: 0.0681\n",
      "Epoch: 007/010 | Batch 350/469 | Cost: 0.1954\n",
      "Epoch: 007/010 | Batch 400/469 | Cost: 0.0326\n",
      "Epoch: 007/010 | Batch 450/469 | Cost: 0.0353\n",
      "Epoch: 007/010 training accuracy: 98.69%\n",
      "Epoch: 008/010 | Batch 000/469 | Cost: 0.0311\n",
      "Epoch: 008/010 | Batch 050/469 | Cost: 0.0221\n",
      "Epoch: 008/010 | Batch 100/469 | Cost: 0.0112\n",
      "Epoch: 008/010 | Batch 150/469 | Cost: 0.0472\n",
      "Epoch: 008/010 | Batch 200/469 | Cost: 0.1111\n",
      "Epoch: 008/010 | Batch 250/469 | Cost: 0.0051\n",
      "Epoch: 008/010 | Batch 300/469 | Cost: 0.0318\n",
      "Epoch: 008/010 | Batch 350/469 | Cost: 0.0284\n",
      "Epoch: 008/010 | Batch 400/469 | Cost: 0.0354\n",
      "Epoch: 008/010 | Batch 450/469 | Cost: 0.0194\n",
      "Epoch: 008/010 training accuracy: 99.02%\n",
      "Epoch: 009/010 | Batch 000/469 | Cost: 0.0119\n",
      "Epoch: 009/010 | Batch 050/469 | Cost: 0.0374\n",
      "Epoch: 009/010 | Batch 100/469 | Cost: 0.0052\n",
      "Epoch: 009/010 | Batch 150/469 | Cost: 0.0331\n",
      "Epoch: 009/010 | Batch 200/469 | Cost: 0.0097\n",
      "Epoch: 009/010 | Batch 250/469 | Cost: 0.0318\n",
      "Epoch: 009/010 | Batch 300/469 | Cost: 0.0566\n",
      "Epoch: 009/010 | Batch 350/469 | Cost: 0.0082\n",
      "Epoch: 009/010 | Batch 400/469 | Cost: 0.0418\n",
      "Epoch: 009/010 | Batch 450/469 | Cost: 0.0036\n",
      "Epoch: 009/010 training accuracy: 99.20%\n",
      "Epoch: 010/010 | Batch 000/469 | Cost: 0.0071\n",
      "Epoch: 010/010 | Batch 050/469 | Cost: 0.0064\n",
      "Epoch: 010/010 | Batch 100/469 | Cost: 0.0224\n",
      "Epoch: 010/010 | Batch 150/469 | Cost: 0.0106\n",
      "Epoch: 010/010 | Batch 200/469 | Cost: 0.0046\n",
      "Epoch: 010/010 | Batch 250/469 | Cost: 0.0282\n",
      "Epoch: 010/010 | Batch 300/469 | Cost: 0.0384\n",
      "Epoch: 010/010 | Batch 350/469 | Cost: 0.0125\n",
      "Epoch: 010/010 | Batch 400/469 | Cost: 0.0651\n",
      "Epoch: 010/010 | Batch 450/469 | Cost: 0.0146\n",
      "Epoch: 010/010 training accuracy: 99.31%\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0  # 初始化正确预测的数量和样本数量\n",
    "    for i, (features, targets) in enumerate(data_loader):  # 遍历数据加载器\n",
    "        features = features.to(device)  # 将输入数据移动到指定设备\n",
    "        targets = targets.to(device)  # 将标签数据移动到指定设备\n",
    "        logits, probas = model(features)  # 获取模型的预测结果和概率分布\n",
    "        _, predicted_labels = torch.max(probas, 1)  # 获取最大概率对应的预测标签\n",
    "        num_examples += targets.size(0)  # 累加样本数量\n",
    "        correct_pred += (predicted_labels == targets).sum()  # 累加正确预测的数量\n",
    "    return correct_pred.float()/num_examples * 100  # 返回准确率\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):  # 迭代每个epoch\n",
    "    model = model.train()  # 设置模型为训练模式\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):  # 遍历训练数据加载器中的每个批次\n",
    "        \n",
    "        features = features.to(device)  # 将输入数据移动到指定设备\n",
    "        targets = targets.to(device)  # 将标签数据移动到指定设备\n",
    "            \n",
    "        ### 正向传播与反向传播\n",
    "        logits, probas = model(features)  # 获取模型的预测结果和概率分布\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        \n",
    "        cost.backward()  # 计算梯度\n",
    "        \n",
    "        ### 更新模型参数\n",
    "        optimizer.step()  # 使用优化器更新模型的参数\n",
    "        \n",
    "        ### 日志记录\n",
    "        if not batch_idx % 50:  # 每50个批次输出一次日志\n",
    "            print('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                  % (epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model = model.eval()  # 设置模型为评估模式，以防止在推理时更新批归一化参数\n",
    "    with torch.set_grad_enabled(False):  # 在推理时不计算梯度以节省内存\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader)))  # 输出当前epoch的训练准确率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.24%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet with convolutional blocks for resizing (using a helper class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same network as above but uses a `ResidualBlock` helper class.  \n",
    "这与上面的网络相同，但使用了`ResidualBlock`辅助类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        \n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # 定义第1个卷积层，输入通道为channels[0]，输出通道为channels[1]\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=channels[0],\n",
    "                                      out_channels=channels[1],\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1)\n",
    "        self.conv_1_bn = torch.nn.BatchNorm2d(channels[1])  # 批归一化\n",
    "        \n",
    "        # 定义第2个卷积层，输入通道为channels[1]，输出通道为channels[2]\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=channels[1],\n",
    "                                      out_channels=channels[2],\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)   \n",
    "        self.conv_2_bn = torch.nn.BatchNorm2d(channels[2])  # 批归一化\n",
    "\n",
    "        # 定义快捷连接的卷积层，输入通道为channels[0]，输出通道为channels[2]\n",
    "        self.conv_shortcut_1 = torch.nn.Conv2d(in_channels=channels[0],\n",
    "                                               out_channels=channels[2],\n",
    "                                               kernel_size=(1, 1),\n",
    "                                               stride=(2, 2),\n",
    "                                               padding=0)   \n",
    "        self.conv_shortcut_1_bn = torch.nn.BatchNorm2d(channels[2])  # 批归一化\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x  # 保存输入x，用于残差连接\n",
    "        \n",
    "        out = self.conv_1(x)  # 通过第1个卷积层\n",
    "        out = self.conv_1_bn(out)  # 批归一化\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "\n",
    "        out = self.conv_2(out)  # 通过第2个卷积层\n",
    "        out = self.conv_2_bn(out)  # 批归一化\n",
    "        \n",
    "        # 使用线性变换对shortcut进行维度匹配（不使用ReLU激活）\n",
    "        shortcut = self.conv_shortcut_1(shortcut)\n",
    "        shortcut = self.conv_shortcut_1_bn(shortcut)  # 批归一化\n",
    "        \n",
    "        out += shortcut  # 残差连接\n",
    "        out = F.relu(out)  # ReLU激活函数\n",
    "\n",
    "        return out  # 返回输出结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 模型定义\n",
    "##########################\n",
    "\n",
    "\n",
    "class ConvNet(torch.nn.Module):  # 定义卷积神经网络类，继承自torch.nn.Module\n",
    "\n",
    "    def __init__(self, num_classes):  # 构造函数，num_classes是输出类别的数量\n",
    "        super(ConvNet, self).__init__()  # 调用父类的构造函数\n",
    "        \n",
    "        self.residual_block_1 = ResidualBlock(channels=[1, 4, 8])  # 第一个残差块，输入通道为1，输出通道为4和8\n",
    "        self.residual_block_2 = ResidualBlock(channels=[8, 16, 32])  # 第二个残差块，输入通道为8，输出通道为16和32\n",
    "    \n",
    "        self.linear_1 = torch.nn.Linear(7*7*32, num_classes)  # 全连接层，输入大小为7*7*32，输出为num_classes个类别\n",
    "\n",
    "        \n",
    "    def forward(self, x):  # 定义前向传播方法\n",
    "\n",
    "        out = self.residual_block_1.forward(x)  # 通过第一个残差块\n",
    "        out = self.residual_block_2.forward(out)  # 通过第二个残差块\n",
    "         \n",
    "        logits = self.linear_1(out.view(-1, 7*7*32))  # 扁平化输出，并通过全连接层\n",
    "        probas = F.softmax(logits, dim=1)  # 对logits进行softmax归一化，得到类别概率\n",
    "        return logits, probas  # 返回logits和概率\n",
    "\n",
    "    \n",
    "torch.manual_seed(random_seed)  # 设置随机种子，保证结果可复现\n",
    "model = ConvNet(num_classes=num_classes)  # 实例化模型，num_classes是类别数量\n",
    "\n",
    "model.to(device)  # 将模型转移到指定设备\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # 使用Adam优化器，学习率为learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/468 | Cost: 2.3534\n",
      "Epoch: 001/010 | Batch 050/468 | Cost: 0.2719\n",
      "Epoch: 001/010 | Batch 100/468 | Cost: 0.2472\n",
      "Epoch: 001/010 | Batch 150/468 | Cost: 0.1019\n",
      "Epoch: 001/010 | Batch 200/468 | Cost: 0.0748\n",
      "Epoch: 001/010 | Batch 250/468 | Cost: 0.1162\n",
      "Epoch: 001/010 | Batch 300/468 | Cost: 0.2745\n",
      "Epoch: 001/010 | Batch 350/468 | Cost: 0.1792\n",
      "Epoch: 001/010 | Batch 400/468 | Cost: 0.0572\n",
      "Epoch: 001/010 | Batch 450/468 | Cost: 0.1089\n",
      "Epoch: 001/010 training accuracy: 97.42%\n",
      "Epoch: 002/010 | Batch 000/468 | Cost: 0.0958\n",
      "Epoch: 002/010 | Batch 050/468 | Cost: 0.0521\n",
      "Epoch: 002/010 | Batch 100/468 | Cost: 0.1024\n",
      "Epoch: 002/010 | Batch 150/468 | Cost: 0.1421\n",
      "Epoch: 002/010 | Batch 200/468 | Cost: 0.0985\n",
      "Epoch: 002/010 | Batch 250/468 | Cost: 0.0494\n",
      "Epoch: 002/010 | Batch 300/468 | Cost: 0.0252\n",
      "Epoch: 002/010 | Batch 350/468 | Cost: 0.0329\n",
      "Epoch: 002/010 | Batch 400/468 | Cost: 0.0230\n",
      "Epoch: 002/010 | Batch 450/468 | Cost: 0.1180\n",
      "Epoch: 002/010 training accuracy: 98.21%\n",
      "Epoch: 003/010 | Batch 000/468 | Cost: 0.0405\n",
      "Epoch: 003/010 | Batch 050/468 | Cost: 0.0425\n",
      "Epoch: 003/010 | Batch 100/468 | Cost: 0.1703\n",
      "Epoch: 003/010 | Batch 150/468 | Cost: 0.0206\n",
      "Epoch: 003/010 | Batch 200/468 | Cost: 0.0533\n",
      "Epoch: 003/010 | Batch 250/468 | Cost: 0.0476\n",
      "Epoch: 003/010 | Batch 300/468 | Cost: 0.0157\n",
      "Epoch: 003/010 | Batch 350/468 | Cost: 0.0129\n",
      "Epoch: 003/010 | Batch 400/468 | Cost: 0.0648\n",
      "Epoch: 003/010 | Batch 450/468 | Cost: 0.0250\n",
      "Epoch: 003/010 training accuracy: 98.67%\n",
      "Epoch: 004/010 | Batch 000/468 | Cost: 0.0138\n",
      "Epoch: 004/010 | Batch 050/468 | Cost: 0.0288\n",
      "Epoch: 004/010 | Batch 100/468 | Cost: 0.0808\n",
      "Epoch: 004/010 | Batch 150/468 | Cost: 0.0808\n",
      "Epoch: 004/010 | Batch 200/468 | Cost: 0.0613\n",
      "Epoch: 004/010 | Batch 250/468 | Cost: 0.0353\n",
      "Epoch: 004/010 | Batch 300/468 | Cost: 0.0434\n",
      "Epoch: 004/010 | Batch 350/468 | Cost: 0.0398\n",
      "Epoch: 004/010 | Batch 400/468 | Cost: 0.0357\n",
      "Epoch: 004/010 | Batch 450/468 | Cost: 0.0261\n",
      "Epoch: 004/010 training accuracy: 98.97%\n",
      "Epoch: 005/010 | Batch 000/468 | Cost: 0.0481\n",
      "Epoch: 005/010 | Batch 050/468 | Cost: 0.0075\n",
      "Epoch: 005/010 | Batch 100/468 | Cost: 0.0845\n",
      "Epoch: 005/010 | Batch 150/468 | Cost: 0.0468\n",
      "Epoch: 005/010 | Batch 200/468 | Cost: 0.0912\n",
      "Epoch: 005/010 | Batch 250/468 | Cost: 0.0446\n",
      "Epoch: 005/010 | Batch 300/468 | Cost: 0.0321\n",
      "Epoch: 005/010 | Batch 350/468 | Cost: 0.0474\n",
      "Epoch: 005/010 | Batch 400/468 | Cost: 0.0346\n",
      "Epoch: 005/010 | Batch 450/468 | Cost: 0.0474\n",
      "Epoch: 005/010 training accuracy: 98.82%\n",
      "Epoch: 006/010 | Batch 000/468 | Cost: 0.0447\n",
      "Epoch: 006/010 | Batch 050/468 | Cost: 0.0151\n",
      "Epoch: 006/010 | Batch 100/468 | Cost: 0.0126\n",
      "Epoch: 006/010 | Batch 150/468 | Cost: 0.0502\n",
      "Epoch: 006/010 | Batch 200/468 | Cost: 0.0142\n",
      "Epoch: 006/010 | Batch 250/468 | Cost: 0.0855\n",
      "Epoch: 006/010 | Batch 300/468 | Cost: 0.0030\n",
      "Epoch: 006/010 | Batch 350/468 | Cost: 0.0044\n",
      "Epoch: 006/010 | Batch 400/468 | Cost: 0.0308\n",
      "Epoch: 006/010 | Batch 450/468 | Cost: 0.0965\n",
      "Epoch: 006/010 training accuracy: 99.06%\n",
      "Epoch: 007/010 | Batch 000/468 | Cost: 0.0198\n",
      "Epoch: 007/010 | Batch 050/468 | Cost: 0.0400\n",
      "Epoch: 007/010 | Batch 100/468 | Cost: 0.0252\n",
      "Epoch: 007/010 | Batch 150/468 | Cost: 0.0131\n",
      "Epoch: 007/010 | Batch 200/468 | Cost: 0.0288\n",
      "Epoch: 007/010 | Batch 250/468 | Cost: 0.0073\n",
      "Epoch: 007/010 | Batch 300/468 | Cost: 0.0681\n",
      "Epoch: 007/010 | Batch 350/468 | Cost: 0.1954\n",
      "Epoch: 007/010 | Batch 400/468 | Cost: 0.0326\n",
      "Epoch: 007/010 | Batch 450/468 | Cost: 0.0353\n",
      "Epoch: 007/010 training accuracy: 98.69%\n",
      "Epoch: 008/010 | Batch 000/468 | Cost: 0.0311\n",
      "Epoch: 008/010 | Batch 050/468 | Cost: 0.0221\n",
      "Epoch: 008/010 | Batch 100/468 | Cost: 0.0112\n",
      "Epoch: 008/010 | Batch 150/468 | Cost: 0.0472\n",
      "Epoch: 008/010 | Batch 200/468 | Cost: 0.1111\n",
      "Epoch: 008/010 | Batch 250/468 | Cost: 0.0051\n",
      "Epoch: 008/010 | Batch 300/468 | Cost: 0.0318\n",
      "Epoch: 008/010 | Batch 350/468 | Cost: 0.0284\n",
      "Epoch: 008/010 | Batch 400/468 | Cost: 0.0354\n",
      "Epoch: 008/010 | Batch 450/468 | Cost: 0.0194\n",
      "Epoch: 008/010 training accuracy: 99.02%\n",
      "Epoch: 009/010 | Batch 000/468 | Cost: 0.0119\n",
      "Epoch: 009/010 | Batch 050/468 | Cost: 0.0374\n",
      "Epoch: 009/010 | Batch 100/468 | Cost: 0.0052\n",
      "Epoch: 009/010 | Batch 150/468 | Cost: 0.0331\n",
      "Epoch: 009/010 | Batch 200/468 | Cost: 0.0097\n",
      "Epoch: 009/010 | Batch 250/468 | Cost: 0.0318\n",
      "Epoch: 009/010 | Batch 300/468 | Cost: 0.0566\n",
      "Epoch: 009/010 | Batch 350/468 | Cost: 0.0082\n",
      "Epoch: 009/010 | Batch 400/468 | Cost: 0.0418\n",
      "Epoch: 009/010 | Batch 450/468 | Cost: 0.0036\n",
      "Epoch: 009/010 training accuracy: 99.20%\n",
      "Epoch: 010/010 | Batch 000/468 | Cost: 0.0071\n",
      "Epoch: 010/010 | Batch 050/468 | Cost: 0.0064\n",
      "Epoch: 010/010 | Batch 100/468 | Cost: 0.0224\n",
      "Epoch: 010/010 | Batch 150/468 | Cost: 0.0106\n",
      "Epoch: 010/010 | Batch 200/468 | Cost: 0.0046\n",
      "Epoch: 010/010 | Batch 250/468 | Cost: 0.0282\n",
      "Epoch: 010/010 | Batch 300/468 | Cost: 0.0384\n",
      "Epoch: 010/010 | Batch 350/468 | Cost: 0.0125\n",
      "Epoch: 010/010 | Batch 400/468 | Cost: 0.0651\n",
      "Epoch: 010/010 | Batch 450/468 | Cost: 0.0146\n",
      "Epoch: 010/010 training accuracy: 99.31%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 计算准确率的函数\n",
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    # 遍历数据加载器中的每个批次\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "        # 将数据传输到设备（GPU或CPU）\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        logits, probas = model(features)\n",
    "        \n",
    "        # 获取预测的标签\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        \n",
    "        # 统计正确预测的数量和样本的总数\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    \n",
    "    # 返回准确率\n",
    "    return correct_pred.float() / num_examples * 100\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()  # 训练模式，启用dropout等层\n",
    "    \n",
    "    # 遍历训练数据集\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 前向传播和反向传播\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)  # 计算交叉熵损失\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        cost.backward()  # 反向传播\n",
    "        \n",
    "        # 更新模型参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 每50个批次打印一次日志\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                  % (epoch+1, num_epochs, batch_idx, len(train_dataset) // batch_size, cost.item()))\n",
    "\n",
    "    # 在验证模式下评估模型（防止在推理时更新batchnorm参数）\n",
    "    model = model.eval()  \n",
    "    with torch.set_grad_enabled(False):  # 推理时不需要计算梯度，节省内存\n",
    "        # 打印训练集上的准确率\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.24%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy      : 1.26.4\n",
      "torch      : 2.6.0+cu126\n",
      "torchvision: 0.21.0+cu126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
